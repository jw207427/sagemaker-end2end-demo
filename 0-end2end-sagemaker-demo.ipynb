{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection for Automobile Claims Demo\n",
    "\n",
    "Auto insurance fraud ranges from misrepresenting facts on insurance applications and inflating insurance claims to staging accidents and submitting claim forms for injuries or damage that never occurred, to false reports of stolen vehicles. Fraud accounted for between 15 percent and 17 percent of total claims payments for auto insurance bodily injury in 2012, according to an Insurance Research Council (IRC) study. The study estimated that between $5.6 billion and $7.7 billion was fraudulently added to paid claims for auto insurance bodily injury payments in 2012, compared with a range of $4.3 billion to $5.8 billion in 2002.\n",
    "\n",
    "- [Quick start with JumpStart and Autopilot](#Quick-Start-with-JumpStart-and-Autopilot)\n",
    "- [Feature Engineering W/ Data Wrangler](#Preprocessing-&-feature-engineering)\n",
    "- [Create Feature Store](#Create-Feature-Store-in-Code)\n",
    "- [Train a XGBoost Model](#Train-A-Model)\n",
    "- [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Deploy And Test](#Deploy-and-Serve-Model)\n",
    "- [CI/CD Pipeline]\n",
    "\n",
    "**This Demo is optimized for SageMaker Studio using Studio notebook in Data Science Kernel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Start with JumpStart and Autopilot\n",
    "\n",
    "---\n",
    "\n",
    "#### SageMaker JumpStart\n",
    "![JumpStart](statics/JumpStart.png)\n",
    "\n",
    "#### SageMaker Autopilot\n",
    "![Autopilot](statics/Autopilot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.41.0 boto3==1.17.70\n",
    "!python -m pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import string\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import awswrangler as wr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = sagemaker_session.account_id()\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "prefix = \"att-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Load raw claims & customer dataset to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_relationship</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted</th>\n",
       "      <th>num_vehicles_involved</th>\n",
       "      <th>num_injuries</th>\n",
       "      <th>num_witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>incident_month</th>\n",
       "      <th>incident_day</th>\n",
       "      <th>incident_dow</th>\n",
       "      <th>incident_hour</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spouse</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Front</td>\n",
       "      <td>Minor</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>71600</td>\n",
       "      <td>8913.668763</td>\n",
       "      <td>80513.668763</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Rear</td>\n",
       "      <td>Totaled</td>\n",
       "      <td>Police</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6400</td>\n",
       "      <td>19746.724395</td>\n",
       "      <td>26146.724395</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Front</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Police</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10400</td>\n",
       "      <td>11652.969918</td>\n",
       "      <td>22052.969918</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Child</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Side</td>\n",
       "      <td>Minor</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>104700</td>\n",
       "      <td>11260.930936</td>\n",
       "      <td>115960.930936</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Side</td>\n",
       "      <td>Major</td>\n",
       "      <td>Police</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>3400</td>\n",
       "      <td>27987.704652</td>\n",
       "      <td>31387.704652</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          driver_relationship incident_type collision_type incident_severity  \\\n",
       "policy_id                                                                      \n",
       "1                      Spouse     Collision          Front             Minor   \n",
       "2                        Self     Collision           Rear           Totaled   \n",
       "3                        Self     Collision          Front             Minor   \n",
       "4                       Child     Collision           Side             Minor   \n",
       "5                        Self     Collision           Side             Major   \n",
       "\n",
       "          authorities_contacted  num_vehicles_involved  num_injuries  \\\n",
       "policy_id                                                              \n",
       "1                          None                      2             0   \n",
       "2                        Police                      3             4   \n",
       "3                        Police                      2             0   \n",
       "4                          None                      2             0   \n",
       "5                        Police                      2             1   \n",
       "\n",
       "           num_witnesses police_report_available  injury_claim  vehicle_claim  \\\n",
       "policy_id                                                                       \n",
       "1                      0                      No         71600    8913.668763   \n",
       "2                      0                     Yes          6400   19746.724395   \n",
       "3                      1                     Yes         10400   11652.969918   \n",
       "4                      0                      No        104700   11260.930936   \n",
       "5                      0                      No          3400   27987.704652   \n",
       "\n",
       "           total_claim_amount  incident_month  incident_day  incident_dow  \\\n",
       "policy_id                                                                   \n",
       "1                80513.668763               3            17             6   \n",
       "2                26146.724395              12            11             2   \n",
       "3                22052.969918              12            24             1   \n",
       "4               115960.930936              12            23             0   \n",
       "5                31387.704652               5             8             2   \n",
       "\n",
       "           incident_hour  fraud  \n",
       "policy_id                        \n",
       "1                      8      0  \n",
       "2                     11      0  \n",
       "3                     14      0  \n",
       "4                     19      0  \n",
       "5                      8      0  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = pd.read_csv(\"./data/claims.csv\", index_col=0)\n",
    "df_customers = pd.read_csv(\"./data/customers.csv\", index_col=0)\n",
    "\n",
    "df_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_age</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>num_claims_past_year</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>policy_liability</th>\n",
       "      <th>customer_zip</th>\n",
       "      <th>customer_gender</th>\n",
       "      <th>customer_education</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>25/50</td>\n",
       "      <td>99207</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>2950</td>\n",
       "      <td>15/30</td>\n",
       "      <td>95632</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>15/30</td>\n",
       "      <td>93203</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>30/60</td>\n",
       "      <td>85208</td>\n",
       "      <td>Female</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>15/30</td>\n",
       "      <td>91792</td>\n",
       "      <td>Female</td>\n",
       "      <td>High School</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_age  months_as_customer  num_claims_past_year  \\\n",
       "policy_id                                                           \n",
       "1                    54                  94                     0   \n",
       "2                    41                 165                     0   \n",
       "3                    57                 155                     0   \n",
       "4                    39                  80                     0   \n",
       "5                    39                  60                     0   \n",
       "\n",
       "           num_insurers_past_5_years policy_state  policy_deductable  \\\n",
       "policy_id                                                              \n",
       "1                                  1           WA                750   \n",
       "2                                  1           CA                750   \n",
       "3                                  1           CA                750   \n",
       "4                                  1           AZ                750   \n",
       "5                                  1           CA                750   \n",
       "\n",
       "           policy_annual_premium policy_liability  customer_zip  \\\n",
       "policy_id                                                         \n",
       "1                           3000            25/50         99207   \n",
       "2                           2950            15/30         95632   \n",
       "3                           3000            15/30         93203   \n",
       "4                           3000            30/60         85208   \n",
       "5                           3000            15/30         91792   \n",
       "\n",
       "          customer_gender customer_education  auto_year  \n",
       "policy_id                                                \n",
       "1                  Unkown          Associate       2006  \n",
       "2                    Male           Bachelor       2012  \n",
       "3                  Female           Bachelor       2017  \n",
       "4                  Female    Advanced Degree       2020  \n",
       "5                  Female        High School       2018  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can preprocess the raw data with Data Wrangler, it must exist in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed claims data is located at s3://sagemaker-us-west-2-987720697751/att-demo/data/raw/claims.csv\n",
      "processed claims data is located at s3://sagemaker-us-west-2-987720697751/att-demo/data/raw/customers.csv\n"
     ]
    }
   ],
   "source": [
    "claims_key = f\"{prefix}/data/raw/claims.csv\"\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=\"data/claims.csv\", Bucket=bucket, Key=claims_key\n",
    ")\n",
    "\n",
    "claims_s3_path = f's3://{bucket}/{claims_key}'\n",
    "print(f'processed claims data is located at {claims_s3_path}')\n",
    "\n",
    "\n",
    "customers_key = f\"{prefix}/data/raw/customers.csv\"\n",
    "s3_client.upload_file(\n",
    "    Filename=\"data/customers.csv\", Bucket=bucket, Key=customers_key\n",
    ")\n",
    "\n",
    "customers_s3_path = f's3://{bucket}/{customers_key}'\n",
    "print(f'processed claims data is located at {customers_s3_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration & feature engineering\n",
    "From here let's jump into SageMaker Data Wranger to preprocess our dataset.  In this step, we are performing the following\n",
    "\n",
    "1. ingest data from S3\n",
    "2. visualize and analyze our data\n",
    "3. process and transform to clean up and encode our dataset\n",
    "4. combine customer and claims data to build one dataset\n",
    "5. export data to S3 and feature store\n",
    "\n",
    "![data_wrangler](statics/data_wrangler.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Store in Code\n",
    "There are multiple ways to create/ingest data to Feature store\n",
    "- Data Wrangler\n",
    "- Stream using Kinesis Data Firehose\n",
    "- Custom ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# if the Data Wrangler job was not run, the claims and customers dataframes will be loaded from local copies\n",
    "timestamp = pd.to_datetime(\"now\").timestamp()\n",
    "\n",
    "claims_preprocessed = pd.read_csv(filepath_or_buffer=\"data/claims_preprocessed.csv\")\n",
    "\n",
    "# a timestamp column is required by the feature store, so one is added with a current timestamp\n",
    "claims_preprocessed[\"event_time\"] = timestamp\n",
    "\n",
    "customers_preprocessed = pd.read_csv(filepath_or_buffer=\"data/customers_preprocessed.csv\")\n",
    "\n",
    "customers_preprocessed[\"event_time\"] = timestamp\n",
    "\n",
    "\n",
    "combined_preprocessed = pd.read_csv(filepath_or_buffer=\"data/claims_customer.csv\")\n",
    "\n",
    "combined_preprocessed = combined_preprocessed.loc[:, ~combined_preprocessed.columns.str.contains(\"^Unnamed: 0\")]\n",
    "\n",
    "combined_preprocessed[\"event_time\"] = timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Feature Store Run Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Store can infer the schema from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema Setup Complete\n"
     ]
    }
   ],
   "source": [
    "claims_fg_name = f\"{prefix}-claims-api\"\n",
    "customers_fg_name = f\"{prefix}-customers-api\"\n",
    "combined_fg_name = f\"{prefix}-combined-api\"\n",
    "\n",
    "record_identifier_feature_name = \"policy_id\"\n",
    "event_time_feature_name = \"event_time\"\n",
    "\n",
    "claims_feature_group = FeatureGroup(name=claims_fg_name, sagemaker_session=feature_store_session)\n",
    "\n",
    "customers_feature_group = FeatureGroup(\n",
    "    name=customers_fg_name, sagemaker_session=feature_store_session\n",
    ")\n",
    "\n",
    "combined_feature_group = FeatureGroup(\n",
    "    name=combined_fg_name, sagemaker_session=feature_store_session\n",
    ")\n",
    "\n",
    "claims_feature_group.load_feature_definitions(data_frame=claims_preprocessed)\n",
    "customers_feature_group.load_feature_definitions(data_frame=customers_preprocessed)\n",
    "combined_feature_group.load_feature_definitions(data_frame=combined_preprocessed)\n",
    "\n",
    "print('Schema Setup Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "claims_feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=sagemaker_role,\n",
    "    enable_online_store=True,\n",
    ")\n",
    "\n",
    "customers_feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=sagemaker_role,\n",
    "    enable_online_store=True,\n",
    ")\n",
    "\n",
    "combined_feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=sagemaker_role,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait until feature group creation has fully completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureGroup att-demo-claims-api successfully created.\n",
      "FeatureGroup att-demo-customers-api successfully created.\n",
      "FeatureGroup att-demo-combined-api successfully created.\n"
     ]
    }
   ],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=claims_feature_group)\n",
    "wait_for_feature_group_creation_complete(feature_group=customers_feature_group)\n",
    "wait_for_feature_group_creation_complete(feature_group=combined_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting data into Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='att-demo-combined-api', sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7f34ee8f61d0>, max_workers=3, max_processes=1, _async_result=<multiprocess.pool.MapResult object at 0x7f34ee7b6ed0>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_feature_group.ingest(data_frame=claims_preprocessed, max_workers=3, wait=True)\n",
    "\n",
    "customers_feature_group.ingest(data_frame=customers_preprocessed, max_workers=3, wait=True)\n",
    "\n",
    "combined_feature_group.ingest(data_frame=combined_preprocessed, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Wait for the Data To Load, Let's Explore the Feature Store Console\n",
    "\n",
    "![Feature Store](statics/feature_store.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling data from offline feature store\n",
    "----\n",
    "We can now build our training and test datasets repeatedly and consistenly from the feature groups we just created.  In this example, we will submit a SQL query to join the the Claims and Customers features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_query = claims_feature_group.athena_query()\n",
    "customers_query = customers_feature_group.athena_query()\n",
    "\n",
    "claims_table = claims_query.table_name\n",
    "customers_table = customers_query.table_name\n",
    "database_name = customers_query.database\n",
    "\n",
    "feature_columns = list(set(claims_preprocessed.columns) ^ set(customers_preprocessed.columns))\n",
    "feature_columns_string = \", \".join(f'\"{c}\"' for c in feature_columns)\n",
    "feature_columns_string = f'\"{claims_table}\".policy_id as policy_id, ' + feature_columns_string\n",
    "\n",
    "query_string = f\"\"\"\n",
    "SELECT DISTINCT {feature_columns_string}\n",
    "FROM \"{claims_table}\" LEFT JOIN \"{customers_table}\" \n",
    "ON \"{claims_table}\".policy_id = \"{customers_table}\".policy_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query 29047a70-656e-4c62-978c-02a4698e3d10 is being executed.\n",
      "INFO:sagemaker:Query 29047a70-656e-4c62-978c-02a4698e3d10 successfully executed.\n"
     ]
    }
   ],
   "source": [
    "claims_query.run(query_string=query_string, output_location=f\"s3://{bucket}/{prefix}/query_results\")\n",
    "claims_query.wait()\n",
    "dataset = claims_query.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train A XGBoost Model\n",
    "----\n",
    "#### Move the target varibale to the first column for our xgboost model\n",
    "\n",
    "Split train & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\"fraud\"] + list(dataset.drop([\"fraud\", \"policy_id\"], axis=1).columns)\n",
    "\n",
    "train = dataset.sample(frac=0.80, random_state=0)[col_order]\n",
    "test = dataset.drop(train.index)[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve class imbalance using SMOTE\n",
    "\n",
    "To handle the imbalance, we can over-sample (i.e. upsample) the minority class using [SMOTE (Synthetic Minority Over-sampling Technique)](https://arxiv.org/pdf/1106.1813.pdf). After installing the imbalanced-learn module, if you receive an ImportError when importing SMOTE, then try restarting the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2793\n",
       "1.0    1207\n",
       "Name: customer_gender_female, dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = train[\"customer_gender_female\"]\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender balance after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2793\n",
       "0.0    2793\n",
       "Name: customer_gender_female, dtype: int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "train_data_gender_upsampled, gender_res = sm.fit_resample(train, gender)\n",
    "train_data_gender_upsampled[\"customer_gender_female\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolve class imbalance for positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5473\n",
       "1     113\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train_data_gender_upsampled[\"fraud\"]\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5473\n",
       "1    2736\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "train_data_upsampled, fraudr_res = sm.fit_resample(train_data_gender_upsampled, target)\n",
    "train_data_upsampled[\"fraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload new data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsampled training data is uploaded to s3://sagemaker-us-west-2-987720697751/att-demo/data/train/upsampled/train.csv\n"
     ]
    }
   ],
   "source": [
    "train_data_upsampled.to_csv(\"data/upsampled_train.csv\", index=False)\n",
    "key = f\"{prefix}/data/train/upsampled/train.csv\"\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=\"data/upsampled_train.csv\",\n",
    "    Bucket=bucket,\n",
    "    Key=key,\n",
    ")\n",
    "\n",
    "train_data_upsampled_s3_path = f\"s3://{bucket}/{key}\"\n",
    "print(f\"Unsampled training data is uploaded to {train_data_upsampled_s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the hyperparameters\n",
    "These are the parameters which will be sent to our training script in order to train the model. Although they are all defined as \"hyperparameters\" here, they can encompass XGBoost's [Learning Task Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters), [Tree Booster Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster), or any other parameters you'd like to configure for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"3\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"xgboost_starter_script.py\",\n",
    "    source_dir=\"code\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=sagemaker_role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    framework_version=\"1.0-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Experiment\n",
    "SageMaker Experiment helps you organize, track, compare and evaluate machine learning (ML) experiments and model versions. SInce ML is a highly iterative process, Experiment helps data scientists and ML engineers to explore thousands of different models in an organized manner. Exspecially when you are using tools like Automatic Model Tuning and Amazon SageMaker Autopilot, it will help you explore a large number of combinations automatically, and quickly zoom in on high-performance models.\n",
    "\n",
    "![Experiment 1](statics/experiment_1.png) ![Experiment 2](statics/experiment_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_experiment = Experiment.create(\n",
    "    experiment_name=f\"att-demo-{int(time.time())}\",\n",
    "    description=\"Fraud Detection Demo\",\n",
    "    sagemaker_boto_client=sagemaker_boto_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new experiment trial for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment name is att-demo-1652885956, and the trail component is single-training-1652885958\n"
     ]
    }
   ],
   "source": [
    "trial_name = f\"single-training-{int(time.time())}\"\n",
    "single_trial = Trial.create(\n",
    "    trial_name=trial_name,\n",
    "    experiment_name=demo_experiment.experiment_name,\n",
    "    sagemaker_boto_client=sagemaker_boto_client,\n",
    ")\n",
    "\n",
    "experiment_config={\n",
    "    \"ExperimentName\": demo_experiment.experiment_name,\n",
    "    \"TrialName\": single_trial.trial_name,\n",
    "    \"TrialComponentDisplayName\": \"ManualTraining\",\n",
    "}\n",
    "\n",
    "print(f\"The experiment name is {demo_experiment.experiment_name}, and the trail component is {single_trial.trial_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2022-05-18-14-59-19-257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-18 14:59:20 Starting - Starting the training job...\n",
      "2022-05-18 14:59:45 Starting - Preparing the instances for trainingProfilerReport-1652885959: InProgress\n",
      ".........\n",
      "2022-05-18 15:01:15 Downloading - Downloading input data...\n",
      "2022-05-18 15:01:46 Training - Downloading the training image......\n",
      "2022-05-18 15:02:43 Training - Training image download completed. Training in progress..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module xgboost_starter_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: xgboost-starter-script\n",
      "  Building wheel for xgboost-starter-script (setup.py): started\n",
      "  Building wheel for xgboost-starter-script (setup.py): finished with status 'done'\n",
      "  Created wheel for xgboost-starter-script: filename=xgboost_starter_script-1.0.0-py2.py3-none-any.whl size=6175 sha256=092322242bfc71de2fabba68e6184b87d7827542a9c02b9897eb27519ba8022f\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-g8eigytv/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built xgboost-starter-script\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xgboost-starter-script\u001b[0m\n",
      "\u001b[34mSuccessfully installed xgboost-starter-script-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"max_depth\": \"3\",\n",
      "        \"num_round\": \"100\",\n",
      "        \"objective\": \"binary:logistic\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2022-05-18-14-59-19-257\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-987720697751/sagemaker-xgboost-2022-05-18-14-59-19-257/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"xgboost_starter_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"xgboost_starter_script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"max_depth\":\"3\",\"num_round\":\"100\",\"objective\":\"binary:logistic\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=xgboost_starter_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=xgboost_starter_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-987720697751/sagemaker-xgboost-2022-05-18-14-59-19-257/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"max_depth\":\"3\",\"num_round\":\"100\",\"objective\":\"binary:logistic\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-05-18-14-59-19-257\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-987720697751/sagemaker-xgboost-2022-05-18-14-59-19-257/source/sourcedir.tar.gz\",\"module_name\":\"xgboost_starter_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"xgboost_starter_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--max_depth\",\"3\",\"--num_round\",\"100\",\"--objective\",\"binary:logistic\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=3\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=100\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m xgboost_starter_script --eta 0.2 --max_depth 3 --num_round 100 --objective binary:logistic\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.9983774000000001\u001b[0m\n",
      "\u001b[34m[1]#011validation-auc:0.9931588000000001\u001b[0m\n",
      "\n",
      "2022-05-18 15:03:13 Uploading - Uploading generated training model\n",
      "2022-05-18 15:03:13 Completed - Training job completed\n",
      "Training seconds: 118\n",
      "Billable seconds: 118\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.fit(inputs={\"train\": train_data_upsampled_s3_path}, experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: att-demo-xgboost-post-smote\n",
      "WARNING:sagemaker:Using already existing model: att-demo-xgboost-post-smote\n"
     ]
    }
   ],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(\n",
    "    TrainingJobName=xgb_estimator.latest_training_job.job_name\n",
    ")\n",
    "\n",
    "model_name = f\"{prefix}-xgboost-post-smote\"\n",
    "model = sagemaker_session.create_model_from_job(\n",
    "    name=model_name,\n",
    "    training_job_name=training_job_info['TrainingJobName'],\n",
    "    role=sagemaker_role,\n",
    "    image_uri=training_job_info['AlgorithmSpecification']['TrainingImage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "We will tune four hyperparameters in this examples:\n",
    "\n",
    "- eta: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative.\n",
    "\n",
    "- max_depth: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"validation:auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    xgb_estimator, \n",
    "    objective_metric_name, \n",
    "    hyperparameter_ranges, \n",
    "    max_jobs=12, \n",
    "    max_parallel_jobs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-xgboost-220518-1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(inputs={\"train\": train_data_upsampled_s3_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize HPO training jobs to the Experiement and Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tuning jobs.\n",
      "Associate all training jobs created by att-demo-1652885956 with trial att-demo-1652885956-hpo\n",
      "Found 12 trial components.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-012-04b32da7-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-009-e638790e-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-011-91b5a381-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-010-1dea75c3-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-007-8282a4a8-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-005-74bc7d98-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-008-033b7545-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-006-232c9d41-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-004-707cb393-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-001-8004a57b-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-003-5fca9579-aws-training-job with trial att-demo-1652885956-hpo.\n",
      "Associating trial component sagemaker-xgboost-220518-1510-002-7a0fe97b-aws-training-job with trial att-demo-1652885956-hpo.\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.search_expression import Filter, Operator, SearchExpression\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "\n",
    "import pytz\n",
    "\n",
    "# Get the most recently created tuning job\n",
    "\n",
    "list_tuning_jobs_response = sagemaker_boto_client.list_hyper_parameter_tuning_jobs(\n",
    "    SortBy=\"CreationTime\", SortOrder=\"Descending\"\n",
    ")\n",
    "print(f'Found {len(list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"])} tuning jobs.')\n",
    "tuning_jobs = list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"]\n",
    "most_recently_created_tuning_job = tuning_jobs[0]\n",
    "tuning_job_name = most_recently_created_tuning_job[\"HyperParameterTuningJobName\"]\n",
    "trial_name = demo_experiment.experiment_name + \"-hpo\"\n",
    "\n",
    "print(f\"Associate all training jobs created by {demo_experiment.experiment_name} with trial {trial_name}\")\n",
    "\n",
    "# create the trial if it doesn't exist\n",
    "try:\n",
    "    trial = Trial.load(trial_name=trial_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        trial = Trial.create(experiment_name=demo_experiment.experiment_name, trial_name=trial_name)\n",
    "        \n",
    "# Get the trial components derived from the training jobs\n",
    "\n",
    "creation_time = most_recently_created_tuning_job[\"CreationTime\"]\n",
    "creation_time = creation_time.astimezone(pytz.utc)\n",
    "creation_time = creation_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "created_after_filter = Filter(\n",
    "    name=\"CreationTime\",\n",
    "    operator=Operator.GREATER_THAN_OR_EQUAL,\n",
    "    value=str(creation_time),\n",
    ")\n",
    "\n",
    "# The training job names contain the tuning job name (and the training job name is in the source arn)\n",
    "source_arn_filter = Filter(\n",
    "    name=\"TrialComponentName\", operator=Operator.CONTAINS, value=tuning_job_name\n",
    ")\n",
    "source_type_filter = Filter(\n",
    "    name=\"Source.SourceType\", operator=Operator.EQUALS, value=\"SageMakerTrainingJob\"\n",
    ")\n",
    "\n",
    "search_expression = SearchExpression(\n",
    "    filters=[created_after_filter, source_arn_filter, source_type_filter]\n",
    ")\n",
    "\n",
    "# Search iterates over every page of results by default\n",
    "trial_component_search_results = list(\n",
    "    TrialComponent.search(search_expression=search_expression, sagemaker_boto_client=sagemaker_boto_client)\n",
    ")\n",
    "print(f\"Found {len(trial_component_search_results)} trial components.\")\n",
    "\n",
    "\n",
    "# Associate the trial components with the trial\n",
    "for tc in trial_component_search_results:\n",
    "    print(f\"Associating trial component {tc.trial_component_name} with trial {trial.trial_name}.\")\n",
    "    trial.add_trial_component(tc.trial_component_name)\n",
    "    # sleep to avoid throttling\n",
    "    time.sleep(0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Deploy and Serve Model\n",
    "----\n",
    "\n",
    "Now that we have trained a model, we can deploy and serve it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "endpoint_name = f\"{model_name}-endpoint-{int(time.time())}\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: Creating\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = f\"{model_name}-endpoint-config-{int(time.time())}\"\n",
    "\n",
    "data_capture_s3_loaction = f\"s3://{bucket}/{prefix}/monitoring/datacapture\"\n",
    "\n",
    "\n",
    "create_ep_config_response = sagemaker_boto_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": endpoint_instance_type,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": endpoint_instance_count,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    "    DataCaptureConfig={\n",
    "        \"EnableCapture\": True,\n",
    "        \"InitialSamplingPercentage\": 100,\n",
    "        \"DestinationS3Uri\": data_capture_s3_loaction,\n",
    "        \"CaptureContentTypeHeader\": { \n",
    "            \"CsvContentTypes\": [ \"text/csv\" ]\n",
    "        },\n",
    "        \"CaptureOptions\": [\n",
    "            {\n",
    "                \"CaptureMode\": \"Input\"\n",
    "            },\n",
    "            {\n",
    "                \"CaptureMode\": \"Output\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "create_endpoint_response = sagemaker_boto_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = endpoint_info[\"EndpointStatus\"]\n",
    "\n",
    "while endpoint_status == \"Creating\":\n",
    "    endpoint_info = sagemaker_boto_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = endpoint_info[\"EndpointStatus\"]\n",
    "    print(\"Endpoint status:\", endpoint_status)\n",
    "    if endpoint_status == \"Creating\":\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, serializer=CSVSerializer(), sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>971</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions    0  1\n",
       "actual             \n",
       "0            971  6\n",
       "1             21  2"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = \"\"\n",
    "    for array in split_array:\n",
    "        predictions = \",\".join([predictions, predictor.predict(array).decode(\"utf-8\")])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=\",\")\n",
    "\n",
    "# run batch prediction\n",
    "probabilities = predict(test.to_numpy()[:, 1:])\n",
    "\n",
    "def calibrate(probabilities, cutoff=.2):\n",
    "    predictions = []\n",
    "    for p in probabilities:\n",
    "        if p <= cutoff:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(1)\n",
    "    return predictions\n",
    "\n",
    "# run calibration and visualize the results\n",
    "predictions = np.asarray(calibrate(probabilities, 0.15))\n",
    "\n",
    "pd.crosstab(\n",
    "    index=test.iloc[:, 0],\n",
    "    columns=predictions,\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"predictions\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from Online Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online feature store query speed 98.91629219055176 ms\n",
      "\n",
      "For policy 1050: prediction is 0.0 and actual is 0\n",
      "------------------\n",
      "\n",
      "CPU times: user 18.8 ms, sys: 0 ns, total: 18.8 ms\n",
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_policy_id = 1050\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "combined_response = featurestore_runtime.get_record(\n",
    "    FeatureGroupName=combined_fg_name, RecordIdentifierValueAsString=str(sample_policy_id)\n",
    ")\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Online feature store query speed {(t2-t1)*1000} ms\\n\")\n",
    "\n",
    "combined_record = combined_response[\"Record\"]\n",
    "combined_df = pd.DataFrame(combined_record).set_index(\"FeatureName\")\n",
    "\n",
    "sample_acutal = int(combined_df.loc['fraud'][0])\n",
    "\n",
    "blended_df = combined_df.loc[col_order].drop([\"fraud\"])\n",
    "\n",
    "data_input = \",\".join([str(x) for x in blended_df[\"ValueAsString\"]])\n",
    "\n",
    "results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "prediction = json.loads(results)\n",
    "print(f\"For policy {int(sample_policy_id)}: prediction is {np.round(prediction)} and actual is {sample_acutal}\")\n",
    "print(\"------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitoring\n",
    "\n",
    "![Model Monitoring](statics/Model_monitoring.png)\n",
    "\n",
    "**1. Constraint suggestion with baseline/training dataset**\n",
    "\n",
    "The training dataset with which you trained the model is usually a good baseline dataset. Note that the training dataset data schema and the inference dataset schema should exactly match (i.e. the number and order of the features).\n",
    "\n",
    "From the training dataset you can ask Amazon SageMaker to suggest a set of baseline constraints and generate descriptive statistics to explore the data. For this example, upload the training dataset that was used to train the pre-trained model included in this example. If you already have it in Amazon S3, you can directly point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our training dataset\n",
    "baseline_data_uri = train_data_upsampled_s3_path\n",
    "baseline_results_prefix = f\"{prefix}/monitoring/baselining/results\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{baseline_results_prefix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a baselining job with training dataset\n",
    "Now that you have the training data ready in Amazon S3, start a job to suggest constraints. DefaultModelMonitor.suggest_baseline(..) starts a ProcessingJob using an Amazon SageMaker provided Model Monitor container to generate the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2022-05-19-18-43-11-183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2022-05-19-18-43-11-183\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/att-demo/data/train/upsampled/train.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-987720697751/att-demo/monitoring/baselining/results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...........................\u001b[34m2022-05-19 18:47:28,366 - matplotlib.font_manager - INFO - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:28.886681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:28.886710: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:30.369430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:30.369461: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:30.369485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-184-47.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:30.369733: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,872 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:987720697751:processing-job/baseline-suggestion-job-2022-05-19-18-43-11-183', 'ProcessingJobName': 'baseline-suggestion-job-2022-05-19-18-43-11-183', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '159807026194.dkr.ecr.us-west-2.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-west-2-987720697751/att-demo/data/train/upsampled/train.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-west-2-987720697751/att-demo/monitoring/baselining/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::987720697751:role/service-role/AmazonSageMaker-ExecutionRole-20220125T091764', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,873 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,873 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,873 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,873 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,930 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,931 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,931 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,939 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,939 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:31,939 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,382 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.184.47\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.\u001b[0m\n",
      "\u001b[34m0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,389 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,393 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-c923ddd7-4083-4adb-b3e4-b1c2af3a0b79\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,868 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,882 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,884 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,886 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,892 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,892 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,892 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,892 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,928 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,938 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,941 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,945 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,945 INFO blockmanagement.BlockManager: The block deletion will start around 2022 May 19 18:47:32\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,947 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,947 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,948 INFO util.GSet: 2.0% max memory 3.1 GB = 64 MB\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:32,948 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,025 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,029 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,029 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,029 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,029 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,029 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,030 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,030 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,030 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,030 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,030 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,030 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,055 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,055 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,055 INFO util.GSet: 1.0% max memory 3.1 GB = 32 MB\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,055 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,057 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,057 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,057 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,057 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,061 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,065 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,065 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,065 INFO util.GSet: 0.25% max memory 3.1 GB = 8 MB\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,065 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,071 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,071 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,071 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,074 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,074 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,075 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,075 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,075 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 983.0 KB\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,076 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,096 INFO namenode.FSImage: Allocated new BlockPoolId: BP-76317507-10.0.184.47-1652986053090\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,107 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,113 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,189 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,200 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,204 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.184.47\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:33,214 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:35,272 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:35,273 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:37,363 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:37,364 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:39,428 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:39,429 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:41,517 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:41,517 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:43,673 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:43,673 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:53,683 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:54 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:54 INFO  Main:28 - Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:54 INFO  Main:31 - Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:54 INFO  FileUtil:66 - Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SparkContext:54 - Running Spark version 2.3.1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SparkContext:54 - Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42775.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SparkEnv:54 - Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SparkEnv:54 - Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-171570b7-b628-4752-884d-43c7580c1657\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  MemoryStore:54 - MemoryStore started with capacity 1458.6 MB\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:55 INFO  SparkContext:54 - Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.184.47:42775/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1652986075616\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  RMProxy:133 - Connecting to ResourceManager at /10.0.184.47:8032\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Client:54 - Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Configuration:2636 - resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  ResourceUtils:427 - Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (15743 MB per container)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Client:54 - Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Client:54 - Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:56 INFO  Client:54 - Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:57 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:47:58 INFO  Client:54 - Uploading resource file:/tmp/spark-1e72e140-aac7-4ab9-ad3a-3c323b4de1ce/__spark_libs__1382471518710475022.zip -> hdfs://10.0.184.47/user/root/.sparkStaging/application_1652986058905_0001/__spark_libs__1382471518710475022.zip\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  Client:54 - Uploading resource file:/tmp/spark-1e72e140-aac7-4ab9-ad3a-3c323b4de1ce/__spark_conf__4030284487091193058.zip -> hdfs://10.0.184.47/user/root/.sparkStaging/application_1652986058905_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:00 INFO  Client:54 - Submitting application application_1652986058905_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:01 INFO  YarnClientImpl:310 - Submitted application application_1652986058905_0001\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:01 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1652986058905_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:02 INFO  Client:54 - Application report for application_1652986058905_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:02 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Thu May 19 18:48:01 +0000 2022] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1652986080913\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1652986058905_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:03 INFO  Client:54 - Application report for application_1652986058905_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:04 INFO  Client:54 - Application report for application_1652986058905_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:05 INFO  Client:54 - Application report for application_1652986058905_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:06 INFO  Client:54 - Application report for application_1652986058905_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:06 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1652986058905_0001), /proxy/application_1652986058905_0001\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:06 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  Client:54 - Application report for application_1652986058905_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.184.47\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1652986080913\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1652986058905_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  YarnClientSchedulerBackend:54 - Application application_1652986058905_0001 has started running.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34201.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  NettyBlockTransferService:54 - Server created on 10.0.184.47:34201\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.184.47, 34201, None)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.184.47:34201 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.184.47, 34201, None)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.184.47, 34201, None)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.0.184.47, 34201, None)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:07 INFO  log:192 - Logging initialized @13387ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:08 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.184.47:54078) with ID 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:09 INFO  BlockManagerMasterEndpoint:54 - Registering block manager algo-1:40371 with 5.8 GB RAM, BlockManagerId(1, algo-1, 40371, None)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:25 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:25 WARN  SparkContext:66 - Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:25 INFO  DatasetReader:132 - Files to process:List(file:///opt/ml/processing/input/baseline_dataset_input/train.csv)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:25 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.3.1/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:25 INFO  SharedState:54 - Warehouse path is 'file:/usr/spark-2.3.1/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:26 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:26 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  CodeGenerator:54 - Code generated in 171.059646 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  CodeGenerator:54 - Code generated in 23.861304 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 429.7 KB, free 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.184.47:34201 (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  SparkContext:54 - Created broadcast 0 from csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  SparkContext:54 - Starting job: csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  DAGScheduler:54 - Got job 0 (csv at DatasetReader.scala:83) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at DatasetReader.scala:83)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:83), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.184.47:34201 (size: 4.5 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:83) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  YarnScheduler:54 - Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on algo-1:40371 (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on algo-1:40371 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1722 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  DAGScheduler:54 - ResultStage 0 (csv at DatasetReader.scala:83) finished in 1.808 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  DAGScheduler:54 - Job 0 finished: csv at DatasetReader.scala:83, took 1.852045 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  CodeGenerator:54 - Code generated in 8.20072 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 429.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.184.47:34201 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  SparkContext:54 - Created broadcast 2 from csv at DatasetReader.scala:83\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<fraud: string, driver_relationship_spouse: string, policy_state_ca: string, incident_type_breakin: string, num_vehicles_involved: string ... 44 more fields>\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 429.7 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.184.47:34201 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  SparkContext:54 - Created broadcast 3 from cache at DataAnalyzer.scala:78\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:29 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  CodeGenerator:54 - Code generated in 80.607326 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  CodeGenerator:54 - Code generated in 55.638443 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  SparkContext:54 - Starting job: head at DataAnalyzer.scala:81\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  DAGScheduler:54 - Got job 1 (head at DataAnalyzer.scala:81) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (head at DataAnalyzer.scala:81)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 63.9 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1457.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  YarnScheduler:54 - Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:30 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on algo-1:40371 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  BlockManagerInfo:54 - Added rdd_11_0 in memory on algo-1:40371 (size: 1273.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 1066 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  YarnScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - ResultStage 1 (head at DataAnalyzer.scala:81) finished in 1.112 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Job 1 finished: head at DataAnalyzer.scala:81, took 1.118356 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DataAnalyzer:89 - The number of columns in the dataframe is 46\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DataAnalyzer:116 - Number of shards is: 10\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  CodeGenerator:54 - Code generated in 15.621057 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Registering RDD 22 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Got job 2 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 95.2 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.184.47:34201 (size: 32.4 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  YarnScheduler:54 - Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:31 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on algo-1:40371 (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 962 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  YarnScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - ShuffleMapStage 2 (collect at AnalysisRunner.scala:313) finished in 0.991 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 108.1 KB, free 1456.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1456.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  YarnScheduler:54 - Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:32 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 287 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - ResultStage 3 (collect at AnalysisRunner.scala:313) finished in 0.308 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Job 2 finished: collect at AnalysisRunner.scala:313, took 1.318980 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  YarnScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  CodeGenerator:54 - Code generated in 16.360016 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Got job 3 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 55.4 KB, free 1456.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1456.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  YarnScheduler:54 - Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 378 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  YarnScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - ResultStage 4 (treeReduce at KLLRunner.scala:107) finished in 0.389 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  DAGScheduler:54 - Job 3 finished: treeReduce at KLLRunner.scala:107, took 0.397427 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:33 INFO  CodeGenerator:54 - Code generated in 48.936772 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  CodeGenerator:54 - Code generated in 272.044622 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  CodeGenerator:54 - Code generated in 105.134529 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Registering RDD 39 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Got job 4 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 94.3 KB, free 1456.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.7 KB, free 1456.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.184.47:34201 (size: 32.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  YarnScheduler:54 - Adding task set 5.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on algo-1:40371 (size: 32.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  YarnScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - ShuffleMapStage 5 (collect at AnalysisRunner.scala:313) finished in 0.145 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - waiting: Set(ResultStage 6)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 54.3 KB, free 1456.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1456.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.184.47:34201 (size: 16.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  YarnScheduler:54 - Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on algo-1:40371 (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  YarnScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - ResultStage 6 (collect at AnalysisRunner.scala:313) finished in 0.113 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Job 4 finished: collect at AnalysisRunner.scala:313, took 0.267666 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Registering RDD 49 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Got job 5 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 50.0 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 10.0.184.47:34201 (size: 20.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  YarnScheduler:54 - Adding task set 7.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:34 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on algo-1:40371 (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 853 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  YarnScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - ShuffleMapStage 7 (countByKey at ColumnProfiler.scala:566) finished in 0.898 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - waiting: Set(ResultStage 8)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - Submitting ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 10.0.184.47:34201 (size: 1924.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  YarnScheduler:54 - Adding task set 8.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 8, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on algo-1:40371 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 8) in 51 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  YarnScheduler:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - ResultStage 8 (countByKey at ColumnProfiler.scala:566) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:35 INFO  DAGScheduler:54 - Job 5 finished: countByKey at ColumnProfiler.scala:566, took 0.979214 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Registering RDD 55 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Got job 6 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[55] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 95.2 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on 10.0.184.47:34201 (size: 32.4 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  SparkContext:54 - Created broadcast 12 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[55] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  YarnScheduler:54 - Adding task set 9.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 9, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on algo-1:40371 (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 9) in 175 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  YarnScheduler:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - ShuffleMapStage 9 (collect at AnalysisRunner.scala:313) finished in 0.186 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Submitting ResultStage 10 (MapPartitionsRDD[58] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 108.0 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  YarnScheduler:54 - Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 10, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 3 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 10) in 113 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  YarnScheduler:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - ResultStage 10 (collect at AnalysisRunner.scala:313) finished in 0.128 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Job 6 finished: collect at AnalysisRunner.scala:313, took 0.326762 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  CodeGenerator:54 - Code generated in 9.983727 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Got job 7 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[67] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 55.5 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[67] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  YarnScheduler:54 - Adding task set 11.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 11, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 11) in 312 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  YarnScheduler:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - ResultStage 11 (treeReduce at KLLRunner.scala:107) finished in 0.323 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:36 INFO  DAGScheduler:54 - Job 7 finished: treeReduce at KLLRunner.scala:107, took 0.326736 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  CodeGenerator:54 - Code generated in 49.232927 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  CodeGenerator:54 - Code generated in 38.609448 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Registering RDD 72 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Got job 8 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 94.9 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 32.9 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on 10.0.184.47:34201 (size: 32.9 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Created broadcast 15 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Adding task set 12.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 12, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on algo-1:40371 (size: 32.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 12) in 142 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - ShuffleMapStage 12 (collect at AnalysisRunner.scala:313) finished in 0.152 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 13)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[75] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 54.5 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on 10.0.184.47:34201 (size: 16.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[75] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Adding task set 13.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 13, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on algo-1:40371 (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 4 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 13) in 76 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - ResultStage 13 (collect at AnalysisRunner.scala:313) finished in 0.089 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Job 8 finished: collect at AnalysisRunner.scala:313, took 0.249469 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Registering RDD 82 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Got job 9 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Final stage: ResultStage 15 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[82] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 50.0 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on 10.0.184.47:34201 (size: 20.2 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[82] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Adding task set 14.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 14.0 (TID 14, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on algo-1:40371 (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 14.0 (TID 14) in 75 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - ShuffleMapStage 14 (countByKey at ColumnProfiler.scala:566) finished in 0.090 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 15)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting ResultStage 15 (ShuffledRDD[83] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 3.2 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 1922.0 B, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on 10.0.184.47:34201 (size: 1922.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Created broadcast 18 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 15 (ShuffledRDD[83] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Adding task set 15.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 15.0 (TID 15, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on algo-1:40371 (size: 1922.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 5 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 15.0 (TID 15) in 29 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - ResultStage 15 (countByKey at ColumnProfiler.scala:566) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Job 9 finished: countByKey at ColumnProfiler.scala:566, took 0.138607 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Registering RDD 88 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Got job 10 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Final stage: ResultStage 17 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[88] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 95.2 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on 10.0.184.47:34201 (size: 32.4 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[88] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Adding task set 16.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 16.0 (TID 16, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on algo-1:40371 (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 16.0 (TID 16) in 237 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - ShuffleMapStage 16 (collect at AnalysisRunner.scala:313) finished in 0.253 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 17)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting ResultStage 17 (MapPartitionsRDD[91] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 108.0 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 36.6 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on 10.0.184.47:34201 (size: 36.6 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  SparkContext:54 - Created broadcast 20 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[91] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  YarnScheduler:54 - Adding task set 17.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 17.0 (TID 17, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on algo-1:40371 (size: 36.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:37 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 6 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 17.0 (TID 17) in 156 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  YarnScheduler:54 - Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - ResultStage 17 (collect at AnalysisRunner.scala:313) finished in 0.184 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Job 10 finished: collect at AnalysisRunner.scala:313, took 0.445770 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  CodeGenerator:54 - Code generated in 12.729418 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Got job 11 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Final stage: ResultStage 18 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Submitting ResultStage 18 (MapPartitionsRDD[100] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 55.5 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  SparkContext:54 - Created broadcast 21 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[100] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  YarnScheduler:54 - Adding task set 18.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 18.0 (TID 18, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 18.0 (TID 18) in 291 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  YarnScheduler:54 - Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - ResultStage 18 (treeReduce at KLLRunner.scala:107) finished in 0.302 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Job 11 finished: treeReduce at KLLRunner.scala:107, took 0.307489 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 219\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 415\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 483\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 384\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 503\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 556\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 253\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 393\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 568\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on algo-1:40371 in memory (size: 32.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on 10.0.184.47:34201 in memory (size: 32.9 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 454\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 448\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 300\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 517\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 196\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 227\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 499\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 395\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 272\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 541\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 181\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 206\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 193\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 578\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 519\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 480\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 479\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 513\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 256\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 349\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 342\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 419\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 320\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 411\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 250\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 177\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 257\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 307\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 495\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 389\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 528\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 306\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 354\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 234\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 180\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 226\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 458\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 476\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on 10.0.184.47:34201 in memory (size: 1922.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_18_piece0 on algo-1:40371 in memory (size: 1922.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 453\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 264\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 569\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 314\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 486\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 190\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 213\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 347\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 199\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 274\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 343\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 379\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 205\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 260\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 270\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 362\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 370\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 387\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 408\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 231\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 317\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 340\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 367\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_21_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 538\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 433\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 285\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  CodeGenerator:54 - Code generated in 47.795947 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 402\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 471\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 461\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 338\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 286\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 345\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 521\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 308\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 323\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 489\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 330\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on 10.0.184.47:34201 in memory (size: 16.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_16_piece0 on algo-1:40371 in memory (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 187\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 278\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 456\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 543\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 372\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 299\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 357\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 535\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 424\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 526\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 339\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 333\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 423\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 399\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 341\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 363\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 192\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 559\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 232\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Registering RDD 105 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Got job 12 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Final stage: ResultStage 20 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned shuffle 2\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[105] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 445\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 539\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 209\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 288\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 434\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 350\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 462\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 498\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 344\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 504\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 328\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 375\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 94.9 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 435\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 575\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 512\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 212\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 501\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 534\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 197\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 210\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 318\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 351\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 410\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 194\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 203\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 261\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 282\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 469\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 545\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 32.9 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on 10.0.184.47:34201 (size: 32.9 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 373\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 459\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 579\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 322\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 248\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 271\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  SparkContext:54 - Created broadcast 22 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[105] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  YarnScheduler:54 - Adding task set 19.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 284\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 368\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 442\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 515\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 403\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 290\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 482\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 236\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 465\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 549\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 244\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 19.0 (TID 19, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on 10.0.184.47:34201 in memory (size: 32.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on algo-1:40371 in memory (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on algo-1:40371 (size: 32.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned shuffle 1\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 327\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 246\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 508\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 567\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 329\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 500\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 182\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 225\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 302\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 422\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 536\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 359\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 204\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 220\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 455\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 533\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 550\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 243\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 296\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 520\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 269\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 540\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 496\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 518\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 560\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 572\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 315\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 255\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 421\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 353\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 507\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 331\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 398\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 443\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 396\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 492\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 506\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 452\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 258\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 463\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 385\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 416\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 563\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 185\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 275\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned shuffle 3\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 542\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 522\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 240\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 364\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 502\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 451\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 571\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 297\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 514\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 531\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 298\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 464\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 292\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 249\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 235\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 251\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 394\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 358\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 291\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 198\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 468\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 188\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 239\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 381\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 436\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 245\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 233\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 576\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 215\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 477\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 484\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 472\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 494\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 191\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 525\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 562\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 511\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 487\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 221\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 252\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 305\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 335\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 437\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 10.0.184.47:34201 in memory (size: 1924.0 B, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on algo-1:40371 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 208\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 401\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 397\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 216\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 406\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 449\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 475\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 326\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 405\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 428\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 229\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 241\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 407\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned shuffle 6\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 417\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 523\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 532\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 337\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 382\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 228\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 392\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 316\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 386\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 548\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 429\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 280\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 440\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 537\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 376\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 238\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 510\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 450\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 281\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 276\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 211\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 303\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 324\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 374\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 277\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 178\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 360\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 369\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 438\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 254\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 366\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 558\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 355\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 426\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 273\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 409\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 295\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 267\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 481\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned shuffle 4\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 348\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 467\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 293\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 230\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on 10.0.184.47:34201 in memory (size: 36.6 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on algo-1:40371 in memory (size: 36.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 265\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 516\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 565\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 497\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 287\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 570\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 371\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 346\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 547\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 555\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 304\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 557\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 259\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 356\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 527\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 311\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 529\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 404\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on 10.0.184.47:34201 in memory (size: 20.2 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_17_piece0 on algo-1:40371 in memory (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 179\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 237\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 439\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 420\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 431\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 447\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 289\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 554\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 418\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 544\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 294\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 490\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 309\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 217\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 564\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 310\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 195\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 352\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 279\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 380\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 214\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 10.0.184.47:34201 in memory (size: 20.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on algo-1:40371 in memory (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 473\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 334\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 412\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 200\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 441\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 186\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 577\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 491\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 466\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 574\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 427\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 485\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 391\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 361\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 378\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 546\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 268\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned shuffle 5\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 474\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 388\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 266\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 336\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 312\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 493\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 457\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 224\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 202\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 425\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 319\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 470\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 444\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 10.0.184.47:34201 in memory (size: 32.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on algo-1:40371 in memory (size: 32.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 413\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 446\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 207\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 247\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 377\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 301\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 573\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 383\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 189\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 222\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 365\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 263\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 432\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 400\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 184\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 505\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 488\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 524\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 321\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 430\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 460\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 509\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 283\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 530\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 325\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 183\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 10.0.184.47:34201 in memory (size: 16.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on algo-1:40371 in memory (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 242\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 390\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 414\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 561\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 218\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 262\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 478\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 201\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 332\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on 10.0.184.47:34201 in memory (size: 32.4 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on algo-1:40371 in memory (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  ContextCleaner:54 - Cleaned accumulator 223\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  TaskSetManager:54 - Finished task 0.0 in stage 19.0 (TID 19) in 174 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  YarnScheduler:54 - Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - ShuffleMapStage 19 (collect at AnalysisRunner.scala:313) finished in 0.193 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - waiting: Set(ResultStage 20)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  DAGScheduler:54 - Submitting ResultStage 20 (MapPartitionsRDD[108] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:38 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 54.5 KB, free 1456.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1456.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on 10.0.184.47:34201 (size: 16.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[108] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Adding task set 20.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 20.0 (TID 20, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on algo-1:40371 (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 7 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 20.0 (TID 20) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - ResultStage 20 (collect at AnalysisRunner.scala:313) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Job 12 finished: collect at AnalysisRunner.scala:313, took 0.240217 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Registering RDD 115 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Got job 13 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Final stage: ResultStage 22 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 21 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 50.0 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.1 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on 10.0.184.47:34201 (size: 20.1 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Created broadcast 24 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Adding task set 21.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 21.0 (TID 21, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on algo-1:40371 (size: 20.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 21.0 (TID 21) in 71 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - ShuffleMapStage 21 (countByKey at ColumnProfiler.scala:566) finished in 0.082 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 22)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting ResultStage 22 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 3.2 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Removed TaskSet 21.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on 10.0.184.47:34201 (size: 1924.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Created broadcast 25 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 22 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Adding task set 22.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 22.0 (TID 22, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on algo-1:40371 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 8 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 22.0 (TID 22) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - ResultStage 22 (countByKey at ColumnProfiler.scala:566) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Job 13 finished: countByKey at ColumnProfiler.scala:566, took 0.124480 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Registering RDD 121 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Got job 14 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Final stage: ResultStage 24 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 23 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 95.2 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on 10.0.184.47:34201 (size: 32.4 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Created broadcast 26 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Adding task set 23.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 23.0 (TID 23, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on algo-1:40371 (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 23.0 (TID 23) in 180 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - ShuffleMapStage 23 (collect at AnalysisRunner.scala:313) finished in 0.194 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 24)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting ResultStage 24 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 108.3 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Created broadcast 27 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Adding task set 24.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 24.0 (TID 24, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 9 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 24.0 (TID 24) in 134 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - ResultStage 24 (collect at AnalysisRunner.scala:313) finished in 0.146 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Job 14 finished: collect at AnalysisRunner.scala:313, took 0.345340 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  CodeGenerator:54 - Code generated in 10.257517 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Got job 15 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Final stage: ResultStage 25 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting ResultStage 25 (MapPartitionsRDD[133] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_28 stored as values in memory (estimated size 55.3 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  MemoryStore:54 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  SparkContext:54 - Created broadcast 28 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[133] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Adding task set 25.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 25.0 (TID 25, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  BlockManagerInfo:54 - Added broadcast_28_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 25.0 (TID 25) in 181 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  YarnScheduler:54 - Removed TaskSet 25.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - ResultStage 25 (treeReduce at KLLRunner.scala:107) finished in 0.197 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:39 INFO  DAGScheduler:54 - Job 15 finished: treeReduce at KLLRunner.scala:107, took 0.207868 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  CodeGenerator:54 - Code generated in 58.251439 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  CodeGenerator:54 - Code generated in 33.351175 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Registering RDD 138 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Got job 16 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Final stage: ResultStage 27 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 26)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 26)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 26 (MapPartitionsRDD[138] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_29 stored as values in memory (estimated size 93.8 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 32.6 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on 10.0.184.47:34201 (size: 32.6 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Created broadcast 29 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[138] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Adding task set 26.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 26.0 (TID 26, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_29_piece0 in memory on algo-1:40371 (size: 32.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 26.0 (TID 26) in 177 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - ShuffleMapStage 26 (collect at AnalysisRunner.scala:313) finished in 0.200 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 27)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting ResultStage 27 (MapPartitionsRDD[141] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_30 stored as values in memory (estimated size 54.0 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on 10.0.184.47:34201 (size: 16.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Created broadcast 30 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[141] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Adding task set 27.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 27.0 (TID 27, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_30_piece0 in memory on algo-1:40371 (size: 16.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 10 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 27.0 (TID 27) in 67 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - ResultStage 27 (collect at AnalysisRunner.scala:313) finished in 0.076 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Job 16 finished: collect at AnalysisRunner.scala:313, took 0.283953 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Registering RDD 148 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Got job 17 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Final stage: ResultStage 29 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 28)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 28)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 28 (MapPartitionsRDD[148] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_31 stored as values in memory (estimated size 50.0 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.1 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on 10.0.184.47:34201 (size: 20.1 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Created broadcast 31 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[148] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Adding task set 28.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 28.0 (TID 28, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_31_piece0 in memory on algo-1:40371 (size: 20.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 28.0 (TID 28) in 57 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - ShuffleMapStage 28 (countByKey at ColumnProfiler.scala:566) finished in 0.074 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 29)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting ResultStage 29 (ShuffledRDD[149] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_32 stored as values in memory (estimated size 3.2 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on 10.0.184.47:34201 (size: 1924.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Created broadcast 32 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 29 (ShuffledRDD[149] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Adding task set 29.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 29.0 (TID 29, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_32_piece0 in memory on algo-1:40371 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 11 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 29.0 (TID 29) in 37 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - ResultStage 29 (countByKey at ColumnProfiler.scala:566) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Job 17 finished: countByKey at ColumnProfiler.scala:566, took 0.128085 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Registering RDD 154 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Got job 18 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Final stage: ResultStage 31 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 30 (MapPartitionsRDD[154] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_33 stored as values in memory (estimated size 95.2 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  MemoryStore:54 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 32.5 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on 10.0.184.47:34201 (size: 32.5 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  SparkContext:54 - Created broadcast 33 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[154] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  YarnScheduler:54 - Adding task set 30.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 30.0 (TID 30, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:40 INFO  BlockManagerInfo:54 - Added broadcast_33_piece0 in memory on algo-1:40371 (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 30.0 (TID 30) in 232 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  YarnScheduler:54 - Removed TaskSet 30.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - ShuffleMapStage 30 (collect at AnalysisRunner.scala:313) finished in 0.243 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - waiting: Set(ResultStage 31)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Submitting ResultStage 31 (MapPartitionsRDD[157] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MemoryStore:54 - Block broadcast_34 stored as values in memory (estimated size 108.1 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MemoryStore:54 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  SparkContext:54 - Created broadcast 34 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[157] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  YarnScheduler:54 - Adding task set 31.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 31.0 (TID 31, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Added broadcast_34_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 12 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 31.0 (TID 31) in 104 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  YarnScheduler:54 - Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - ResultStage 31 (collect at AnalysisRunner.scala:313) finished in 0.120 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Job 18 finished: collect at AnalysisRunner.scala:313, took 0.368203 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  CodeGenerator:54 - Code generated in 9.913602 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Got job 19 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Submitting ResultStage 32 (MapPartitionsRDD[166] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MemoryStore:54 - Block broadcast_35 stored as values in memory (estimated size 55.4 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MemoryStore:54 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  SparkContext:54 - Created broadcast 35 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[166] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  YarnScheduler:54 - Adding task set 32.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 32.0 (TID 32, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Added broadcast_35_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 32.0 (TID 32) in 232 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.241 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Job 19 finished: treeReduce at KLLRunner.scala:107, took 0.244509 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  YarnScheduler:54 - Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  CodeGenerator:54 - Code generated in 27.321048 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 660\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 911\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 698\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 648\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 724\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 757\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 694\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 649\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 686\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 604\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 814\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 816\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 966\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 858\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 736\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 584\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 770\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 687\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 769\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 803\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 830\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 663\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 744\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 762\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 981\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 775\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 753\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 641\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 806\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 631\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 875\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 629\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 726\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 923\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 720\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 829\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 785\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 903\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 977\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on 10.0.184.47:34201 in memory (size: 1924.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_32_piece0 on algo-1:40371 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 645\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 760\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 956\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 696\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 899\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 844\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 987\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 878\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 754\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 926\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 935\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 772\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 609\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 992\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 886\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 905\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 943\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 839\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 891\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 988\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 800\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 618\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 751\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 729\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 854\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 975\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_35_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 651\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 653\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 780\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 630\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 807\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 617\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 765\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 872\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 666\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 704\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 828\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 815\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 763\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 621\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 940\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 605\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 916\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 707\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 634\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 865\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 930\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 719\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 781\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 680\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 950\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 715\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 774\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 711\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 759\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 702\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 778\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_34_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 661\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 941\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 701\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 595\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned shuffle 9\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 620\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 809\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 688\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 637\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 836\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 728\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 942\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 934\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 739\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 838\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 968\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 993\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 892\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 868\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 644\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 909\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 692\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 906\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 633\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 580\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 962\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 847\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 856\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 606\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 936\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 638\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 861\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 826\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 857\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 898\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 592\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 782\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 777\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 885\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 740\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 978\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 591\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 673\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 919\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 764\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 951\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 776\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 812\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 908\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 901\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on 10.0.184.47:34201 in memory (size: 20.1 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_24_piece0 on algo-1:40371 in memory (size: 20.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  CodeGenerator:54 - Code generated in 58.977104 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 840\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 949\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 608\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 889\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 811\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 813\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned shuffle 10\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 867\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 551\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 723\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on 10.0.184.47:34201 in memory (size: 16.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_30_piece0 on algo-1:40371 in memory (size: 16.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Registering RDD 171 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Got job 20 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Final stage: ResultStage 34 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 33)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 33)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 612\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 33 (MapPartitionsRDD[171] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_28_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MemoryStore:54 - Block broadcast_36 stored as values in memory (estimated size 94.3 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 685\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 819\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 912\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 925\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 997\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 792\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 841\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 745\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 731\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 622\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 600\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 603\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 697\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 722\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 888\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 994\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 730\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 771\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 747\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 658\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 965\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  MemoryStore:54 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 32.8 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 693\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 721\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 825\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 866\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on 10.0.184.47:34201 (size: 32.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 880\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 945\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 895\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 599\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  SparkContext:54 - Created broadcast 36 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on 10.0.184.47:34201 in memory (size: 32.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_26_piece0 on algo-1:40371 in memory (size: 32.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[171] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 874\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 766\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 984\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 791\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 787\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 902\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 713\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 798\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 796\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  YarnScheduler:54 - Adding task set 33.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned shuffle 7\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 817\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 842\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 859\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 917\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 870\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 642\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 913\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 725\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 750\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 832\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 650\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 804\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 976\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 590\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 810\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 973\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 691\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 823\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 820\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 833\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 818\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 790\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 671\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 607\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 589\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 588\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 667\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 797\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 946\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 822\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 758\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 850\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 735\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on 10.0.184.47:34201 in memory (size: 16.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_23_piece0 on algo-1:40371 in memory (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 33.0 (TID 33, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 734\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 931\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 586\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 662\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 768\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 827\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 732\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 955\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 756\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 989\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 972\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 849\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 855\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 710\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 991\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 647\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 678\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 871\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 598\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 881\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 716\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 922\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 851\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 675\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 738\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 654\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 957\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 845\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 664\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 873\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 995\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 985\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 953\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 784\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 960\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 996\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 684\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 625\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 802\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 656\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 733\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 893\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 789\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 714\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 846\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 676\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 552\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 646\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 958\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 794\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 742\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 681\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 752\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 583\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 619\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on 10.0.184.47:34201 in memory (size: 32.9 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_22_piece0 on algo-1:40371 in memory (size: 32.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Added broadcast_36_piece0 in memory on algo-1:40371 (size: 32.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 659\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 929\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 674\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 883\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 980\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 708\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 990\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 601\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 805\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 967\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 611\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 801\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 585\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 954\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 743\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 848\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 682\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 884\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 928\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 623\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 986\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 863\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 761\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 727\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 616\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 974\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned shuffle 8\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 690\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_27_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 897\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 712\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 788\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 914\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 918\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 748\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 773\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 933\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 952\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 877\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 862\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 927\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 706\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 795\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 593\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 695\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 837\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned shuffle 11\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 831\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 596\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 963\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 937\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 615\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 808\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 652\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 924\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 582\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 864\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 683\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 610\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 843\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 835\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 636\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 869\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 982\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 700\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 894\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 709\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 613\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 587\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on 10.0.184.47:34201 in memory (size: 1924.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_25_piece0 on algo-1:40371 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 639\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 890\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 741\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 602\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 614\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 944\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 594\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 628\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 932\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 852\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 643\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 779\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 915\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 793\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 938\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 632\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 640\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 669\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 853\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 824\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 860\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 672\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 581\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned shuffle 12\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 896\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 939\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 921\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 907\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 799\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 635\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 718\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 979\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 961\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 699\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 767\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 655\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 657\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on 10.0.184.47:34201 in memory (size: 32.5 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_33_piece0 on algo-1:40371 in memory (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 959\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 821\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 746\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 910\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 737\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 900\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 887\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 983\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 705\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 783\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 665\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 677\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 703\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 879\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 553\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 947\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 624\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 786\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 964\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 670\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 755\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 834\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 626\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 627\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on 10.0.184.47:34201 in memory (size: 32.6 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_29_piece0 on algo-1:40371 in memory (size: 32.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 876\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 904\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 948\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on 10.0.184.47:34201 in memory (size: 20.1 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  BlockManagerInfo:54 - Removed broadcast_31_piece0 on algo-1:40371 in memory (size: 20.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 679\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 668\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 689\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 597\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 717\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 920\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 882\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:41 INFO  ContextCleaner:54 - Cleaned accumulator 749\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 33.0 (TID 33) in 220 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - ShuffleMapStage 33 (collect at AnalysisRunner.scala:313) finished in 0.243 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - waiting: Set(ResultStage 34)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting ResultStage 34 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_37 stored as values in memory (estimated size 54.3 KB, free 1456.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_37_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1456.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on 10.0.184.47:34201 (size: 16.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Created broadcast 37 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Adding task set 34.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 34.0 (TID 34, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_37_piece0 in memory on algo-1:40371 (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 13 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 34.0 (TID 34) in 71 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Removed TaskSet 34.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - ResultStage 34 (collect at AnalysisRunner.scala:313) finished in 0.083 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Job 20 finished: collect at AnalysisRunner.scala:313, took 0.338292 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Registering RDD 181 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Got job 21 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Final stage: ResultStage 36 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 35)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 35)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 35 (MapPartitionsRDD[181] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_38 stored as values in memory (estimated size 50.0 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_38_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on 10.0.184.47:34201 (size: 20.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Created broadcast 38 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[181] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Adding task set 35.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 35.0 (TID 35, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_38_piece0 in memory on algo-1:40371 (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 35.0 (TID 35) in 87 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - ShuffleMapStage 35 (countByKey at ColumnProfiler.scala:566) finished in 0.099 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - waiting: Set(ResultStage 36)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting ResultStage 36 (ShuffledRDD[182] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_39 stored as values in memory (estimated size 3.2 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_39_piece0 stored as bytes in memory (estimated size 1925.0 B, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on 10.0.184.47:34201 (size: 1925.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Created broadcast 39 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 36 (ShuffledRDD[182] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Adding task set 36.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 36.0 (TID 36, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_39_piece0 in memory on algo-1:40371 (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 14 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 36.0 (TID 36) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - ResultStage 36 (countByKey at ColumnProfiler.scala:566) finished in 0.032 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Job 21 finished: countByKey at ColumnProfiler.scala:566, took 0.138216 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Registering RDD 187 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Got job 22 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Final stage: ResultStage 38 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 37)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 37)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 37 (MapPartitionsRDD[187] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_40 stored as values in memory (estimated size 95.2 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_40_piece0 stored as bytes in memory (estimated size 32.5 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on 10.0.184.47:34201 (size: 32.5 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Created broadcast 40 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[187] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Adding task set 37.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 37.0 (TID 37, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_40_piece0 in memory on algo-1:40371 (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 37.0 (TID 37) in 348 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Removed TaskSet 37.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - ShuffleMapStage 37 (collect at AnalysisRunner.scala:313) finished in 0.359 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - waiting: Set(ResultStage 38)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting ResultStage 38 (MapPartitionsRDD[190] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_41 stored as values in memory (estimated size 108.1 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MemoryStore:54 - Block broadcast_41_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  SparkContext:54 - Created broadcast 41 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[190] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Adding task set 38.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 38.0 (TID 38, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  BlockManagerInfo:54 - Added broadcast_41_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 15 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 38.0 (TID 38) in 81 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  YarnScheduler:54 - Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - ResultStage 38 (collect at AnalysisRunner.scala:313) finished in 0.089 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:42 INFO  DAGScheduler:54 - Job 22 finished: collect at AnalysisRunner.scala:313, took 0.451712 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  CodeGenerator:54 - Code generated in 9.225661 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Got job 23 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Final stage: ResultStage 39 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting ResultStage 39 (MapPartitionsRDD[199] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_42 stored as values in memory (estimated size 55.3 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_42_piece0 stored as bytes in memory (estimated size 21.7 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on 10.0.184.47:34201 (size: 21.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Created broadcast 42 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[199] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Adding task set 39.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 39.0 (TID 39, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_42_piece0 in memory on algo-1:40371 (size: 21.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 39.0 (TID 39) in 162 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Removed TaskSet 39.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - ResultStage 39 (treeReduce at KLLRunner.scala:107) finished in 0.170 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Job 23 finished: treeReduce at KLLRunner.scala:107, took 0.173589 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  CodeGenerator:54 - Code generated in 34.631493 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  CodeGenerator:54 - Code generated in 18.907159 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Registering RDD 204 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Got job 24 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Final stage: ResultStage 41 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 40)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 40)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 40 (MapPartitionsRDD[204] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_43 stored as values in memory (estimated size 93.8 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_43_piece0 stored as bytes in memory (estimated size 32.6 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on 10.0.184.47:34201 (size: 32.6 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Created broadcast 43 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[204] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Adding task set 40.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 40.0 (TID 40, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_43_piece0 in memory on algo-1:40371 (size: 32.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 40.0 (TID 40) in 110 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - ShuffleMapStage 40 (collect at AnalysisRunner.scala:313) finished in 0.118 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 41)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting ResultStage 41 (MapPartitionsRDD[207] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_44 stored as values in memory (estimated size 54.0 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on 10.0.184.47:34201 (size: 16.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Created broadcast 44 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[207] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Adding task set 41.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 41.0 (TID 41, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_44_piece0 in memory on algo-1:40371 (size: 16.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 16 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 41.0 (TID 41) in 64 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - ResultStage 41 (collect at AnalysisRunner.scala:313) finished in 0.073 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Job 24 finished: collect at AnalysisRunner.scala:313, took 0.198740 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Registering RDD 214 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Got job 25 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Final stage: ResultStage 43 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 42)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 42)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 42 (MapPartitionsRDD[214] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_45 stored as values in memory (estimated size 50.0 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_45_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on 10.0.184.47:34201 (size: 20.2 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Created broadcast 45 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[214] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Adding task set 42.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 42.0 (TID 42, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_45_piece0 in memory on algo-1:40371 (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 42.0 (TID 42) in 68 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - ShuffleMapStage 42 (countByKey at ColumnProfiler.scala:566) finished in 0.087 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 43)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting ResultStage 43 (ShuffledRDD[215] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_46 stored as values in memory (estimated size 3.2 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_46_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on 10.0.184.47:34201 (size: 1924.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Created broadcast 46 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 43 (ShuffledRDD[215] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Adding task set 43.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 43.0 (TID 43, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_46_piece0 in memory on algo-1:40371 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 17 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 43.0 (TID 43) in 23 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Removed TaskSet 43.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - ResultStage 43 (countByKey at ColumnProfiler.scala:566) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Job 25 finished: countByKey at ColumnProfiler.scala:566, took 0.134880 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Registering RDD 220 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Got job 26 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Final stage: ResultStage 45 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 44)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 44)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 44 (MapPartitionsRDD[220] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_47 stored as values in memory (estimated size 95.2 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  MemoryStore:54 - Block broadcast_47_piece0 stored as bytes in memory (estimated size 32.5 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on 10.0.184.47:34201 (size: 32.5 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  SparkContext:54 - Created broadcast 47 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[220] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  YarnScheduler:54 - Adding task set 44.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 44.0 (TID 44, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:43 INFO  BlockManagerInfo:54 - Added broadcast_47_piece0 in memory on algo-1:40371 (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 44.0 (TID 44) in 138 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - ShuffleMapStage 44 (collect at AnalysisRunner.scala:313) finished in 0.148 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - waiting: Set(ResultStage 45)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting ResultStage 45 (MapPartitionsRDD[223] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_48 stored as values in memory (estimated size 108.1 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_48_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Created broadcast 48 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[223] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Adding task set 45.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 45.0 (TID 45, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_48_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 18 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 45.0 (TID 45) in 93 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - ResultStage 45 (collect at AnalysisRunner.scala:313) finished in 0.102 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Job 26 finished: collect at AnalysisRunner.scala:313, took 0.253875 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  CodeGenerator:54 - Code generated in 8.278925 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Got job 27 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Final stage: ResultStage 46 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting ResultStage 46 (MapPartitionsRDD[232] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_49 stored as values in memory (estimated size 55.4 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_49_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Created broadcast 49 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[232] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Adding task set 46.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 46.0 (TID 46, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_49_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 46.0 (TID 46) in 323 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - ResultStage 46 (treeReduce at KLLRunner.scala:107) finished in 0.330 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Job 27 finished: treeReduce at KLLRunner.scala:107, took 0.332820 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  CodeGenerator:54 - Code generated in 31.407886 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  CodeGenerator:54 - Code generated in 29.115328 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Registering RDD 237 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Got job 28 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Final stage: ResultStage 48 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 47)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 47)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 47 (MapPartitionsRDD[237] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_50 stored as values in memory (estimated size 94.3 KB, free 1455.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_50_piece0 stored as bytes in memory (estimated size 32.9 KB, free 1455.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on 10.0.184.47:34201 (size: 32.9 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Created broadcast 50 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[237] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Adding task set 47.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 47.0 (TID 47, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_50_piece0 in memory on algo-1:40371 (size: 32.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 47.0 (TID 47) in 80 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - ShuffleMapStage 47 (collect at AnalysisRunner.scala:313) finished in 0.088 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - waiting: Set(ResultStage 48)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting ResultStage 48 (MapPartitionsRDD[240] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_51 stored as values in memory (estimated size 54.3 KB, free 1455.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_51_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1455.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on 10.0.184.47:34201 (size: 16.7 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Created broadcast 51 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[240] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Adding task set 48.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 48.0 (TID 48, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_51_piece0 in memory on algo-1:40371 (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 19 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Finished task 0.0 in stage 48.0 (TID 48) in 56 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Removed TaskSet 48.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - ResultStage 48 (collect at AnalysisRunner.scala:313) finished in 0.066 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Job 28 finished: collect at AnalysisRunner.scala:313, took 0.158166 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Registering RDD 247 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Got job 29 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Final stage: ResultStage 50 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 49)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 49)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 49 (MapPartitionsRDD[247] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_52 stored as values in memory (estimated size 50.0 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  MemoryStore:54 - Block broadcast_52_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on 10.0.184.47:34201 (size: 20.2 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  SparkContext:54 - Created broadcast 52 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[247] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  YarnScheduler:54 - Adding task set 49.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:44 INFO  TaskSetManager:54 - Starting task 0.0 in stage 49.0 (TID 49, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_52_piece0 in memory on algo-1:40371 (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 49.0 (TID 49) in 46 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - ShuffleMapStage 49 (countByKey at ColumnProfiler.scala:566) finished in 0.055 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 50)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting ResultStage 50 (ShuffledRDD[248] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_53 stored as values in memory (estimated size 3.2 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_53_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on 10.0.184.47:34201 (size: 1924.0 B, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  SparkContext:54 - Created broadcast 53 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 50 (ShuffledRDD[248] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Adding task set 50.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 50.0 (TID 50, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_53_piece0 in memory on algo-1:40371 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 20 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 50.0 (TID 50) in 17 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Removed TaskSet 50.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - ResultStage 50 (countByKey at ColumnProfiler.scala:566) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Job 29 finished: countByKey at ColumnProfiler.scala:566, took 0.081474 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Registering RDD 253 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Got job 30 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Final stage: ResultStage 52 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 51)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 51)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 51 (MapPartitionsRDD[253] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_54 stored as values in memory (estimated size 95.2 KB, free 1455.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_54_piece0 stored as bytes in memory (estimated size 32.5 KB, free 1455.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on 10.0.184.47:34201 (size: 32.5 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  SparkContext:54 - Created broadcast 54 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[253] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Adding task set 51.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 51.0 (TID 51, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_54_piece0 in memory on algo-1:40371 (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 51.0 (TID 51) in 159 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Removed TaskSet 51.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - ShuffleMapStage 51 (collect at AnalysisRunner.scala:313) finished in 0.171 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 52)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting ResultStage 52 (MapPartitionsRDD[256] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_55 stored as values in memory (estimated size 108.2 KB, free 1455.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1089\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_55_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1455.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_49_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  SparkContext:54 - Created broadcast 55 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[256] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Adding task set 52.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1175\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1531\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1000\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1304\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1263\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1317\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1238\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1022\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1012\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 52.0 (TID 52, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1215\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1116\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1227\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1284\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1256\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1274\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1110\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1139\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on 10.0.184.47:34201 in memory (size: 32.9 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_50_piece0 on algo-1:40371 in memory (size: 32.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1102\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1312\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1405\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1163\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1060\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1416\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_55_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_41_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1449\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1161\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1336\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 971\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1358\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1309\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1381\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1294\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1045\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1019\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1326\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1271\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1248\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1188\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1146\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1181\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1421\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1130\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1230\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1390\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1486\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1050\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1057\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1401\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1156\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on 10.0.184.47:34201 in memory (size: 20.2 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_52_piece0 on algo-1:40371 in memory (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 21 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1225\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1505\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1113\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_48_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1149\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1187\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1362\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1394\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1140\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1222\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1018\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1072\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1403\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1118\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1302\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1152\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1389\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1036\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1023\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1470\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1437\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1127\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1042\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1084\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1151\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1266\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1217\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1221\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1417\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1464\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1462\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1114\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1209\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1303\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 969\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1002\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1306\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1092\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1169\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1514\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1419\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1235\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1526\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1404\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1257\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1402\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on 10.0.184.47:34201 in memory (size: 1924.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_46_piece0 on algo-1:40371 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1377\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1457\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1393\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on 10.0.184.47:34201 in memory (size: 32.5 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_47_piece0 on algo-1:40371 in memory (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1080\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1351\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1277\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1237\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1189\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1508\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1442\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1458\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1299\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1334\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1363\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1472\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1427\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1085\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1444\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1088\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1519\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1004\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1475\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1040\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1259\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1200\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 13\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1250\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1195\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1249\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1005\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1268\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1443\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 17\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on 10.0.184.47:34201 in memory (size: 32.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_36_piece0 on algo-1:40371 in memory (size: 32.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1321\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1504\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1079\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1447\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1445\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 16\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1343\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1298\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1071\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 998\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1454\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1423\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1308\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1370\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1382\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1364\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1193\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1407\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1109\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1233\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1125\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1111\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1275\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1368\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1398\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1106\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1511\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1350\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1112\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1497\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1055\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1288\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1461\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1523\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1310\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1017\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1374\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1137\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1483\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1245\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1372\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1307\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1385\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1252\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1069\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1011\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1365\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1323\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1155\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1162\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1467\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1108\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1295\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1428\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1439\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1219\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1095\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1272\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1008\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1383\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on 10.0.184.47:34201 in memory (size: 16.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_37_piece0 on algo-1:40371 in memory (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1480\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1211\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1091\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1459\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1400\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1496\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1436\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1035\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1032\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1150\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1281\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1148\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1333\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 15\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1201\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1246\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1384\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1058\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on 10.0.184.47:34201 in memory (size: 1925.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_39_piece0 on algo-1:40371 in memory (size: 1925.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1218\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1119\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1205\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1476\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1320\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1014\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1099\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1094\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1178\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1481\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1507\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1353\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1337\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1124\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1474\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1172\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1466\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1452\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1453\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1292\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1327\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1456\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1015\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1261\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1509\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1232\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1283\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1529\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1190\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1214\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1418\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1289\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1346\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1138\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1386\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1314\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1220\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1240\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1516\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 20\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1159\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1319\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1206\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on 10.0.184.47:34201 in memory (size: 32.5 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_40_piece0 on algo-1:40371 in memory (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1425\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1216\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1471\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1075\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1279\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1177\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1395\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1413\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1212\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 999\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on 10.0.184.47:34201 in memory (size: 21.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_42_piece0 on algo-1:40371 in memory (size: 21.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1332\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1260\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1478\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1136\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on 10.0.184.47:34201 in memory (size: 1924.0 B, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_53_piece0 on algo-1:40371 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1241\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1204\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1100\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1198\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1513\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1269\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1530\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1073\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1499\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1226\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1171\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1010\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1285\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1199\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1093\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1020\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1357\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1406\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1180\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1411\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1247\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1154\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1157\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1213\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1053\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1192\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1168\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1488\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1066\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1311\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1482\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1525\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1296\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1328\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1077\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1276\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1338\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1521\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1061\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1076\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1345\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1510\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1134\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1025\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1059\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1493\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1244\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1027\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1422\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1524\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1373\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1409\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1103\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1360\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1396\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1376\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1379\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1028\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1203\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1415\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1479\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1512\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1434\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1293\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 970\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1029\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1054\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1006\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1347\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1473\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1179\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1101\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1223\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1433\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 18\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1506\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1229\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1527\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1026\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1430\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1477\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1366\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1165\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1431\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1322\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1287\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1375\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1441\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1267\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1003\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1009\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1265\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1243\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1501\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1063\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1330\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1278\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1231\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1282\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1087\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1410\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1518\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1354\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1435\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1083\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1208\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1224\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1361\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1173\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1335\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1522\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1038\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1371\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1258\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1142\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1491\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1141\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1251\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1465\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1498\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1143\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1133\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1158\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1324\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1391\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1318\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1494\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1236\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1305\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1048\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1325\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1451\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1316\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1352\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1033\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1122\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1286\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1013\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1176\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1145\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1184\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1487\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1197\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1043\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1049\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1399\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1047\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1455\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1446\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1432\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1291\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on 10.0.184.47:34201 in memory (size: 16.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_51_piece0 on algo-1:40371 in memory (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1239\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1210\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1128\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1515\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1062\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on 10.0.184.47:34201 in memory (size: 16.4 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_44_piece0 on algo-1:40371 in memory (size: 16.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1500\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1041\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1290\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1392\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1414\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1340\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1255\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1170\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1348\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1429\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 14\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1420\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1367\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1121\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1342\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1096\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1147\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1135\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1067\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1051\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1344\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1030\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1131\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1460\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1234\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1253\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1329\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1339\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1440\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1097\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1160\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1126\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1007\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1489\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1517\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1503\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1270\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1182\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned shuffle 19\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1448\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1273\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1056\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1297\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1485\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1202\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1185\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1016\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1065\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1153\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1408\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1463\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1207\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1129\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1031\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1070\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1144\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1359\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1495\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1242\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1490\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1492\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1397\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1098\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1450\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1264\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1104\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1369\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1520\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1044\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1024\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1052\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1380\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1132\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1341\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1355\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1301\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1105\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1356\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on 10.0.184.47:34201 in memory (size: 32.6 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_43_piece0 on algo-1:40371 in memory (size: 32.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1194\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1331\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1280\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1037\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1115\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1469\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1388\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1064\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1068\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1387\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1001\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1046\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1262\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1183\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1412\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1164\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1315\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1086\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1426\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1082\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1186\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1532\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1034\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1484\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1468\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1166\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1424\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1167\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1196\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1528\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1228\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1074\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1502\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1174\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1254\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1300\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1438\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on 10.0.184.47:34201 in memory (size: 20.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_45_piece0 on algo-1:40371 in memory (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on 10.0.184.47:34201 in memory (size: 20.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Removed broadcast_38_piece0 on algo-1:40371 in memory (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1349\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1378\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1117\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1191\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1021\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1120\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1123\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1081\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  ContextCleaner:54 - Cleaned accumulator 1090\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 52.0 (TID 52) in 127 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Removed TaskSet 52.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - ResultStage 52 (collect at AnalysisRunner.scala:313) finished in 0.163 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Job 30 finished: collect at AnalysisRunner.scala:313, took 0.339175 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  CodeGenerator:54 - Code generated in 8.908686 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Got job 31 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Final stage: ResultStage 53 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting ResultStage 53 (MapPartitionsRDD[265] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_56 stored as values in memory (estimated size 55.4 KB, free 1456.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  MemoryStore:54 - Block broadcast_56_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  SparkContext:54 - Created broadcast 56 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[265] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Adding task set 53.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 53.0 (TID 53, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  BlockManagerInfo:54 - Added broadcast_56_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 53.0 (TID 53) in 241 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  YarnScheduler:54 - Removed TaskSet 53.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - ResultStage 53 (treeReduce at KLLRunner.scala:107) finished in 0.250 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  DAGScheduler:54 - Job 31 finished: treeReduce at KLLRunner.scala:107, took 0.251856 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:45 INFO  CodeGenerator:54 - Code generated in 23.357831 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Registering RDD 270 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Got job 32 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Final stage: ResultStage 55 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 54 (MapPartitionsRDD[270] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_57 stored as values in memory (estimated size 94.3 KB, free 1456.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_57_piece0 stored as bytes in memory (estimated size 32.8 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on 10.0.184.47:34201 (size: 32.8 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Created broadcast 57 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[270] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Adding task set 54.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 54.0 (TID 54, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_57_piece0 in memory on algo-1:40371 (size: 32.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 54.0 (TID 54) in 124 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - ShuffleMapStage 54 (collect at AnalysisRunner.scala:313) finished in 0.130 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Removed TaskSet 54.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - waiting: Set(ResultStage 55)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting ResultStage 55 (MapPartitionsRDD[273] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_58 stored as values in memory (estimated size 54.3 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_58_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1456.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on 10.0.184.47:34201 (size: 16.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Created broadcast 58 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[273] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Adding task set 55.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 55.0 (TID 55, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_58_piece0 in memory on algo-1:40371 (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 22 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 55.0 (TID 55) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - ResultStage 55 (collect at AnalysisRunner.scala:313) finished in 0.031 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Removed TaskSet 55.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Job 32 finished: collect at AnalysisRunner.scala:313, took 0.167795 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Registering RDD 278 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Got job 33 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Final stage: ResultStage 57 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 56)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 56)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 56 (MapPartitionsRDD[278] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_59 stored as values in memory (estimated size 95.2 KB, free 1456.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_59_piece0 stored as bytes in memory (estimated size 32.5 KB, free 1456.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on 10.0.184.47:34201 (size: 32.5 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Created broadcast 59 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[278] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Adding task set 56.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 56.0 (TID 56, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_59_piece0 in memory on algo-1:40371 (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 56.0 (TID 56) in 234 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Removed TaskSet 56.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - ShuffleMapStage 56 (collect at AnalysisRunner.scala:313) finished in 0.244 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - waiting: Set(ResultStage 57)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting ResultStage 57 (MapPartitionsRDD[281] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_60 stored as values in memory (estimated size 108.0 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_60_piece0 stored as bytes in memory (estimated size 36.7 KB, free 1456.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on 10.0.184.47:34201 (size: 36.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Created broadcast 60 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[281] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Adding task set 57.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 57.0 (TID 57, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_60_piece0 in memory on algo-1:40371 (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 23 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Finished task 0.0 in stage 57.0 (TID 57) in 103 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Removed TaskSet 57.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - ResultStage 57 (collect at AnalysisRunner.scala:313) finished in 0.113 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Job 33 finished: collect at AnalysisRunner.scala:313, took 0.364219 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  CodeGenerator:54 - Code generated in 21.96671 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Got job 34 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Final stage: ResultStage 58 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting ResultStage 58 (MapPartitionsRDD[290] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_61 stored as values in memory (estimated size 55.6 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  MemoryStore:54 - Block broadcast_61_piece0 stored as bytes in memory (estimated size 21.8 KB, free 1455.9 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on 10.0.184.47:34201 (size: 21.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  SparkContext:54 - Created broadcast 61 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[290] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  YarnScheduler:54 - Adding task set 58.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 58.0 (TID 58, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:46 INFO  BlockManagerInfo:54 - Added broadcast_61_piece0 in memory on algo-1:40371 (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 58.0 (TID 58) in 168 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 58.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ResultStage 58 (treeReduce at KLLRunner.scala:107) finished in 0.177 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Job 34 finished: treeReduce at KLLRunner.scala:107, took 0.180463 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  CodeGenerator:54 - Code generated in 23.177584 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  CodeGenerator:54 - Code generated in 18.818549 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Registering RDD 295 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Got job 35 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Final stage: ResultStage 60 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 59)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 59)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 59 (MapPartitionsRDD[295] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_62 stored as values in memory (estimated size 95.4 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_62_piece0 stored as bytes in memory (estimated size 33.2 KB, free 1455.8 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on 10.0.184.47:34201 (size: 33.2 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 62 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[295] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 59.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 59.0 (TID 59, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_62_piece0 in memory on algo-1:40371 (size: 33.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 59.0 (TID 59) in 92 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 59.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ShuffleMapStage 59 (collect at AnalysisRunner.scala:313) finished in 0.100 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 60)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ResultStage 60 (MapPartitionsRDD[298] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_63 stored as values in memory (estimated size 54.8 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_63_piece0 stored as bytes in memory (estimated size 16.9 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_63_piece0 in memory on 10.0.184.47:34201 (size: 16.9 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 63 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[298] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 60.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 60.0 (TID 60, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_63_piece0 in memory on algo-1:40371 (size: 16.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 24 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 60.0 (TID 60) in 46 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 60.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ResultStage 60 (collect at AnalysisRunner.scala:313) finished in 0.052 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Job 35 finished: collect at AnalysisRunner.scala:313, took 0.159401 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Registering RDD 305 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Got job 36 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Final stage: ResultStage 62 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 61)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 61)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 61 (MapPartitionsRDD[305] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_64 stored as values in memory (estimated size 50.0 KB, free 1455.7 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_64_piece0 stored as bytes in memory (estimated size 20.2 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_64_piece0 in memory on 10.0.184.47:34201 (size: 20.2 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 64 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[305] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 61.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 61.0 (TID 61, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_64_piece0 in memory on algo-1:40371 (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 61.0 (TID 61) in 48 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 61.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ShuffleMapStage 61 (countByKey at ColumnProfiler.scala:566) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 62)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ResultStage 62 (ShuffledRDD[306] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_65 stored as values in memory (estimated size 3.2 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_65_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_65_piece0 in memory on 10.0.184.47:34201 (size: 1924.0 B, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 65 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 62 (ShuffledRDD[306] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 62.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 62.0 (TID 62, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_65_piece0 in memory on algo-1:40371 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 25 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 62.0 (TID 62) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 62.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ResultStage 62 (countByKey at ColumnProfiler.scala:566) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Job 36 finished: countByKey at ColumnProfiler.scala:566, took 0.089253 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  CodeGenerator:54 - Code generated in 6.20623 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Registering RDD 311 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Got job 37 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Final stage: ResultStage 64 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 63)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 63)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 63 (MapPartitionsRDD[311] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_66 stored as values in memory (estimated size 61.7 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_66_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1455.6 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_66_piece0 in memory on 10.0.184.47:34201 (size: 23.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 66 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[311] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 63.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 63.0 (TID 63, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_66_piece0 in memory on algo-1:40371 (size: 23.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 63.0 (TID 63) in 144 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 63.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ShuffleMapStage 63 (collect at AnalysisRunner.scala:313) finished in 0.152 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 64)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ResultStage 64 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_67 stored as values in memory (estimated size 66.0 KB, free 1455.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_67_piece0 stored as bytes in memory (estimated size 25.8 KB, free 1455.5 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_67_piece0 in memory on 10.0.184.47:34201 (size: 25.8 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 67 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 64.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 64.0 (TID 64, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_67_piece0 in memory on algo-1:40371 (size: 25.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 26 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 64.0 (TID 64) in 84 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 64.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ResultStage 64 (collect at AnalysisRunner.scala:313) finished in 0.094 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Job 37 finished: collect at AnalysisRunner.scala:313, took 0.253709 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  CodeGenerator:54 - Code generated in 6.884748 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Got job 38 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Final stage: ResultStage 65 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting ResultStage 65 (MapPartitionsRDD[323] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_68 stored as values in memory (estimated size 52.4 KB, free 1455.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  MemoryStore:54 - Block broadcast_68_piece0 stored as bytes in memory (estimated size 21.0 KB, free 1455.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_68_piece0 in memory on 10.0.184.47:34201 (size: 21.0 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  SparkContext:54 - Created broadcast 68 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[323] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Adding task set 65.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 65.0 (TID 65, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  BlockManagerInfo:54 - Added broadcast_68_piece0 in memory on algo-1:40371 (size: 21.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 65.0 (TID 65) in 56 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  YarnScheduler:54 - Removed TaskSet 65.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - ResultStage 65 (treeReduce at KLLRunner.scala:107) finished in 0.061 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  DAGScheduler:54 - Job 38 finished: treeReduce at KLLRunner.scala:107, took 0.063947 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  CodeGenerator:54 - Code generated in 9.211677 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:47 INFO  CodeGenerator:54 - Code generated in 15.961426 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  CodeGenerator:54 - Code generated in 24.961676 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Registering RDD 328 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Got job 39 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Final stage: ResultStage 67 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 66)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 66)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 66 (MapPartitionsRDD[328] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_69 stored as values in memory (estimated size 59.4 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.0 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_69_piece0 in memory on 10.0.184.47:34201 (size: 23.0 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  SparkContext:54 - Created broadcast 69 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[328] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Adding task set 66.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 66.0 (TID 66, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_69_piece0 in memory on algo-1:40371 (size: 23.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 66.0 (TID 66) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Removed TaskSet 66.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - ShuffleMapStage 66 (collect at AnalysisRunner.scala:313) finished in 0.043 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - waiting: Set(ResultStage 67)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting ResultStage 67 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_70 stored as values in memory (estimated size 16.1 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.7 KB, free 1455.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_70_piece0 in memory on 10.0.184.47:34201 (size: 6.7 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  SparkContext:54 - Created broadcast 70 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Adding task set 67.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 67.0 (TID 67, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_70_piece0 in memory on algo-1:40371 (size: 6.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 27 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 67.0 (TID 67) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Removed TaskSet 67.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - ResultStage 67 (collect at AnalysisRunner.scala:313) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Job 39 finished: collect at AnalysisRunner.scala:313, took 0.075671 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ConstraintGenerator:45 - Generating Constraints:\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ConstraintGenerator:50 - Constraints: {\n",
      "  \"version\" : 0.0,\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"fraud\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_spouse\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_ca\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_type_breakin\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_vehicles_involved\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_month\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_type_theft\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_none\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_injuries\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"vehicle_claim\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_hour\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_na\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_wa\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"months_as_customer\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"injury_claim\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"police_report_available\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_other\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_insurers_past_5_years\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_gender_female\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_rear\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_age\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_or\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_claims_past_year\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_self\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_severity\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_id\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_na\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_side\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_fire\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_liability\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_front\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_education\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_nv\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"auto_year\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_police\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_az\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"total_claim_amount\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_gender_male\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_annual_premium\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_child\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_type_collision\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_deductable\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_dow\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_day\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_witnesses\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_ambulance\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  } ],\n",
      "  \"monitoring_config\" : {\n",
      "    \"evaluate_constraints\" : \"Enabled\",\n",
      "    \"emit_metrics\" : \"Enabled\",\n",
      "    \"datatype_check_threshold\" : 1.0,\n",
      "    \"domain_content_threshold\" : 1.0,\n",
      "    \"distribution_constraints\" : {\n",
      "      \"perform_comparison\" : \"Enabled\",\n",
      "      \"comparison_threshold\" : 0.1,\n",
      "      \"comparison_method\" : \"Robust\"\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  FileUtil:29 - Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  StatsGenerator:65 - Generating Stats:\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  CodeGenerator:54 - Code generated in 11.899075 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  CodeGenerator:54 - Code generated in 20.365194 ms\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  SparkContext:54 - Starting job: count at StatsGenerator.scala:67\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Registering RDD 336 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Got job 40 (count at StatsGenerator.scala:67) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Final stage: ResultStage 69 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 68)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 68)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 68 (MapPartitionsRDD[336] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_71 stored as values in memory (estimated size 50.8 KB, free 1455.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_71_piece0 stored as bytes in memory (estimated size 20.3 KB, free 1455.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_71_piece0 in memory on 10.0.184.47:34201 (size: 20.3 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  SparkContext:54 - Created broadcast 71 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[336] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Adding task set 68.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 68.0 (TID 68, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_71_piece0 in memory on algo-1:40371 (size: 20.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 68.0 (TID 68) in 46 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Removed TaskSet 68.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - ShuffleMapStage 68 (count at StatsGenerator.scala:67) finished in 0.056 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - waiting: Set(ResultStage 69)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting ResultStage 69 (MapPartitionsRDD[339] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_72 stored as values in memory (estimated size 7.4 KB, free 1455.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MemoryStore:54 - Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1455.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_72_piece0 in memory on 10.0.184.47:34201 (size: 3.8 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  SparkContext:54 - Created broadcast 72 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[339] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Adding task set 69.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 69.0 (TID 69, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Added broadcast_72_piece0 in memory on algo-1:40371 (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 28 to 10.0.184.47:54078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 69.0 (TID 69) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  YarnScheduler:54 - Removed TaskSet 69.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - ResultStage 69 (count at StatsGenerator.scala:67) finished in 0.032 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  DAGScheduler:54 - Job 40 finished: count at StatsGenerator.scala:67, took 0.092462 s\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1728\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1717\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2077\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1816\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1709\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1751\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2063\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1887\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1808\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1768\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1654\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1848\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1905\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1951\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1582\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1731\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2061\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1791\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2060\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2102\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1846\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1680\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2034\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1822\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1857\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1961\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2036\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1847\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2009\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1914\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1863\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1917\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 24\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1853\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2045\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1748\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1568\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2015\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1796\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_55_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_55_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1881\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1721\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1773\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1873\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1637\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1934\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1809\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1814\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1706\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1912\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2080\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1733\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1900\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1879\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2030\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2073\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1656\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1677\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1804\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1929\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1767\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2002\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1711\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1533\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1668\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1823\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1612\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1587\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1826\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2084\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2062\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1566\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1839\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1687\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1783\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1837\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1684\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1622\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1988\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1923\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1982\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_69_piece0 on 10.0.184.47:34201 in memory (size: 23.0 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_69_piece0 on algo-1:40371 in memory (size: 23.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 27\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1710\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2120\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1645\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1538\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1646\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1628\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1987\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2047\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1785\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2041\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1636\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1756\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1996\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1534\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1994\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1893\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1713\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1976\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1613\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1548\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1591\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1772\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1719\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1907\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1562\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1638\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1924\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1671\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1811\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1919\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1993\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1609\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1904\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_58_piece0 on 10.0.184.47:34201 in memory (size: 16.7 KB, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_58_piece0 on algo-1:40371 in memory (size: 16.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1693\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_65_piece0 on 10.0.184.47:34201 in memory (size: 1924.0 B, free: 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_65_piece0 on algo-1:40371 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 22\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2085\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2112\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1954\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2109\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2010\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1997\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1679\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1937\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1577\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2110\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1894\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1995\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1942\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1778\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2119\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1594\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2105\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1801\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1545\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1564\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1953\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1898\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2018\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1855\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1760\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1698\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1896\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1665\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1869\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2054\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1563\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1579\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2104\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1682\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 23\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2074\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1769\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1875\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1623\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2091\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1968\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1775\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2014\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2028\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1936\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1945\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1841\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1551\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2048\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1691\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1758\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1852\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1660\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1854\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1755\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1640\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1902\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1599\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1704\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1812\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1712\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2013\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1844\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2095\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1878\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1593\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1762\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1750\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1720\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2092\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1774\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1560\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1699\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1678\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1926\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1952\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1674\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1817\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1625\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2089\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2020\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1950\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1554\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1639\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1861\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1580\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1990\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2035\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2050\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1781\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2099\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_57_piece0 on 10.0.184.47:34201 in memory (size: 32.8 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_57_piece0 on algo-1:40371 in memory (size: 32.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1724\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1759\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1543\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1824\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2078\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2083\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2118\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2052\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2059\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1586\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1618\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2106\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1578\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1985\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2116\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1716\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1730\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1573\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2057\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2088\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1585\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2053\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1576\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1966\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1643\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1906\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1741\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2021\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1858\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1872\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1989\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1555\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2044\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1972\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2072\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1663\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1542\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1725\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1570\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_60_piece0 on 10.0.184.47:34201 in memory (size: 36.7 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_60_piece0 on algo-1:40371 in memory (size: 36.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1845\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1851\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1836\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1977\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1658\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1928\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2003\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2117\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1920\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1670\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1565\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1956\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1962\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1595\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1650\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1986\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1700\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1856\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1940\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1943\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1598\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1696\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1850\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1825\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1780\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1667\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1877\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1959\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1737\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1694\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1747\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1949\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1738\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1868\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1547\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2011\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1864\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1829\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1745\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1955\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2096\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2115\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2046\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2001\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2029\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2065\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1981\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2040\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1556\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1630\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1901\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2087\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1600\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_62_piece0 on 10.0.184.47:34201 in memory (size: 33.2 KB, free: 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_62_piece0 on algo-1:40371 in memory (size: 33.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1631\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_59_piece0 on 10.0.184.47:34201 in memory (size: 32.5 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_59_piece0 on algo-1:40371 in memory (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1784\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1815\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1818\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1975\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1828\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1944\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1549\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1651\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1960\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2058\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1659\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1537\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1743\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1973\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1614\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1597\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2027\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1722\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1672\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1714\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2111\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1807\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1884\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1757\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1921\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1739\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1683\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1899\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1888\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1932\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1647\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1761\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1886\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1669\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1561\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1948\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1927\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1789\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2055\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1766\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1590\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_72_piece0 on 10.0.184.47:34201 in memory (size: 3.8 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_72_piece0 on algo-1:40371 in memory (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1655\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2076\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1605\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1657\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1813\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1540\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1913\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2024\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1793\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1800\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1890\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1883\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1779\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1799\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1965\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 21\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2079\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2100\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1629\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1827\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2082\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2006\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1946\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2032\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 25\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2097\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1935\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1546\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1735\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1939\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2069\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2007\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1701\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1866\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1895\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1550\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_61_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_61_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1776\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2121\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1909\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1552\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1707\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1970\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2026\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1664\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1697\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1606\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2004\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_71_piece0 on 10.0.184.47:34201 in memory (size: 20.3 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_71_piece0 on algo-1:40371 in memory (size: 20.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1702\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1718\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1744\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1592\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1681\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1979\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1726\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1833\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1617\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1971\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2008\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1805\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2101\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1708\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1675\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1666\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1732\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_70_piece0 on 10.0.184.47:34201 in memory (size: 6.7 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_70_piece0 on algo-1:40371 in memory (size: 6.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1991\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1880\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1754\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1632\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1819\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1908\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1983\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1980\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1596\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1676\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1616\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1832\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1644\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1742\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1635\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1715\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1621\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1798\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1865\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1649\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1797\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1915\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1771\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1611\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1705\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1608\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2107\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1838\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1589\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2067\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1619\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1559\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1794\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1764\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2005\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2071\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_63_piece0 on 10.0.184.47:34201 in memory (size: 16.9 KB, free: 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_63_piece0 on algo-1:40371 in memory (size: 16.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1876\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1770\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1889\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_68_piece0 on 10.0.184.47:34201 in memory (size: 21.0 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_68_piece0 on algo-1:40371 in memory (size: 21.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1891\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_64_piece0 on 10.0.184.47:34201 in memory (size: 20.2 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_64_piece0 on algo-1:40371 in memory (size: 20.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1922\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1810\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1601\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2017\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1567\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1984\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1974\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1584\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1624\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1843\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1862\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1871\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1652\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1740\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1787\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1736\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2042\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1581\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1574\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1685\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1834\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2043\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2019\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1627\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1992\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1786\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1536\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 26\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1897\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1998\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1820\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1938\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1874\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1541\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1958\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1788\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1835\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1806\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1686\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1859\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1558\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1933\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1575\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1723\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2000\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2108\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_67_piece0 on 10.0.184.47:34201 in memory (size: 25.8 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_67_piece0 on algo-1:40371 in memory (size: 25.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2016\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1963\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1703\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1615\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1607\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2081\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1604\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1969\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1831\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1648\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1911\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_56_piece0 on 10.0.184.47:34201 in memory (size: 21.8 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_56_piece0 on algo-1:40371 in memory (size: 21.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1867\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2056\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1860\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1892\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2051\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1957\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1642\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1765\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1941\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1661\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1553\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1610\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1557\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1729\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1603\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1689\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1802\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1795\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_66_piece0 on 10.0.184.47:34201 in memory (size: 23.7 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_66_piece0 on algo-1:40371 in memory (size: 23.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2070\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2033\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1633\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1727\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2113\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1870\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2068\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1964\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1662\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2066\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1903\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1653\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1782\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned shuffle 28\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2093\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1925\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1885\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2039\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1626\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1821\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1572\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1583\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1792\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1746\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1910\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1544\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_54_piece0 on 10.0.184.47:34201 in memory (size: 32.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  BlockManagerInfo:54 - Removed broadcast_54_piece0 on algo-1:40371 in memory (size: 32.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2090\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2075\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2114\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1849\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1602\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2086\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1830\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1790\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1763\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2012\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1569\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2064\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1673\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1752\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1620\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2025\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1539\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1535\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1882\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1753\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2022\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1734\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1978\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1588\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2023\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1690\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2037\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1947\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1634\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1695\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1571\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2031\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1967\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1777\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1803\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2049\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1749\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1916\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1931\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1688\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1999\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2094\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1842\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1918\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1692\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2038\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2103\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 2098\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1930\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1641\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  ContextCleaner:54 - Cleaned accumulator 1840\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  StatsGenerator:70 - Stats: {\n",
      "  \"version\" : 0.0,\n",
      "  \"dataset\" : {\n",
      "    \"item_count\" : 8209\n",
      "  },\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"fraud\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.3332927274942137,\n",
      "      \"sum\" : 2736.0,\n",
      "      \"std_dev\" : 0.47139016249141447,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 5472.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 2737.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\u001b[0m\n",
      "\u001b[34m.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_spouse\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.09750281126772628,\n",
      "      \"sum\" : 800.400577696765,\n",
      "      \"std_dev\" : 0.27264914684886343,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7151.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 52.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 66.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 67.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 71.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 61.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 74.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 67.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 73.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 527.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1337075640178187, 0.0, 0.5848750604652789, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27061999469359665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7981581646362419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5484344133944249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1660748523335137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32761018720129553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42038090277186335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05097487702244241, 0.0, 0.20778342096169145, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8437550439872936, 0.0, 0.6872955625825176, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.19477349768722585, 0.810468217215466, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3477248891009498, 0.5403554026142626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2698265466893234, 0.0, 0.0, 0.0, 0.5909148513651238, 0.0, 0.3028298889787422, 0.2691203766777923, 0.2992744787157362, 0.0, 0.0, 0.0, 0.0, 0.6559033130983996, 0.0, 0.0, 0.7753975599251152, 0.9308464322814988, 0.0, 0.0, 0.0, 0.0, 0.6993394662526431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.694017414105742, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3186896039905236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3374320822612149, 0.8077178199814796, 0.0, 0.0, 0.0, 0.7359179535519887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7905442304904889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0683020263188312, 0.0, 0.8037552360117627, 0.0, 0.0, 0.0, 0.11371178354428235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3679807915775636, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7950580176061312, 0.6762691743895763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7325847215278923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9024923075361247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7643771488083516, 0.0, 0.8712516273986526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08196573464366219, 1.0, 0.0, 1.0, 0.6928543518957885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4017931351094245, 0.0, 0.0, 0.4772000794179613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13651539163088466, 0.0, 0.0, 0.0, 0.004525847653185644, 0.0, 0.7784827278868942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12188808253227046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5892907546083338, 0.0, 0.0, 0.14675753080288245, 0.6735465781313908, 0.0, 0.27686996949201226, 0.0, 0.9308240749901141, 0.6607985296909104, 0.0, 0.31157173958222895, 0.8456535222773424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.862076142576597, 0.0, 0.0, 0.0, 0.718607017827837, 0.0, 0.7528486558822063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7502607940873155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7205546926810974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2911008872266839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9572603939380486, 0.0, 0.0, 0.8281234878640757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9807938054145848, 0.0, 0.5037083870840707, 0.0, 0.0, 0.24546308409753947, 0.0, 0.0, 0.29906463498200075, 0.8057264289981986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4014976105648763, 0.20687146203694362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8529263838545813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37975864573108786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4502824838315258, 0.0, 0.0, 0.0, 0.30343859785595384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4480636389395335, 0.0, 0.0, 0.0, 0.34223461672739997, 0.0, 0.0, 0.0, 0.0, 0.7593108551502052, 0.0, 0.0, 0.47130827457412117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.41843579556201127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6985369405411993, 0.4006270071280137, 0.0, 0.0, 0.8850936566380897, 0.9961628544921991, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08710928946143404, 0.0, 0.0, 0.7382488998655176, 0.6242407369975181, 0.0, 0.8096630249049525, 0.08277940817513718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9374930584895892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40356604537434004, 0.0, 0.0, 0.0, 0.0, 0.5313568317526952, 0.0, 0.0, 0.0, 0.0, 0.9621021041650275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06128536462596501, 0.0, 0.0, 0.0, 0.41829111109348593, 0.6905872051295556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38586682381248194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6439069148335783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5322228748561939, 0.0, 0.10137984246986353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8636296725324342, 0.7280122577961974, 0.0, 0.0, 0.0, 0.0, 0.5066857908540028, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002317547904813866, 0.0029210326213620075, 0.0037377134751231944, 0.00566581452956727, 0.009453967229866578, 0.01230970301607559, 0.018346676147552143, 0.020353284966116547, 0.021938182026471464, 0.02449844826765235, 0.028466957609411314, 0.030021332149071878, 0.030857904308072448, 0.03617683912152636, 0.038840584289834834, 0.049496853493666615, 0.05488581124399128, 0.05912464366193515, 0.06006820803017754, 0.06290897154120523, 0.06726925952374518, 0.07597312957426716, 0.07737694191221034, 0.08179200037722478, 0.08391953582142941, 0.08764983619465327, 0.09072170223493103, 0.09292914437938993, 0.09432742629104363, 0.10274825245242336, 0.10480806499757211, 0.1129316426860113, 0.11619095652544598, 0.12276054283779958, 0.12786429997752347, 0.13169343847203852, 0.138871326396517, 0.160183837854469, 0.16273699286149124, 0.16668292852698752, 0.17058191155709002, 0.17424340164537955, 0.17546519191296783, 0.1805182283924236, 0.19111653836367193, 0.1914276804995425, 0.19395386726777486, 0.1959043303664072, 0.19924595440831405, 0.20056025107298292, 0.2040246657385787, 0.20730900318755796, 0.21175535066547835, 0.21287339739839595, 0.21615732323232617, 0.21790870825201347, 0.21965213725984145, 0.2204836934733041, 0.22504187617087212, 0.22627525081659983, 0.22848674675477076, 0.2352355848019848, 0.24574645565613695, 0.2542313837486956, 0.2581732541911692, 0.2624342509071732, 0.26537011160197543, 0.2669488101400066, 0.2697538529098541, 0.270765257086357, 0.27316116895176246, 0.2782784472828207, 0.2918781650993746, 0.2973550482368389, 0.2984349123618767, 0.3022437239265705, 0.30959427808892803, 0.31092893000755417, 0.31259363586376243, 0.31755457986950175, 0.31902517276175546, 0.3200273165623919, 0.3211022749221595, 0.32838122788508106, 0.33209936539313645, 0.3347078980219448, 0.33581208549458264, 0.3397774715618851, 0.34562499357640153, 0.34904266488192737, 0.3522257670496579, 0.353903824994937, 0.3566348200882157, 0.3647982191445295, 0.36695607920480067, 0.3720499472273642, 0.37544110966791266, 0.3773136614063236, 0.3810518069922785, 0.3840880843232788, 0.39936874839469094, 0.4027075796465307, 0.4065567838081042, 0.4085932405775119, 0.4113394664991439, 0.41977848121497063, 0.4281908363928463, 0.43051551582774616, 0.4353242214552362, 0.43817234641198766, 0.4400580465093987, 0.4426894246856915, 0.4468880289416285, 0.448813645746606, 0.4510195505583582, 0.4531403590248738, 0.4584664245692578, 0.4604437795044949, 0.46464189815733914, 0.47289713281090484, 0.4754066078500737, 0.4756878180109587, 0.4799259388888496, 0.4883941300649396, 0.4954521034609818, 0.5007109258366713, 0.5106235510293298, 0.5183651534651377, 0.5224441454054645, 0.5241591707261622, 0.530358225319291, 0.5359333105954953, 0.5408107662674382, 0.5424710034626561, 0.5453811212183025, 0.5491303362771727, 0.549402981016866, 0.554209085422771, 0.5567269125563817, 0.5588494477693676, 0.5596884448379399, 0.5634389273484588, 0.5649843576752536, 0.5792663538205268, 0.5799959259185951, 0.585810145971902, 0.5930280903657361, 0.6008332054889804, 0.60687734157693, 0.6107707306850386, 0.6127627288219041, 0.6192390320535817, 0.6220395623709938, 0.6251964322182036, 0.6285914323498593, 0.6305809415830923, 0.6375686773841709, 0.6384586012459614, 0.6396221800696524, 0.6438143528824058, 0.648235897382097, 0.6539940923398012, 0.656336807390897, 0.6596293663947422, 0.6667719097838972, 0.674746094075448, 0.6774720221535848, 0.6870391505824806, 0.6887625408113653, 0.6927610381522795, 0.6938055569674118, 0.6991468916467449, 0.7043053259583958, 0.7066755336776999, 0.7108847166823191, 0.7154376982371025, 0.7196655392084791, 0.7210619239265232, 0.7215605917495654, 0.7257259103641033, 0.7376570332190543, 0.7439524348950457, 0.7481919059789975, 0.7514197422850579, 0.7574644454507177, 0.7596176113005162, 0.762482884475553, 0.767458668379145, 0.7744586700742674, 0.7811704237869193, 0.7837729908722203, 0.786522382390847, 0.787901988292265, 0.7917202592613465, 0.804390726955485, 0.805525913576057, 0.8073960303399513, 0.8103051518253228, 0.8167232025585446, 0.8187070571192328, 0.8237780901011652, 0.8251321959287038, 0.8267146599310183, 0.8328679885287787, 0.8339474785184636, 0.8385492149028282, 0.8448623274896327, 0.8510002638507566, 0.8548034871153397, 0.8571295598562823, 0.8598238353912759, 0.8664386675276454, 0.8689442522791451, 0.870399348804558, 0.8720630754882168, 0.8752859430886095, 0.876777345827834, 0.87986267736116, 0.8888628526679876, 0.8899367157988848, 0.9017650078109195, 0.9069695135399728, 0.9149658650779686, 0.9173823365407313, 0.9245224687318999, 0.9273551805862972, 0.9301993453853711, 0.9308873720608084, 0.9353131064848684, 0.9389964220859776, 0.9404192073007469, 0.9423834540022769, 0.9425313075201167, 0.9446657321710952, 0.9563200933875275, 0.9580359265563657, 0.9640698178140\u001b[0m\n",
      "\u001b[34m27, 0.96945054290662, 0.9743722386792576, 0.9795508403817569, 0.9828502180848019, 0.9876595923412518, 0.9899093933109753, 0.9943341854704327, 0.999713804155914, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012318351664258875, 0.052649537368961274, 0.09116449040619168, 0.16399948098949724, 0.2687299330263144, 0.3599970331630863, 0.40227643474413566, 0.4657577940235549, 0.4729759037881379, 0.5298174073033349, 0.5967386388761682, 0.6129441748656059, 0.6532630192373301, 0.6880480095048696, 0.7155533152342419, 0.7653259617384489, 0.8378257352832454, 0.8680543225322929, 0.9087013092693679, 0.948303162758473, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_ca\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.5911319808981625,\n",
      "      \"sum\" : 4852.602431193016,\n",
      "      \"std_dev\" : 0.446116717687062,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 2514.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 206.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 199.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 218.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 220.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 205.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 218.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 206.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 228.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 3995.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 0.9318909752764775, 1.0, 0.9353781613071173, 0.0, 0.4453865259778722, 0.9854328452487211, 0.7526002529416542, 1.0, 1.0, 1.0, 1.0, 0.5216645183294442, 0.9789788932737828, 0.8196095530657999, 0.0, 0.7877421883023699, 1.0, 0.0, 0.0, 0.0, 1.0, 0.012341046060374006, 0.14296087760075216, 0.2577064618297372, 0.244161608716153, 1.0, 1.0, 1.0, 0.9524153059966436, 0.8835647283701904, 0.7293800053064033, 1.0, 1.0, 0.9926658491638197, 0.025809392863181735, 1.0, 0.0, 1.0, 0.0, 0.2581039291604684, 0.0, 0.08245699034625531, 0.7778112444584507, 0.8223391114568475, 0.09723621203549127, 0.47510001327416174, 0.4511931914507237, 0.6696085263343835, 0.5892146143478555, 0.5457216032101775, 1.0, 0.9369278637311389, 0.0, 0.7964843893295808, 0.7567580902469283, 0.0, 1.0, 0.9408941791243455, 0.6907263151132631, 0.728786222256576, 1.0, 0.0, 1.0, 0.7140994662287976, 0.6723898127987045, 0.8301274055955237, 0.9445841115577556, 0.0, 1.0, 1.0, 0.3470270780920607, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5498641783643982, 0.9631590270650665, 0.8852464005861646, 0.5095914808144868, 1.0, 1.0, 0.38247088493768844, 0.20778342096169145, 0.41230298171245405, 0.11236448194898563, 0.33198647143270277, 0.7816325580532472, 0.43705152184218765, 0.6277454148973364, 0.647457940745546, 0.8437550439872936, 0.6750772055933587, 1.0, 0.0, 0.26975666564213197, 0.0, 0.6307174444919292, 0.0, 0.6122757656938724, 0.016675813489839153, 1.0, 0.18953178278453398, 1.0, 0.7315621195611339, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3477248891009498, 1.0, 0.6757612928952238, 1.0, 0.0, 0.0, 0.3671973893384931, 0.7689200445711684, 0.005918345354424481, 0.011078552594309676, 0.0, 0.4282106840640195, 0.5659478239190433, 0.12757017457137088, 0.0, 0.6456228170138647, 1.0, 0.7308796233222077, 0.7007255212842638, 1.0, 0.06133518670662774, 1.0, 1.0, 0.6559033130983996, 0.801185939062597, 1.0, 1.0, 0.9308464322814988, 1.0, 1.0, 0.4730275033430207, 0.04331527325431195, 0.6993394662526431, 1.0, 0.74473672782921, 1.0, 0.0, 0.5131750822820359, 1.0, 1.0, 1.0, 0.9119595841996332, 0.93907127827928, 1.0, 0.8172488340125641, 0.31904507433223983, 0.0, 1.0, 0.24257826607382516, 1.0, 0.3186896039905236, 0.8953240294644667, 0.1285964859605525, 0.0, 0.0, 0.0, 0.2855858985295022, 0.3616470948410445, 0.8746246507661267, 0.7463872291402918, 0.357913492647601, 0.2755365671408512, 0.4945211251204079, 1.0, 0.588093637605447, 0.6839223161567359, 0.6269684345287165, 0.8083948823040229, 0.6116464193899924, 0.29574756259502066, 0.0, 0.327420958733448, 0.16462051323650484, 0.0, 0.0, 0.38473257650744497, 0.5640048194294142, 1.0, 0.0, 0.06737687152192573, 0.8315407863376656, 0.17732655322393942, 0.7230716360496688, 0.2273290118718334, 0.2851004659086863, 1.0, 0.0, 0.3603754923631707, 0.0, 0.0, 0.13652010508718693, 0.30880227534961535, 1.0, 0.26599769309265797, 1.0, 0.5574049643141872, 1.0, 1.0, 1.0, 0.11408600450257511, 0.0, 0.018945403374354575, 0.7359179535519887, 0.2083995736183316, 0.13292804270798264, 0.3615112152008645, 0.3197431954076949, 0.9428828366295567, 0.13762973439836135, 0.9990705831300389, 0.9032236273447073, 1.0, 1.0, 0.41626278068790734, 1.0, 0.9117258769127757, 0.9597110542654579, 1.0, 0.680479462524374, 1.0, 0.620371252123721, 1.0, 0.0, 0.38593951093692735, 0.6260528655209325, 1.0, 0.0, 0.0, 0.6714418501142015, 0.05446604736683758, 0.18245804065249005, 0.0, 0.5718160601328272, 0.0, 1.0, 0.0, 0.0, 0.20658101622178082, 0.31326647658061035, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.20494198239386885, 0.0, 0.23480616624560802, 0.856838642188807, 0.6577161472759535, 0.3584314333150056, 0.9744302009102653, 0.2120298664090684, 1.0, 1.0, 1.0, 0.0824059718619482, 0.599967858261066, 0.48564686533427714, 1.0, 1.0, 0.1286847527531465, 1.0, 0.0, 1.0, 1.0, 0.8533292165587878, 0.6718399276463922, 1.0, 1.0, 0.7687200716840445, 1.0, 0.6939528337712285, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.05642585596482286, 0.8712516273986526, 1.0, 1.0, 1.0, 0.9865631141144104, 1.0, 1.0, 0.646837228926381, 1.0, 0.3616494225795682, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8054649668315159, 0.8205521392557188, 0.3233553651801525, 1.0, 0.4017931351094245, 0.0, 1.0, 0.0, 0.2069369716293441, 0.0, 0.06751107641019816, 0.9338659428462488, 0.5977762651528876, 0.5312101194932091, 0.0, 0.07780807194871575, 0.0, 0.6957581361728042, 1.0, 0.6120085299594553, 0.0, 1.0, 0.07091595948797924, 0.0, 0.8624965074015853, 1.0, 0.6951874662100657, 0.6296283449385927, 1.0, 0.8677120523489618, 1.0, 0.5826286460403656, 0.9954741523468144, 0.9115147258658508, 1.0, 0.056162009903313104, 0.7443609062046385, 0.5275636489994199, 0.17159636706519, 1.0, 0.5374064528948469, 0.0, 1.0, 0.41586133940794756, 1.0, 1.0, 1.0, 0.5487333859268856, 0.0, 0.0, 0.46798046247804337, 0.5892907546083338, 1.0, 0.0, 1.0, 0.6735465781313908, 0.8626382540313258, 1.0, 0.9539369363180226, 1.0, 1.0, 0.2536371156867585, 0.688428260417771, 0.15434647772265764, 0.7403967162915215, 0.0, 0.0, 1.0, 0.5212951420344775, 1.0, 0.10540528595616694, 0.0, 0.0, 1.0, 0.17777188742298944, 1.0, 0.267140812668169, 1.0, 0.27721539937847883, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.23449947767409374, 1.0, 1.0, 0.10802895749157926, 1.0, 0.2497392059126845, 0.27450667350707825, 0.6246639742837168, 0.08116422446371452, 0.4522024791035387, 0.2609085780070469, 0.0, 1.0, 0.8774521266031688, 0.0, 1.0, 0.9682775081839688, 0.0, 1.0, 0.1919321828839774, 1.0, 0.5624293741179209, 0.2794453073189026, 0.21749985561970642, 0.0, 0.0, 0.862922393510989, 0.7329249925436676, 0.0, 0.858761429838704, 0.3258813426157904, 0.9540422650780858, 1.0, 0.018275069723506232, 0.09586464742180933, 0.0, 0.9918891959474917, 0.04860313802089389, 0.13702091003632066, 0.0, 0.0, 1.0, 0.06142512925983268, 0.7760754122034105, 1.0, 1.0, 0.022503741791106813, 0.8078656456839812, 0.0, 1.0, 1.0, 0.3393228356557111, 1.0, 0.9937839753781721, 0.3146289089351988, 0.0, 0.0, 0.0, 0.2820673090598982, 0.7163920765828637, 1.0, 1.0, 0.0, 0.042739606061951374, 0.1353476453972543, 0.1186606144745388, 0.0, 0.5234735291677627, 0.26211958483125763, 1.0, 1.0, 1.0, 0.21228564166859132, 0.8844416233193683, 0.16357907701436047, 0.5024656497627655, 1.0, 0.8029813013091038, 1.0, 0.6059261954142473, 0.0, 0.12158413695503834, 1.0, 1.0, 0.0, 0.40777860066855953, 0.0, 0.19427357100180143, 0.44720103221643803, 1.0, 0.0, 0.5887959327881459, 0.6633625340146814, 1.0, 0.5985023894351237, 0.7931285379630564, 1.0, 0.8140384924425823, 0.9508186599164314, 0.2098976295862307, 0.0, 1.0, 0.0, 0.6995965330235282, 1.0, 1.0, 1.0, 0.5036886093282389, 0.0, 0.4918582813348057, 0.37975864573108786, 1.0, 0.4781589235558441, 1.0, 0.3714335993527168, 1.0, 0.0, 0.4688905036624724, 0.7457176662047873, 0.8259409191119182, 0.30343859785595384, 0.0, 0.8203240881472009, 1.0, 0.32859392735626314, 0.073691723078804, 0.6191680442430584, 0.8248069479798307, 0.3111894964100129, 1.0, 1.0, 0.4259975194684281, 0.032257175166284346, 0.6577653832726, 0.0, 0.9329566255282273, 0.5865117810374487, 1.0, 0.7593108551502052, 0.7126656189865445, 1.0, 1.0, 1.0, 1.0, 0.4827065178477469, 0.4131073977271442, 0.19934548947118313, 1.0, 0.0722769475731766, 0.5757858627744116, 0.8536545489411119, 0.27471291564544476, 0.36039404005411124, 0.08707120557730819, 0.20214939922527075, 1.0, 1.0, 0.4560268887150325, 1.0, 0.1510761305239272, 0.6027285271595403, 0.24555062594449106, 0.0, 1.0, 0.8885123121612181, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7288698044883412, 0.3014630594588007, 0.4006270071280137, 1.0, 0.1097633782042291, 0.1149063433619103, 1.0, 1.0, 1.0, 1.0, 0.05451192743782629, 0.0, 0.0, 0.0, 0.8726258854858964, 0.08710928946143404, 0.5126155583279571, 0.30858394248684795, 1.0, 1.0, 1.0, 1.0, 0.08277940817513718, 1.0, 1.0, 0.5691417246177293, 0.0, 0.0, 0.7963006634151322, 0.0, 0.9857682495857412, 0.20871570750331647, 0.39861592931143663, 0.0, 1.0, 0.9589318272095946, 0.7448250755299131, 0.5540444549078982, 0.02002322973218762, 0.06250694151041081, 0.6125335361782434, 0.5834215190184351, 0.5357960510478733, 1.0, 0.0, 0.0, 0.21912606467080087, 0.11284318718362141, 1.0, 0.48468951693630746, 0.9731323459550647, 0.6195181145069641, 0.8938744145090045, 1.0, 0.39577767966043076, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5109707430450621, 0.0, 0.053781964177377906, 1.0, 0.6420388054672354, 0.6663391093663074, 0.0, 0.86163179911181, 0.26183172946315636, 0.14303558522376103, 0.06128536462596501, 0.5076376964803742, 1.0, 0.14444887656412753, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6141331761875181, 0.3258245840194487, 0.8082637826097335, 1.0, 0.5839192892611353, 0.0, 0.8514057478914739, 0.08426436615585109, 0.3560930851664217, 0.3196155862374779, 0.2741203638192007, 1.0, 0.2601321733995965, 0.2109771554518658, 0.11910653587671627, 0.8594528720044571, 0.2864737377445836, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3062678870046147, 0.7349187156614274, 0.6961924503010899, 0.8071294313103857, 0.0, 0.4677771251438061, 0.1783584302210447, 0.8986201575301365, 0.7918913237957292, 0.0, 0.48227400008154353, 1.0, 0.1745898512471864, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.18378466510790115, 0.0, 0.5127879930780861, 0.9752351224238488, 0.0, 0.40788960850728007, 0.0, 0.13637032746756583, 0.0, 0.0, 1.0, 1.0, 0.38555356440131383, 1.0, 0.1439989251068472 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8839955658189744E-4, 4.5608128090568467E-4, 0.0018798835249106416, 0.003090781410644672, 0.0031678485807017376, 0.004519509295742963, 0.005142026940678446, 0.00758459951052981, 0.008411591129726004, 0.008706147062543579, 0.00968688274096774, 0.011478352004553272, 0.0122504609008115, 0.013698550408914545, 0.01419004939576718, 0.014825444909325247, 0.015742912995676983, 0.015823171996820817, 0.017950462984037463, 0.018094301923460843, 0.020353284966116547, 0.022141475472629457, 0.02381302501191629, 0.02449844826765235, 0.025141958277272725, 0.027974743503408894, 0.028466957609411314, 0.029364159102392318, 0.030392273151904625, 0.03132539442564286, 0.03280962412860844, 0.03798156328985347, 0.038486661016915225, 0.04055873754468142, 0.042837555119113246, 0.043735625879969486, 0.04416193617783126, 0.045153006961531905, 0.04545250043579596, 0.04753288331215322, 0.05010033175392403, 0.05190094358730901, 0.05239129559486122, 0.055334267828904826, 0.056017694636790405, 0.05745406032309475, 0.05955149426382744, 0.061330955643282614, 0.06652760821085524, 0.06738455478552252, 0.06902954088784963, 0.0691126279391916, 0.06935752364804015, 0.06982903456157541, 0.07089157589128536, 0.0746384310794288, 0.07680744106928128, 0.08166727586009626, 0.08430131461135038, 0.08503413492203138, 0.08717946783183117, 0.08764983619465327, 0.08876739410776846, 0.089812154282774, 0.0918708877100447, 0.09216795847243231, 0.09250043793896379, 0.09280017843937771, 0.09305719116516609, 0.09490844126734621, 0.09639215565320491, 0.09756251023929974, 0.09870398922535117, 0.10094119997752149, 0.10173837270729402, 0.10274825245242336, 0.10413735792028744, 0.10440412974808144, 0.10554744317576781, 0.10633729734822717, 0.10705717855418606, 0.10994297453474744, 0.11097752458514809, 0.1147969272512801, 0.11647784967333707, 0.11764902847355863, 0.11800783027836415, 0.11841503917593188, 0.11956199775205645, 0.12065897982347196, 0.12201550301516517, 0.12322265417216605, 0.12448877344738385, 0.12572426899222622, 0.12612504447898165, 0.1263864224056671, 0.12709624021843924, 0.12736947344788108, 0.1274856801402462, 0.1291744452431104, 0.1305012641171842, 0.1313494081449067, 0.13158921205861795, 0.13306653164811633, 0.13653426965853666, 0.13702760101303746, 0.138871326396517, 0.13911584889108752, 0.14225523977681542, 0.14386750098625656, 0.14430920072160303, 0.1451965128846603, 0.14817792822994547, 0.14899973614924344, 0.15052149166341355, 0.15156937158767358, 0.1520721162366515, 0.15298380082856267, 0.15513767251036725, 0.1560358113399769, 0.157984338493256, 0.15830390010561435, 0.1590250037402613, 0.160183837854469, 0.1617346404542951, 0.16253798746870785, 0.1638810237804822, 0.16562834702826534, 0.16679564340332564, 0.16693107081750147, 0.16813688674857796, 0.16863229377803002, 0.16931148947992314, 0.17112872374704136, 0.17208603245262644, 0.17334305297528085, 0.1748693323338848, 0.17682598440433972, 0.17788812404902343, 0.17957317974097997, 0.18129294288076725, 0.18537277908251149, 0.18672329577304148, 0.18931407201373374, 0.19072598759089465, 0.19197737009344706, 0.19524687801030516, 0.19648189156506568, 0.19809551672028958, 0.2005529778452665, 0.20140672761724876, 0.2034364751360912, 0.20375940443714569, 0.204166559168243, 0.20540140847802935, 0.20709491817657122, 0.20730900318755796, 0.20827974073865352, 0.20975294768368136, 0.21119773609464043, 0.21324966484556307, 0.2140747237910866, 0.2149022859042924, 0.2162270091277797, 0.2172308864530108, 0.21903613635556474, 0.21944397311278618, 0.21981073151700503, 0.22074548845278175, 0.22190046078437287, 0.2232633855051963, 0.22370952248405218, 0.22522370226848976, 0.22696469436536415, 0.2281422738183787, 0.22917195121416212, 0.23148063547620878, 0.232055739701156, 0.23684470874111063, 0.2381163881375561, 0.23885666040192766, 0.2399893638699575, 0.2403823886994838, 0.2415749821308889, 0.2437294825243418, 0.24589231968383596, 0.2462441609706001, 0.24628601881053158, 0.24997158785780882, 0.25180809402100246, 0.25363555551403827, 0.2539748745720247, 0.2542313837486956, 0.25482050463038564, 0.2560475651049543, 0.2583973805482145, 0.2598386312385369, 0.26193087666148285, 0.26247058512126453, 0.2633157837532001, 0.2644718166671908, 0.26537011160197543, 0.2660192780053807, 0.26868348029670375, 0.26933129830202507, 0.2737913075141065, 0.2748442724488852, 0.2762373249751531, 0.2768717261174458, 0.2782784472828207, 0.2855892363734017, 0.28703999214119424, 0.2882515771673685, 0.2925150910707418, 0.2954679246267593, 0.29639200687528344, 0.29735979414177116, 0.29807565052482277, 0.3006846248737963, 0.30168884277242725, 0.3019167000775018, 0.30232937247992486, 0.30362393814384026, 0.3061373408795932, 0.3078863820162494, 0.30959427808892803, 0.3099999371717893, 0.31168982851504146, 0.31296084941751945, 0.314060794992732, 0.3150103723767316, 0.31798255134033493, 0.31830409469234733, 0.3196668324405447, 0.32150883134941877, 0.3225279778464152, 0.32350039491147375, 0.32415225353566357, 0.32485993885033193, 0.3270446441518178, 0.3299674621924332, 0.3306913908381208, 0.3331333394490783, 0.3334073221591105, 0.3337321385209615, 0.33684050186110326, 0.3373109541512276, 0.3388593215713035, 0.3408156997898466, 0.34167450189692083, 0.34180370549218253, 0.34366319260910305, 0.3447175903083418, 0.3460059076601988, 0.3479069381183494, 0.3509253412056069, 0.35260260592885817, 0.3542677648410466, 0.3554088252576564, 0.3567687116232726, 0.3574240310528104, 0.36171025485958064, 0.3624313226158291, 0.36275360039915205, 0.36290916291909503, 0.36350934895084597, 0.3638096411409335, 0.36411277501049943, 0.3646706762343366, 0.36695607920480067, 0.3677336508051099, 0.36801131960381095, 0.3697912516708558, 0.3703969862753065, 0.3720066173959019, 0.37352017689968753, 0.3738238284068618, 0.37480356778179635, 0.3758050158460863, 0.3800745089372053, 0.3803005598005843, 0.3810518069922785, 0.382750979151274\u001b[0m\n",
      "\u001b[34m3, 0.38368550776710364, 0.3853758830473618, 0.3859186888152639, 0.3865268613608237, 0.3870787603356308, 0.3873925856686593, 0.3892292693149614, 0.3905936075817822, 0.3910427630581744, 0.39312265842307004, 0.39385343506652026, 0.3942446968609433, 0.39543426799291437, 0.3968078343853325, 0.39785435594751895, 0.39883602970372944, 0.39916679451101955, 0.40087941495967483, 0.401154599920561, 0.40144563091319363, 0.40244663743366893, 0.40464033874139593, 0.40585813724354247, 0.4065142370240653, 0.40771577066522524, 0.4081190568259231, 0.40877726122913205, 0.41005211719819123, 0.413520907811293, 0.41516136831111794, 0.4156038959073355, 0.41579750068745014, 0.41644303267518146, 0.41779124023176883, 0.4185806216239353, 0.41906794673720227, 0.4195249932833254, 0.4233859928702822, 0.4254126176822334, 0.42863054697047576, 0.431112405097005, 0.4334246378285814, 0.4338005122547718, 0.43431182785899425, 0.4372883009776608, 0.4374819266082097, 0.4383849800307613, 0.4391255366373824, 0.4403115551620601, 0.4424099364806695, 0.44336294206328275, 0.44450457589413983, 0.44579091457722897, 0.44662098387329263, 0.4487788039946148, 0.44894904670506763, 0.45012443241975963, 0.450597018983134, 0.45069022851989604, 0.4510195505583582, 0.452086596811366, 0.4531240341239554, 0.4533147449007112, 0.4551723424548132, 0.4553831354806076, 0.45802221166825874, 0.4591892337325618, 0.4600023955807989, 0.4618434812751103, 0.4623911769125407, 0.46381424972767993, 0.4650552483006444, 0.4667486007208975, 0.4667820772311879, 0.46811092099248586, 0.46842260322500684, 0.4695186653456337, 0.46974376299068377, 0.4712755809015643, 0.4720604341969983, 0.4727738191601998, 0.47297134609551017, 0.4740064284831559, 0.4742884204312605, 0.47584082927383775, 0.47639945284738827, 0.4764612712393995, 0.47685697930283477, 0.47755585459453553, 0.47787844802224244, 0.4799259388888496, 0.48090600075306966, 0.4818674792746166, 0.48271347307693446, 0.4861492654234021, 0.4883746289829387, 0.49141817752855677, 0.4925990052218141, 0.4972559303146882, 0.49750912317306795, 0.49794978651155286, 0.49857079950570915, 0.49897111691376594, 0.5000801182715826, 0.5005682301331646, 0.5014292004942908, 0.501959606943131, 0.504003763596326, 0.5046190246076956, 0.5061075548467509, 0.5066726489827458, 0.5085818224714432, 0.5116357178950771, 0.5122847572434851, 0.5127202478126281, 0.5134023377562469, 0.5146410168401129, 0.517596301315522, 0.5206455598621482, 0.5210731905083879, 0.5217659769519277, 0.5224810405161183, 0.5240322689883441, 0.5250490347362518, 0.5262784603382027, 0.5272651809152565, 0.5304744579561373, 0.5320216789842518, 0.5322575311489761, 0.5332719062320496, 0.5377829347413765, 0.5386956673430391, 0.5397326187599428, 0.5415335754307422, 0.5423636649797383, 0.5440207242400631, 0.5455821217920664, 0.5456868884954734, 0.5484997216514768, 0.5493135250610869, 0.5493803432702421, 0.5498766388180678, 0.5509152549890532, 0.5520693646533779, 0.5546573480350956, 0.5554717469498404, 0.5556346507584856, 0.5561408115786989, 0.5565441636180959, 0.5579807387826399, 0.5589278417492163, 0.5600916974433955, 0.5627116990223392, 0.5644410906788825, 0.5644945456018406, 0.5649843576752536, 0.5668368886848336, 0.569016098079178, 0.5711131211389614, 0.5724981686718883, 0.5726428531155846, 0.573349345635218, 0.5764724375577539, 0.5773108866038105, 0.5802215187850294, 0.5814177144685109, 0.5832574924561156, 0.5832665178130454, 0.5837819411546507, 0.584056095418145, 0.585264173032529, 0.588135259582504, 0.5902326591508927, 0.5930145003605977, 0.5942907505617747, 0.5960221236734518, 0.5967764199616896, 0.600281460528037, 0.6023524204079639, 0.6030520270657072, 0.6032031529136835, 0.603291805714943, 0.6047940736900298, 0.6054812505259454, 0.6056346761816498, 0.6081760367165, 0.611940505337331, 0.6136768269235341, 0.6144000074313238, 0.6173517574129742, 0.6185270587181856, 0.6196159269449223, 0.6209085902177081, 0.6213444972535296, 0.6226863385936764, 0.6240071100586886, 0.625519600031983, 0.6284340474189989, 0.6285140563405658, 0.6288383852142582, 0.6325441099658279, 0.6349600455910331, 0.637055728154008, 0.6377319129014088, 0.6379607933159701, 0.6401682238281661, 0.6428189148001743, 0.6442567236508115, 0.6448683522461874, 0.646090123462508, 0.6465392594532176, 0.6477742329503421, 0.648457739950302, 0.6500550604703602, 0.6543750064235985, 0.6551823922538302, 0.6557236725616563, 0.6575603127780231, 0.6585747303957017, 0.6590355342036808, 0.6596199073333251, 0.6617368946676516, 0.6630073461417759, 0.6649945162377737, 0.6663932109709568, 0.6668544210142678, 0.6673503980464284, 0.6678902166918754, 0.6710552838599144, 0.6715584436130373, 0.6742588420064991, 0.6743151979360468, 0.6754202075470892, 0.6761082314144111, 0.6761253975882903, 0.6769888016137862, 0.6773873215187168, 0.6783788228551418, 0.6788977250778405, 0.6799401674790165, 0.6801319311034514, 0.6807558929604856, 0.6816694824016201, 0.6817486440901612, 0.6828042832346014, 0.68345033473213, 0.684810478902641, 0.6868367981702229, 0.6876508981144864, 0.6880159796735815, 0.6889975052673197, 0.69309548680543, 0.6948823736759592, 0.695624652354058, 0.6977562760734295, 0.6995106143995676, 0.6997052060994762, 0.7004317991565039, 0.7011428647409692, 0.7029434409786768, 0.7047217107796899, 0.7061585021190541, 0.7066755336776999, 0.7076883263306187, 0.710029881056391, 0.7108847166823191, 0.7146412749087242, 0.7150387188506838, 0.7175721247315944, 0.7177375295870672, 0.7189619186189717, 0.7200080396631131, 0.7202964615285208, 0.7206551452831133, 0.7217215527171793, 0.7222473762507389, 0.7243876613210546, 0.7257164632199491, 0.7285614223657998, 0.7304924774822994, 0.7321226068429558, 0.7324138648126686, 0.7336158300423125, 0.7340297625893063, 0.7362398101338331, 0.7394082298313118, 0.7428249749063163, 0.743256503690242, 0.7445066553443953, 0.7461789218433051, 0.7472195877420377, 0.7477943497593724, 0.7480047363714034, 0.7482328313318959, 0.7504969203172582, 0.7521286995435712, 0.753594630745753, 0.7577687821754331, 0.7586763901110049, 0.7595824101146318, 0.7608574545654768, 0.7619068201324154, 0.7625963946941753, 0.7632156906886146, 0.7647191414762792, 0.7672368528987112, 0.7674988305907054, 0.76821640971065, 0.7707425309055517, 0.7723010151653429, 0.7730890416974662, 0.7739062217706651, 0.775911532807306, 0.7767904834072271, 0.7789366285462715, 0.7809958936149914, 0.7815056477421821, 0.7820507692637583, 0.7823883294600873, 0.782581939851338, 0.7838426767676738, 0.7839873586893554, 0.7846556186174474, 0.7848618229588802, 0.7856431035291273, 0.7863577330614815, 0.7867083407073091, 0.7888875288338638, 0.7894094219135857, 0.7914116322589493, 0.7916999884533517, 0.7925213919629192, 0.7935706545388016, 0.7939897163680061, 0.7944856336484907, 0.7997810954240216, 0.800754045591686, 0.801684293191305, 0.802851208995546, 0.8048028354281175, 0.8049910195613842, 0.806589342326277, 0.8080792823558299, 0.8087899845635385, 0.809183171139031, 0.8108608999770154, 0.8121571474622259, 0.8122581209903419, 0.815414870462967, 0.8157694046351072, 0.8165475988497707, 0.8182767067718435, 0.8192551048714611, 0.8216479329617712, 0.8218064439010868, 0.8228290747281345, 0.8231128548561456, 0.8237780901011652, 0.8264880901957624, 0.8267146599310183, 0.8268388837118774, 0.8281168290063428, 0.8293324051412837, 0.8295875568652503, 0.8301509829979181, 0.8311457933223139, 0.8328319018690757, 0.8336431341439584, 0.8337919509188273, 0.8347579495573968, 0.8363161985346985, 0.8396596557087903, 0.841375855473622, 0.8422307463439479, 0.8426737199981718, 0.8437162904502238, 0.8458495504599677, 0.8480158852494014, 0.8493238922901226, 0.8511742608527708, 0.8517825379006754, 0.8541359976505043, 0.8547034500931975, 0.8561856496851863, 0.8573089023608409, 0.8579550909150572, 0.8595563969179368, 0.8598238353912759, 0.8608841511089125, 0.8619869084042723, 0.8634007668570018, 0.8651933473978111, 0.866386514251342, 0.8681692953265041, 0.8683464112067416, 0.8697631766817108, 0.870399348804558, 0.8711512879997452, 0.8720630754882168, 0.8722253472100095, 0.8728002373125504, 0.8737462172073865, 0.877138441511404, 0.8776470196507814, 0.8785046089122346, 0.8797527734883244, 0.87986267736116, 0.8815634549407569, 0.8830764644746085, 0.8844242755019771, 0.8849643081805878, 0.8857142300020205, 0.8892515546810419, 0.8896520330175663, 0.8911066860189609, 0.8918931032565626, 0.8939852050469608, 0.89440845402336, 0.8951919350024279, 0.8963214192657235, 0.8968786375919242, 0.8976746726779566, 0.9001331788638218, 0.9011263823593646, 0.9022364034622381, 0.9031907788344291, 0.9039133302603747, 0.9059638955657336, 0.9068038804373053, 0.910187845717226, 0.9106765794351396, 0.9111597549124356, 0.9135753892374535, 0.9147311149565036, 0.9172845384756465, 0.9173823365407313, 0.9197777535442859, 0.9223674846701029, 0.9235200445006869, 0.9241077159112795, 0.9245610553768049, 0.9255222078518809, 0.9257591270116136, 0.9283835056363074, 0.9316658951543958, 0.9343078835103408, 0.9355087287508325, 0.9370910284587948, 0.9390570959671871, 0.9401831912520826, 0.9412724482418516, 0.9422589481308262, 0.9425313075201167, 0.9427197489223766, 0.943174822961285, 0.9471960395314719, 0.9481047004815891, 0.9514420287256811, 0.9528967959978275, 0.9535350978515088, 0.9550385584084489, 0.9575300907434668, 0.9620184367101465, 0.964069817814027, 0.9650607535940116, 0.9673543224543314, 0.9685781784887271, 0.9703317769352602, 0.9721560924225866, 0.9742476541447561, 0.9747626541517358, 0.977031676545176, 0.977973078776183, 0.9828502180848019, 0.9853717411223243, 0.9867291015008487, 0.987092772019008, 0.9885075267018847, 0.9892177539577501, 0.9899093933109753, 0.9903617819983719, 0.9905460327701334, 0.9929707961863808, 0.9939112517601609, 0.9943341854704327, 0.9956378335948083, 0.9971187483343854, 0.9976824520951861, 0.9995572185627921, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017379790185479638, 0.03486516023382491, 0.042729737016674374, 0.046945357147813005, 0.0587624957676135, 0.1037786973149617, 0.12297080852962672, 0.14780646665299224, 0.18545887467665434, 0.20357828034224268, 0.2239997929645705, 0.22862516152492351, 0.25422457989749325, 0.28139096057752677, 0.30100926196041233, 0.3296145416455878, 0.3378879898934354, 0.3770626170648813, 0.4032613611238318, 0.44158732741680207, 0.4575213642806325, 0.4735738884350885, 0.4951551181069822, 0.5322449888262991, 0.5366192517843801, 0.556181735039757, 0.5709045018441643, 0.5946898169142566, 0.602621011535599, 0.6287648182059451, 0.6550093388321085, 0.6792572595618726, 0.7242853081264119, 0.7442790655949556, 0.7688690875723534, 0.7996408564512874, 0.8306425177506246, 0.842659340297474, 0.868122813490531, 0.8905324013208848, 0.9095245109478184, 0.9315894883189899, 0.952648638038717, 0.9658122340608418, 0.9815722812617825, 0.990927595347275, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1\u001b[0m\n",
      "\u001b[34m.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_type_breakin\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.12864727989548272,\n",
      "      \"sum\" : 1056.0655206620177,\n",
      "      \"std_dev\" : 0.2981048939908194,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 6699.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 122.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 97.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 116.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 113.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 110.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 138.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 111.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 116.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 587.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.06810902472352254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5216645183294442, 0.9789788932737828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244161608716153, 0.0, 0.0, 0.14519422120073855, 0.0, 0.1164352716298096, 0.7293800053064033, 0.0, 0.0, 0.9926658491638197, 0.025809392863181735, 0.0, 0.47955059583471404, 0.0, 0.2018418353637581, 0.0, 0.0, 0.0, 0.22218875554154927, 0.0, 0.0, 0.0, 0.4511931914507237, 0.3303914736656165, 0.5892146143478555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2859005337712024, 0.6723898127987045, 0.0, 0.0, 0.0, 0.23402842514482092, 0.0, 0.0, 0.5796190972281366, 0.0, 0.0, 0.041428088819387754, 0.967802737648485, 0.0, 0.9631590270650665, 0.0, 0.4904085191855132, 0.0, 0.0, 0.38247088493768844, 0.0, 0.0, 0.0, 0.0, 0.7816325580532472, 0.0, 0.0, 0.0, 0.0, 0.3249227944066413, 0.0, 0.0, 0.26975666564213197, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.18953178278453398, 0.7273493526875153, 0.7315621195611339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23107995542883164, 0.0, 0.011078552594309676, 0.7301734533106766, 0.0, 0.0, 0.0, 0.4090851486348762, 0.0, 0.0, 0.7308796233222077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6849894928165754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04331527325431195, 0.3006605337473569, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6826945225795135, 0.08804041580036681, 0.93907127827928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24257826607382516, 0.9086911974553298, 0.6813103960094764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6383529051589555, 0.0, 1.0, 0.0, 0.0, 0.4945211251204079, 0.8783046932733277, 0.0, 0.6839223161567359, 0.0, 0.8083948823040229, 0.0, 0.29574756259502066, 0.0, 0.0, 0.8353794867634952, 0.8188281491499799, 0.0, 0.0, 0.5640048194294142, 0.0, 0.0, 0.06737687152192573, 0.0, 0.17732655322393942, 0.7230716360496688, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7070152942725908, 0.0, 0.19228218001852038, 0.0, 0.0, 0.018945403374354575, 0.0, 0.2083995736183316, 0.0, 0.6384887847991355, 1.0, 0.05711716337044326, 1.0, 0.0, 1.0, 0.02461798384123859, 0.20945576950951106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.680479462524374, 0.0, 0.0, 0.19624476398823731, 0.0, 0.0, 0.0, 0.0, 0.8486288287367251, 0.0, 0.32855814988579846, 0.0, 0.18245804065249005, 0.0, 0.42818393986717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9931853020998719, 0.0, 0.9215133919074179, 0.18792238899132097, 0.0, 0.0, 0.0, 0.0, 0.856838642188807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8123907241861509, 0.0824059718619482, 0.0, 0.48564686533427714, 0.0, 0.9262052018843451, 0.0, 0.0, 0.0, 0.08818137131390835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23127992831595545, 0.0, 0.0, 0.0, 0.17712714419825404, 0.0, 0.0, 1.0, 0.0, 0.0, 0.05642585596482286, 0.0, 0.28944089496820824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3071456481042115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6360473423391266, 0.5982068648905755, 0.0, 0.6921258747256326, 0.0, 0.0, 0.0, 0.9324889235898018, 0.9338659428462488, 0.5977762651528876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13924684459410952, 0.3879914700405447, 0.0, 0.6738921474874265, 0.07091595948797924, 0.0, 0.8624965074015853, 0.766927188109165, 0.6951874662100657, 0.6296283449385927, 0.0, 0.0, 0.022410039654956804, 0.5826286460403656, 0.9954741523468144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1674597445179885, 0.0, 0.9667320288306416, 0.0, 0.41586133940794756, 0.0, 0.39675505645552933, 0.4740062659484451, 0.0, 0.1308251425969127, 0.5300624550517324, 0.0, 0.0, 0.18237662169551383, 0.10494339600016689, 0.0, 0.32645342186860915, 0.8626382540313258, 0.0, 0.9539369363180226, 0.0691759250098859, 0.0, 0.0, 0.688428260417771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47870485796552253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.7055627116496911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.749379016724156, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4522024791035387, 0.0, 0.31348605695674747, 0.18492789932419318, 0.8774521266031688, 0.0, 0.671587742938926, 0.0, 0.0, 0.03769772491485279, 0.0, 0.6792754755400424, 0.0, 0.2794453073189026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8781204982186164, 0.9817249302764938, 0.0, 0.0, 0.9918891959474917, 0.04860313802089389, 0.0, 0.0, 0.0, 0.5718448269698801, 0.06142512925983268, 0.0, 0.0, 0.5613524997539452, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6853710910648012, 0.3259824651160327, 1.0, 0.0, 0.7179326909401018, 0.0, 0.32628215156894647, 0.0, 0.0, 0.042739606061951374, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7877143583314087, 0.8844416233193683, 0.8364209229856395, 0.0, 0.0, 0.0, 0.0, 0.6059261954142473, 0.0, 0.12158413695503834, 0.0, 0.7545369159024605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11822241207245987, 0.5985023894351237, 0.7931285379630564, 0.779491212863352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6995965330235282, 0.0, 0.11582308223679427, 0.0, 0.0, 0.17084935971586013, 0.4918582813348057, 0.6202413542689121, 0.0, 0.0, 0.7679699780618315, 1.0, 0.6332632016094104, 0.5497175161684742, 0.0, 0.0, 0.8259409191119182, 0.6965614021440462, 0.0, 0.8203240881472009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24183819541535312, 0.4259975194684281, 0.0, 0.6577653832726, 0.4356046196610104, 0.0, 0.0, 0.47391748158259706, 0.0, 0.0, 0.19316000840843273, 0.5286917254258788, 0.0, 0.6217754847566552, 0.0, 0.0, 0.8006545105288169, 0.0, 0.0, 0.5757858627744116, 0.0, 0.0, 0.6396059599458888, 0.08707120557730819, 1.0, 0.0, 0.20705708338303286, 0.4560268887150325, 0.0, 0.0, 0.6027285271595403, 0.24555062594449106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7176320809573438, 0.0, 0.0, 0.7288698044883412, 0.0, 0.0, 0.0, 0.8902366217957709, 0.1149063433619103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4991989468413318, 0.0, 0.8726258854858964, 0.0, 0.0, 0.30858394248684795, 0.0, 0.0, 0.8293851501423746, 0.0, 0.9172205918248628, 0.446441467337642, 0.0, 0.5691417246177293, 0.0, 0.2748888400666839, 0.0, 0.0, 0.9857682495857412, 1.0, 0.39861592931143663, 0.6607797016082162, 0.4554045512892506, 0.9589318272095946, 1.0, 0.0, 0.0, 0.06250694151041081, 0.6125335361782434, 0.0, 0.0, 0.0, 0.5197057412086442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9731323459550647, 0.6195181145069641, 0.0, 0.4686431682473048, 0.0, 0.0, 0.0, 0.7003313161585092, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5109707430450621, 0.0, 0.0, 0.9779141546988203, 0.0, 0.0, 0.6123048451609933, 0.86163179911181, 0.0, 0.0, 0.0, 0.5076376964803742, 0.0, 0.14444887656412753, 0.0, 0.0, 0.0, 0.4843234489229269, 0.502746113409122, 0.8215839034365042, 0.0, 0.0, 0.6141331761875181, 0.3258245840194487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08426436615585109, 0.0, 0.6803844137625221, 0.0, 0.0, 0.0, 0.2109771554518658, 0.0, 0.0, 0.0, 0.5180771651975611, 1.0, 0.8365308907609035, 0.0, 0.0, 0.0, 0.3062678870046147, 0.7349187156614274, 0.0, 0.19287056868961427, 0.09271481081026989, 0.0, 0.0, 0.8986201575301365, 0.0, 0.0, 0.48227400008154353, 0.05731031001048681, 0.0, 0.7074262751619323, 0.2882220550090505, 0.8983552751676653, 0.41731385344541716, 0.1241073677137774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7511809729800681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25747897614372484, 0.0, 0.0, 0.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5608128090568467E-4, 0.003090781410644672, 0.004362166405191714, 0.008059103342119789, 0.009453967229866578, 0.010090606689024728, 0.014696167712714536, 0.017149781915198115, 0.019891007586233078, 0.02052081472932521, 0.022968323454824024, 0.025237345848264203, 0.02583537137198444, 0.029233793525217044, 0.03273641247363446, 0.03593867492155334, 0.042342278772383835, 0.04300695186693948, 0.043735625879969486, 0.045153006961531905, 0.05010033175392403, 0.050559187959538954, 0.051255604850289016, 0.05260475041355317, 0.056017694636790405, 0.056825177038715036, 0.058727551758148366, 0.06100714300539489, 0.06310903307915017, 0.06919270268351019, 0.07161649436369255, 0.07189816449021347, 0.08220706371178166, 0.08320830929766487, 0.08876739410776846, 0.08991624485970229, 0.09393411431363474, 0.09464012572212965, 0.09624242822485785, 0.09841699471293242, 0.09873720688266585, 0.10493471114875419, 0.10559154597664, 0.10640541354986843, 0.11006328420111522, 0.11113714733201241, 0.11570131818030216, 0.11754055954390019, 0.11800783027836415, 0.12322265417216605, 0.12535647579238562, 0.12627113710773186, 0.12689115723577238, 0.12736947344788108, 0.12960065119544195, 0.130062167102311, 0.13105574772085493, 0.13196531962396174, 0.13264457760095316, 0.13356133247235458, 0.13699906305367138, 0.13801309159572772, 0.14104331457937047, 0.14339537001089253, 0.14386750098625656, 0.14479301498163, 0.14970396795695773, 0.15052149166341355, 0.15232958946453545, 0.1557512975941816, 0.157984338493256, 0.1590250037402613, 0.16679564340332564, 0.16811812839929585, 0.16863229377803002, 0.16931148947992314, 0.17208922929525938, 0.17328534006898166, 0.17623260420087705, 0.1817232932281565, 0.18537277908251149, 0.18903952472753172, 0.19081682886096896, 0.19763922059113015, 0.19865200812619144, 0.19984127128193951, 0.20357837754636043, 0.20730900318755796, 0.20853645911048102, 0.21050770157594767, 0.212098011707735, 0.2136981415703284, 0.21798466506703273, 0.22351069734898188, 0.22740949586137893, 0.22917195121416212, 0.23178359028935003, 0.23341147602835666, 0.2368916363986917, 0.2381163881375561, 0.23914254543452318, 0.2403823886994838, 0.2422312178245669, 0.24251811521058264, 0.24626592957199545, 0.24651990563798298, 0.24854705554065637, 0.25108010366516775, 0.2560475651049543, 0.2590187497254215, 0.2644718166671908, 0.2672526297935953, 0.2695075225177006, 0.2754831486013819, 0.2768505135353705, 0.2828011306704997, 0.28481354521975877, 0.2882515771673685, 0.2898645682019342, 0.2939809923359754, 0.29566503927161913, 0.29639200687528344, 0.30085310835325507, 0.30247902916792657, 0.30752979549045634, 0.3093202288519934, 0.31022115075187884, 0.31296084941751945, 0.3146046565539943, 0.31810444690347206, 0.3204500728660916, 0.3225265851765271, 0.32387460241170973, 0.32415225353566357, 0.3258231175644498, 0.3299674621924332, 0.3322055709473216, 0.3337321385209615, 0.3372271327554204, 0.3409644657963192, 0.34167450189692083, 0.34191741525080965, 0.34361414061523277, 0.3459242046280019, 0.3495747511761357, 0.3524835351566369, 0.3542677648410466, 0.35833465667167375, 0.36346135324664564, 0.3638096411409335, 0.36411277501049943, 0.3645563543404774, 0.3674558900341721, 0.3678405008135426, 0.37324115637923383, 0.37354298032307287, 0.3765302877892983, 0.37961676445167025, 0.381227922958995, 0.3832842396422014, 0.38551422248836875, 0.3872372711780959, 0.3898723529415441, 0.3903689883430981, 0.39385343506652026, 0.39679684708631646, 0.39788417555702305, 0.39910018807372305, 0.4003724315400786, 0.4029042298132802, 0.4051967853222104, 0.40667406999858313, 0.4085932405775119, 0.4095689101773067, 0.41267532608339663, 0.41524097233404045, 0.41644303267518146, 0.41779124023176883, 0.424644596748444, 0.4289849318408905, 0.43377056601801756, 0.43564479045650983, 0.4367110690461853, 0.44122371365532653, 0.4439038323199116, 0.44644192179654874, 0.45086966372282733, 0.45\u001b[0m\n",
      "\u001b[34m30367486286119, 0.4551723424548132, 0.4553831354806076, 0.45746563146774855, 0.45835358178324015, 0.4591892337325618, 0.46144551188731264, 0.46461316880897086, 0.467324113238445, 0.46840053539556914, 0.4695186653456337, 0.469641774680709, 0.4701187389114738, 0.4764612712393995, 0.4769152754182153, 0.47755585459453553, 0.4782598841952235, 0.4870778352252343, 0.4883746289829387, 0.49141817752855677, 0.4929175759397333, 0.4936696906457322, 0.49823600049927297, 0.4992890741633287, 0.5046190246076956, 0.508068899894271, 0.512726394261776, 0.5146575865735116, 0.5156088143991507, 0.5177356387478078, 0.5184506597241457, 0.5199526226899144, 0.5207399100854625, 0.5225397167320532, 0.5243121819890413, 0.5297139661083676, 0.5324811925594262, 0.5333922153027841, 0.5353679411816512, 0.5368852861624885, 0.5415335754307422, 0.5448477590845157, 0.5455968455200472, 0.549309771480104, 0.5509152549890532, 0.5518771364211856, 0.5537987790224563, 0.554356681216369, 0.5615432847494218, 0.5646290509972631, 0.5684648985079399, 0.5725043496432408, 0.5740622915330605, 0.5772497307686131, 0.5810150933751095, 0.584056095418145, 0.5850287845999218, 0.5854839351832077, 0.5861725346792042, 0.5883445395432976, 0.5886254285874106, 0.5902326591508927, 0.594248831384939, 0.5964854749854216, 0.5991205850403252, 0.600899811926277, 0.602553163842865, 0.6038509825402779, 0.6047940736900298, 0.6092716343863868, 0.6129212396643692, 0.6146241169526382, 0.6164281773718701, 0.6193103188391342, 0.6199685648741642, 0.623085835263628, 0.6265374038558266, 0.6284534886801256, 0.6320898295062423, 0.6346392564873805, 0.6363068752438598, 0.6401682238281661, 0.6401983115596238, 0.6416319088273545, 0.6448683522461874, 0.6449589435480417, 0.6466004439486619, 0.6497970089092697, 0.6514263327580295, 0.6540795524983057, 0.6551823922538302, 0.6582175952632383, 0.6591137644695265, 0.6625196743251018, 0.6626890458487724, 0.6649945162377737, 0.6664304505277996, 0.6669651281946016, 0.6696026161339619, 0.6743151979360468, 0.6771524124576737, 0.6773873215187168, 0.6788977250778405, 0.6799401674790165, 0.6803479447079375, 0.6819504274490813, 0.6834132400913489, 0.6837541055770425, 0.6857005429336439, 0.6868367981702229, 0.687728213951204, 0.6899997373089434, 0.6916180555693193, 0.69309548680543, 0.69662727121739, 0.6977562760734295, 0.700251959444521, 0.70327235889591, 0.7076883263306187, 0.708855752214821, 0.710029881056391, 0.712673283491098, 0.7215292710724477, 0.7221548367934345, 0.7242425955587187, 0.7244520607805166, 0.7256153947974125, 0.731031968404614, 0.7322233245116658, 0.736200425060762, 0.7394082298313118, 0.7430815396313801, 0.7457387685551354, 0.7462072574818386, 0.7517721730390933, 0.7537139811894684, 0.759344327922866, 0.7625963946941753, 0.7658290392349099, 0.7685998047885084, 0.7730890416974662, 0.7737208917857682, 0.7743026829445951, 0.775911532807306, 0.7795163065266959, 0.78019465117681, 0.780731853200901, 0.7815056477421821, 0.7820912917479865, 0.7839486349883128, 0.7856431035291273, 0.7881056695598909, 0.7905205102716735, 0.7933940143053477, 0.7935706545388016, 0.7945985915219707, 0.7959753342614213, 0.7963328622273151, 0.801684293191305, 0.8048028354281175, 0.8058445326178331, 0.806589342326277, 0.8082754395559376, 0.8087899845635385, 0.8088812905039974, 0.8093243982852624, 0.8121571474622259, 0.8132767042269585, 0.8194817716075764, 0.8236064207981895, 0.8251306676661152, 0.8278683753221728, 0.8333170714730125, 0.834590952595272, 0.8354078308421259, 0.839816162145531, 0.8407125547571949, 0.843924612611724, 0.8461929753583922, 0.8506802606048463, 0.8542607889973357, 0.8564934027625736, 0.8577447602231846, 0.8639615807350102, 0.8683464112067416, 0.8700700754642987, 0.8720483384470077, 0.8738749555210183, 0.8748747428582531, 0.8779844969848348, 0.8787692497929145, 0.881125608822928, 0.8829339585758313, 0.8839773186518307, 0.8858600306903679, 0.8887912526617813, 0.8911066860189609, 0.8936627026517728, 0.894632466047194, 0.8972517475475766, 0.9004534871912249, 0.9030937278765383, 0.9039133302603747, 0.9064209639144368, 0.9103736608450579, 0.9129310047746899, 0.9147311149565036, 0.916603301642411, 0.9202971812194077, 0.9228548314604181, 0.9242870707946612, 0.9292884022620594, 0.9316590644677396, 0.933571083457648, 0.9363211539691568, 0.9370910284587948, 0.9423153896731928, 0.9471960395314719, 0.9519076895879646, 0.9532141550282315, 0.9559596206115356, 0.9601677847287454, 0.9682215156426756, 0.9696077268480954, 0.9724199990401033, 0.9760326986002038, 0.9796467150338835, 0.984234499234434, 0.9885075267018847, 0.9902088935876214, 0.9912632267336332, 0.9920355952545489, 0.9961229496394411, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06151702623923505, 0.12297080852962672, 0.16637758693227234, 0.27811237207306494, 0.33637046382842206, 0.38705582513439407, 0.4386072164895384, 0.5156015524259594, 0.5902639388856225, 0.6400029668369137, 0.7457754201025067, 0.8306425177506246, 0.8841989781315029, 0.9443036349578299, 0.9963357758067243, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_vehicles_involved\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.8342063588744062,\n",
      "      \"sum\" : 15057.0,\n",
      "      \"std_dev\" : 0.8031606202381528,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 7.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.6,\n",
      "            \"count\" : 3138.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.6,\n",
      "            \"upper_bound\" : 2.2,\n",
      "            \"count\" : 3563.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.2,\n",
      "            \"upper_bound\" : 2.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.8,\n",
      "            \"upper_bound\" : 3.4,\n",
      "            \"count\" : 1267.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.4,\n",
      "            \"upper_bound\" : 4.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.0,\n",
      "            \"upper_bound\" : 4.6,\n",
      "            \"count\" : 217.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.6,\n",
      "            \"upper_bound\" : 5.2,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.2,\n",
      "            \"upper_bound\" : 5.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.8,\n",
      "            \"upper_bound\" : 6.4,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.4,\n",
      "            \"upper_bound\" : 7.0,\n",
      "            \"count\" : 0.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0 ], [ 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0 ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3\u001b[0m\n",
      "\u001b[34m.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_month\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 6.739432330369107,\n",
      "      \"sum\" : 55324.0,\n",
      "      \"std_dev\" : 3.3316250379400643,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 12.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 2.1,\n",
      "            \"count\" : 1188.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.1,\n",
      "            \"upper_bound\" : 3.2,\n",
      "            \"count\" : 619.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.2,\n",
      "            \"upper_bound\" : 4.3,\n",
      "            \"count\" : 569.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.3,\n",
      "            \"upper_bound\" : 5.4,\n",
      "            \"count\" : 683.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.4,\n",
      "            \"upper_bound\" : 6.5,\n",
      "            \"count\" : 669.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.5,\n",
      "            \"upper_bound\" : 7.6,\n",
      "            \"count\" : 688.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.6,\n",
      "            \"upper_bound\" : 8.7,\n",
      "            \"count\" : 773.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 8.7,\n",
      "            \"upper_bound\" : 9.8,\n",
      "            \"count\" : 889.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 9.8,\n",
      "            \"upper_bound\" : 10.9,\n",
      "            \"count\" : 927.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 10.9,\n",
      "            \"upper_bound\" : 12.0,\n",
      "            \"count\" : 1204.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 4.0, 10.0, 9.0, 9.0, 6.0, 6.0, 3.0, 3.0, 2.0, 5.0, 2.0, 8.0, 10.0, 11.0, 5.0, 9.0, 4.0, 2.0, 10.0, 6.0, 7.0, 7.0, 2.0, 10.0, 7.0, 9.0, 5.0, 6.0, 9.0, 1.0, 9.0, 9.0, 7.0, 9.0, 10.0, 10.0, 7.0, 6.0, 9.0, 11.0, 9.0, 9.0, 10.0, 9.0, 5.0, 11.0, 7.0, 9.0, 9.0, 1.0, 3.0, 9.0, 9.0, 9.0, 4.0, 6.0, 10.0, 6.0, 9.0, 7.0, 6.0, 1.0, 10.0, 7.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 4.0, 8.0, 5.0, 9.0, 1.0, 3.0, 9.0, 5.0, 9.0, 11.0, 6.0, 11.0, 11.0, 5.0, 6.0, 5.0, 5.0, 5.0, 8.0, 8.0, 12.0, 8.0, 9.0, 9.0, 7.0, 12.0, 12.0, 5.0, 5.0, 4.0, 7.0, 12.0, 5.0, 5.0, 9.0, 11.0, 6.0, 7.0, 11.0, 8.0, 8.0, 1.0, 3.0, 6.0, 10.0, 6.0, 5.0, 9.0, 11.0, 9.0, 2.0, 9.0, 5.0, 4.0, 4.0, 10.0, 5.0, 10.0, 9.0, 5.0, 9.0, 9.0, 1.0, 3.0, 4.0, 7.0, 6.0, 11.0, 4.0, 8.0, 9.0, 1.0, 5.0, 3.0, 5.0, 12.0, 8.0, 10.0, 9.0, 7.0, 4.0, 9.0, 10.0, 9.0, 6.0, 5.0, 2.0, 10.0, 5.0, 8.0, 8.0, 10.0, 4.0, 1.0, 1.0, 6.0, 8.0, 5.0, 6.0, 6.0, 1.0, 9.0, 3.0, 7.0, 5.0, 9.0, 9.0, 10.0, 7.0, 8.0, 7.0, 5.0, 6.0, 5.0, 5.0, 9.0, 2.0, 9.0, 4.0, 6.0, 11.0, 5.0, 10.0, 7.0, 11.0, 6.0, 6.0, 3.0, 10.0, 5.0, 6.0, 6.0, 12.0, 8.0, 9.0, 9.0, 5.0, 9.0, 8.0, 6.0, 9.0, 5.0, 8.0, 6.0, 8.0, 9.0, 1.0, 7.0, 5.0, 10.0, 9.0, 11.0, 10.0, 11.0, 7.0, 8.0, 12.0, 4.0, 3.0, 8.0, 10.0, 9.0, 5.0, 7.0, 12.0, 1.0, 12.0, 9.0, 6.0, 10.0, 9.0, 12.0, 2.0, 10.0, 8.0, 8.0, 8.0, 3.0, 11.0, 3.0, 8.0, 5.0, 7.0, 1.0, 5.0, 7.0, 2.0, 4.0, 10.0, 8.0, 10.0, 12.0, 10.0, 9.0, 12.0, 9.0, 4.0, 9.0, 7.0, 9.0, 3.0, 2.0, 7.0, 10.0, 11.0, 7.0, 11.0, 5.0, 9.0, 10.0, 11.0, 1.0, 5.0, 8.0, 8.0, 9.0, 5.0, 11.0, 5.0, 7.0, 1.0, 8.0, 7.0, 10.0, 9.0, 10.0, 4.0, 12.0, 1.0, 7.0, 7.0, 7.0, 2.0, 5.0, 11.0, 2.0, 5.0, 6.0, 7.0, 4.0, 6.0, 3.0, 9.0, 5.0, 11.0, 10.0, 6.0, 8.0, 2.0, 9.0, 8.0, 1.0, 2.0, 8.0, 1.0, 2.0, 9.0, 11.0, 5.0, 10.0, 10.0, 9.0, 4.0, 9.0, 10.0, 9.0, 10.0, 11.0, 7.0, 10.0, 6.0, 3.0, 4.0, 2.0, 3.0, 3.0, 9.0, 3.0, 7.0, 7.0, 5.0, 11.0, 10.0, 8.0, 10.0, 10.0, 12.0, 10.0, 3.0, 5.0, 5.0, 11.0, 9.0, 2.0, 7.0, 9.0, 10.0, 8.0, 8.0, 5.0, 6.0, 7.0, 6.0, 9.0, 9.0, 10.0, 8.0, 9.0, 8.0, 12.0, 3.0, 10.0, 7.0, 11.0, 9.0, 12.0, 11.0, 5.0, 7.0, 8.0, 5.0, 6.0, 1.0, 7.0, 4.0, 4.0, 9.0, 10.0, 8.0, 3.0, 6.0, 11.0, 9.0, 7.0, 5.0, 9.0, 3.0, 10.0, 9.0, 8.0, 9.0, 11.0, 9.0, 8.0, 8.0, 9.0, 10.0, 11.0, 10.0, 9.0, 6.0, 1.0, 10.0, 5.0, 10.0, 6.0, 1.0, 10.0, 9.0, 6.0, 8.0, 10.0, 7.0, 10.0, 12.0, 5.0, 8.0, 11.0, 8.0, 6.0, 8.0, 11.0, 8.0, 5.0, 8.0, 10.0, 7.0, 9.0, 4.0, 4.0, 8.0, 8.0, 6.0, 9.0, 10.0, 7.0, 1.0, 3.0, 11.0, 9.0, 6.0, 10.0, 5.0, 9.0, 1.0, 2.0, 8.0, 5.0, 1.0, 8.0, 6.0, 1.0, 1.0, 2.0, 7.0, 3.0, 9.0, 1.0, 10.0, 8.0, 3.0, 5.0, 6.0, 8.0, 7.0, 3.0, 10.0, 10.0, 3.0, 6.0, 9.0, 10.0, 4.0, 9.0, 3.0, 4.0, 10.0, 9.0, 6.0, 6.0, 10.0, 10.0, 10.0, 9.0, 6.0, 8.0, 6.0, 10.0, 10.0, 7.0, 10.0, 10.0, 12.0, 3.0, 11.0, 4.0, 11.0, 2.0, 2.0, 9.0, 11.0, 2.0, 5.0, 6.0, 8.0, 9.0, 9.0, 11.0, 9.0, 6.0, 3.0, 7.0, 10.0, 7.0, 6.0, 9.0, 10.0, 9.0, 7.0, 12.0, 2.0, 8.0, 9.0, 8.0, 5.0, 2.0, 6.0, 9.0, 7.0, 8.0, 9.0, 10.0, 10.0, 2.0, 9.0, 4.0, 9.0, 10.0, 7.0, 11.0, 12.0, 6.0, 6.0, 8.0, 4.0, 7.0, 11.0, 3.0, 8.0, 9.0, 5.0, 6.0, 6.0, 11.0, 2.0, 7.0, 9.0, 4.0, 9.0, 4.0, 5.0, 4.0, 8.0, 6.0, 7.0, 5.0, 7.0, 7.0, 10.0, 9.0, 3.0, 8.0, 6.0, 6.0, 10.0, 3.0, 2.0, 11.0, 1.0, 8.0, 9.0, 10.0, 8.0, 1.0, 8.0, 7.0, 6.0, 11.0, 10.0, 9.0, 8.0, 12.0, 6.0, 10.0, 7.0, 7.0, 7.0, 6.0, 1.0, 8.0, 4.0, 8.0, 3.0, 7.0, 10.0, 3.0, 5.0, 5.0, 4.0, 9.0, 10.0, 9.0, 11.0, 9.0, 7.0, 10.0, 10.0, 6.0, 1.0, 5.0, 10.0, 6.0, 9.0, 10.0, 9.0, 2.0, 4.0, 3.0, 4.0, 10.0, 9.0, 8.0, 4.0, 10.0, 5.0, 6.0, 3.0, 1.0, 6.0, 9.0, 7.0, 4.0, 5.0, 7.0, 7.0, 1.0, 4.0, 5.0, 11.0, 9.0, 8.0, 4.0, 3.0, 8.0, 11.0, 6.0, 4.0, 4.0, 1.0, 3.0, 9.0, 8.0, 7.0, 8.0, 11.0, 2.0, 9.0, 9.0, 1.0, 5.0, 10.0, 9.0, 7.0, 7.0, 8.0, 10.0, 7.0, 12.0, 4.0, 5.0, 10.0, 12.0, 12.0, 11.0, 9.0, 12.0, 10.0, 9.0, 10.0, 7.0, 4.0 ], [ 12.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0 ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, \u001b[0m\n",
      "\u001b[34m10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_type_theft\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.05253115155949086,\n",
      "      \"sum\" : 431.2282231518605,\n",
      "      \"std_dev\" : 0.20218735444677188,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7606.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 39.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 41.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 36.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 53.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 53.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 45.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 45.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 33.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 258.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.2181743295932732, 0.0, 0.0, 0.4453865259778722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8372372182218181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38510260282302966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5532906396230001, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7567580902469283, 0.6805581617791014, 0.0, 0.9408941791243455, 0.6907263151132631, 0.0, 0.0, 0.0, 0.9088593605553225, 0.0, 0.0, 0.0, 0.0, 0.6688535108358502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8852464005861646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5218843281579432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9408229281364582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12757017457137088, 0.0, 0.6456228170138647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34985438418085446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5875969395321339, 0.19575560640562462, 0.5131750822820359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.327420958733448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40595053443318885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9853910028911171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7064652075413396, 0.0, 0.6672191310392045, 0.0, 0.2929847057274092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41626278068790734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9652096385457352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31326647658061035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17478862874036893, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07379479811565492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6693569842407483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7105591050317918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0661340571537512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056162009903313104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016437571124496841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5129793498209074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07300359289962732, 0.0, 0.0, 0.23449947767409374, 0.0, 0.917840883093553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8150721006758068, 0.0, 0.0, 0.0, 0.0, 0.534966673409444, 0.0, 0.1919321828839774, 0.0, 0.0, 0.0, 0.0, 0.11349747335809746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06864866614787224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7760754122034105, 0.0, 0.0, 0.0, 0.8078656456839812, 0.0, 0.0, 0.0, 0.0, 0.7088991127733161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7163920765828637, 0.6737178484310535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5024656497627655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.170178735282715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.969615938904338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5036886093282389, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23203002193816846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07592701115431688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7581618045846469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7126656189865445, 0.8068399915915673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7929429166169671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8885123121612181, 0.0, 0.0, 0.0, 0.7597805667916144, 0.5562286609077549, 0.0, 0.0, 0.0, 0.27113019551165884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0038371455078008987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17061484985762543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16706260768133896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6617038454813468, 0.21912606467080087, 0.0, 0.59643395462566, 0.48468951693630746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2996686838414908, 0.0, 0.0, 0.0, 0.680672373225737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06327544414650987, 0.0, 0.0, 0.0, 0.10815501457335674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8514057478914739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4819228348024389, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5177259999184565, 0.9426896899895132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7211323573568237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0023771777486145673, 0.008257382832161153, 0.024820024024491683, 0.042291749222681196, 0.044387772170854434, 0.07211109292943518, 0.08919732903018673, 0.0913741048604092, 0.09216795847243231, 0.09357903608556317, 0.09446116207109889, 0.1021495296575381, 0.11196093563988219, 0.1147969272512801, 0.12736419745316474, 0.12982644895171758, 0.1457392110026643, 0.14798414736583476, 0.15177540985110205, 0.16493405454498, 0.16735973313862795, 0.17213162467782717, 0.1771709252718655, 0.19415546738216694, 0.20975294768368136, 0.21111247116613618, 0.21794923073624173, 0.22190046078437287, 0.22701327869441323, 0.2358575991436871, 0.23740360530582472, 0.24347796840486724, 0.24997158785780882, 0.2637601898661669, 0.26896803159538596, 0.27136596353901055, 0.27812915548661243, 0.28490802153096084, 0.299748040555479, 0.3024474782893799, 0.306051463522788, 0.30869874337319525, 0.32261267848128317, 0.33314557898573216, 0.3375324658838189, 0.34184728549809207, 0.3518949654658766, 0.35423624044477453, 0.3573253423275764, 0.3607725191105998, 0.36709366932156584, 0.3772677177071667, 0.3803005598005843, 0.3898997462910806, 0.3936290555666244, 0.40244663743366893, 0.4072290591298152, 0.41533190983417523, 0.42268911339618953, 0.423944812913302, 0.43108686262328944, 0.4353709490027369, 0.44123405537560234, 0.4453426519649044, 0.45281371421091676, 0.4549188895075871, 0.45896347937729864, 0.46317271675134175, 0.46497449540106717, 0.4683301859338135, 0.47028603389163237, 0.4740064284831559, 0.4764135147785471, 0.49141817752855677, 0.49750912317306795, 0.5039521613201134, 0.5074463661197421, 0.5116357178950771, 0.5153984129811353, 0.5208167705564001, 0.5235166162217073, 0.5332179227688121, 0.54140205648616, 0.5438057278662374, 0.5474148403797259, 0.5494142384304533, 0.5504717771029405, 0.5535580782034513, 0.5644410906788825, 0.575355403251556, 0.5850784422062031, 0.5930145003605977, 0.5952015709148002, 0.5975533625663311, 0.602115824442977, 0.6072062241906566, 0.6139794562733938, 0.6203832355483297, 0.6218992302125492, 0.624425446471728, 0.6292988060107362, 0.6428189148001743, 0.6529496581378422, 0.6586921462074435, 0.6720560387522534, 0.6741768824355502, 0.6874063641362376, 0.6889975052673197, 0.6899154616572449, 0.6995106143995676, 0.7015650876381233, 0.7061585021190541, 0.7094124401936449, 0.7176357859086295, 0.7219292275156795, 0.7309803532016895, 0.7338319874844625, 0.743256503690242, 0.7502278375534802, 0.7628933355543641, 0.7651603288167663, 0.7704472210739898, 0.7808825205300616, 0.7830166373167329, 0.784499241132449, 0.7848618229588802, 0.7985932723827512, 0.8106859279862663, 0.8281168290063428, 0.8394609095007669, 0.8502960320430423, 0.8525849549383427, 0.8643116822077207, 0.8649198537742393, 0.869937832897689, 0.8767674242836752, 0.8821356142820601, 0.894265118256414, 0.9186777969935043, 0.9235831405619486, 0.9256373300253358, 0.9292573980072293, 0.9309704591121504, 0.9405284311327192, 0.9444749671908494, 0.9534994135599345, 0.9546600300333075, 0.9620184367101465, 0.9867489664960895, 0.9946841651964872, 0.9978961568241166, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      " 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048450025644673045, 0.15734065970252598, 0.24630116594948082, 0.4032613611238318, 0.4673974805992379, 0.580112229695468, 0.6659911212547621, 0.8962213026850383, 0.9786312874005304, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_none\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.2795973513272215,\n",
      "      \"sum\" : 2295.2146570451614,\n",
      "      \"std_dev\" : 0.4113106016498802,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 5268.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 155.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 178.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 159.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 167.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 163.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 144.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 139.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 177.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 1659.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.5035469815118861, 0.9318909752764775, 0.0, 0.9353781613071173, 0.533883707341511, 0.5546134740221278, 1.0, 1.0, 0.8662924359821813, 1.0, 0.41512493953472107, 0.9856690941329987, 0.47833548167055584, 0.0, 0.8196095530657999, 1.0, 1.0, 1.0, 0.0, 0.5429981326052693, 0.6261918911329976, 0.0, 1.0, 1.0, 0.0, 0.755838391283847, 0.0, 0.6148973971769703, 0.0, 0.0, 0.0, 0.0, 1.0, 0.525565106379265, 0.0, 0.9741906071368183, 0.44670936037699993, 0.0, 0.005418010964740039, 0.0, 0.0, 0.11354064232628669, 0.0, 0.7778112444584507, 0.8223391114568475, 0.09723621203549127, 0.0, 0.5488068085492763, 0.0, 1.0, 1.0, 0.5484344133944249, 1.0, 1.0, 0.7964843893295808, 0.2432419097530717, 0.31944183822089856, 0.0, 0.059105820875654524, 0.0, 0.728786222256576, 0.0, 0.9280517502288481, 0.0, 0.7140994662287976, 0.0, 0.16987259440447633, 1.0, 0.3311464891641498, 0.7659715748551791, 0.0, 0.0, 0.0, 0.9777815179744196, 0.0, 0.0, 0.03219726235151499, 0.5498641783643982, 0.03684097293493349, 0.11475359941383545, 0.0, 0.8304959081339414, 0.0, 0.0, 0.7922165790383086, 0.0, 0.0, 0.0, 0.21836744194675284, 0.43705152184218765, 0.6277454148973364, 0.0, 0.0, 0.6750772055933587, 0.0, 0.03838419295383433, 0.0, 0.0, 0.0, 0.7396828977631081, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.47811567184205683, 0.9320267001805963, 0.8187744389502905, 0.9571969635192346, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3671973893384931, 0.7689200445711684, 1.0, 0.9889214474056903, 0.0, 1.0, 0.0, 0.8724298254286291, 0.0, 0.0, 0.6971701110212578, 0.0, 0.7007255212842638, 0.0, 1.0, 0.0, 1.0, 0.6559033130983996, 0.801185939062597, 0.3150105071834246, 0.0, 1.0, 0.8274987416356734, 0.0, 0.4730275033430207, 0.956684726745688, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.31730547742048654, 0.9119595841996332, 0.0, 0.0, 0.0, 1.0, 0.0, 0.9080150893749742, 0.7574217339261748, 0.09130880254467022, 0.3186896039905236, 0.8953240294644667, 1.0, 0.5738505979750267, 0.9390980669005067, 0.969069118606434, 0.2855858985295022, 0.3616470948410445, 0.8746246507661267, 0.0, 1.0, 0.2755365671408512, 0.0, 0.12169530672667228, 1.0, 0.0, 0.6269684345287165, 0.0, 0.6116464193899924, 0.0, 0.7442562984516996, 0.672579041266552, 0.16462051323650484, 0.18117185085002008, 0.0, 0.615267423492555, 0.0, 0.5940494655668112, 0.41034650484845236, 0.0, 0.0, 0.8226734467760606, 0.0, 0.0, 1.0, 1.0, 0.01460899710888286, 0.0, 0.6048394293625812, 0.6125487040774613, 1.0, 0.6911977246503846, 0.29353479245866043, 1.0, 0.3327808689607955, 1.0, 0.0, 1.0, 0.8077178199814796, 0.11408600450257511, 0.18392095765664873, 1.0, 0.7359179535519887, 0.0, 0.13292804270798264, 0.3615112152008645, 0.0, 0.9428828366295567, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5837372193120927, 1.0, 0.0, 0.9597110542654579, 0.0, 0.0, 0.0683020263188312, 1.0, 0.0, 0.9162750621546516, 0.38593951093692735, 1.0, 1.0, 0.0, 0.15188617233663027, 0.6714418501142015, 0.05446604736683758, 0.0, 0.03479036145426484, 0.5718160601328272, 0.0, 0.7261112593446369, 0.0, 0.14722707441051697, 0.20658101622178082, 0.0, 0.0, 0.0, 0.006814697900128119, 0.47659281493252814, 0.07848660809258212, 0.0, 0.8252113712596311, 0.20494198239386885, 0.32373082561042366, 0.0, 0.0, 0.0, 1.0, 0.9744302009102653, 1.0, 0.0, 1.0, 0.18760927581384912, 0.9175940281380518, 1.0, 1.0, 1.0, 0.0, 0.1286847527531465, 0.21491634276024296, 0.0, 0.9118186286860916, 0.9024923075361247, 1.0, 0.6718399276463922, 0.0, 0.3306430157592517, 0.7687200716840445, 0.0, 0.6939528337712285, 0.9363152324974833, 0.822872855801746, 0.9948603724144397, 1.0, 0.9157446225820287, 0.0, 0.23562285119164839, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6249797483760352, 0.0, 0.0, 0.14032041491966707, 0.9594721829554119, 0.7822874870218485, 0.0, 0.8054649668315159, 0.8205521392557188, 1.0, 0.36395265766087337, 0.4017931351094245, 0.4221720284885643, 0.3078741252743674, 0.5227999205820387, 1.0, 0.9812415974554621, 0.06751107641019816, 0.0, 0.4022237348471124, 0.0, 0.29436460363101846, 0.07780807194871575, 1.0, 0.0, 0.8607531554058905, 0.6120085299594553, 0.0, 0.32610785251257346, 0.9290840405120208, 0.0, 0.13750349259841466, 0.0, 0.0, 0.37037165506140735, 0.0, 0.8677120523489618, 0.9775899603450432, 0.0, 0.0, 1.0, 0.2215172721131058, 0.9438379900966869, 1.0, 0.5275636489994199, 0.0, 0.8325402554820115, 0.0, 0.0, 0.0, 0.5841386605920524, 0.0, 0.0, 0.5259937340515549, 0.5487333859268856, 0.8691748574030873, 0.0, 1.0, 0.0, 0.8176233783044862, 0.8950566039998331, 0.8532424691971175, 0.0, 0.0, 0.0, 0.046063063681977434, 0.9308240749901141, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.37641496252069395, 0.0, 0.0, 1.0, 0.10540528595616694, 0.5538234406337256, 0.0, 1.0, 0.17777188742298944, 0.0, 1.0, 0.0, 0.0, 0.23184129171472645, 0.2944372883503089, 0.6922971866101562, 0.0, 0.0, 0.2559714196523233, 0.0, 0.7655005223259063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27450667350707825, 1.0, 0.08116422446371452, 0.5477975208964613, 1.0, 0.0, 0.0, 0.12254787339683115, 0.0, 0.0, 0.0, 0.46503332659055596, 0.9623022750851472, 0.8080678171160226, 0.3207245244599576, 0.5624293741179209, 0.0, 0.0, 0.0, 0.601357505786936, 0.862922393510989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12187950178138363, 0.018275069723506232, 0.09586464742180933, 0.9313513338521278, 0.0, 0.0, 1.0, 0.4624153743074342, 0.0, 0.42815517303011985, 0.0, 0.22392458779658952, 1.0, 0.4386475002460548, 0.022503741791106813, 0.19213435431601877, 0.2625900556880538, 0.5370413147419743, 0.0, 0.0, 0.0, 1.0, 0.3146289089351988, 0.6740175348839673, 0.0, 0.0, 0.2820673090598982, 0.0, 0.32628215156894647, 0.02075803212396421, 1.0, 0.0, 0.1353476453972543, 0.0, 0.0, 0.5234735291677627, 0.0, 0.0, 1.0, 0.0, 0.21228564166859132, 1.0, 0.16357907701436047, 0.0, 0.0, 0.0, 0.0, 0.3940738045857527, 0.0, 0.8784158630449617, 0.0, 0.24546308409753947, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8817775879275401, 0.0, 0.0, 0.220508787136648, 1.0, 0.9508186599164314, 0.2098976295862307, 0.26091857965016807, 0.0, 0.2652914297349743, 0.0, 0.0, 0.8841769177632057, 0.0, 0.4963113906717611, 0.8291506402841399, 0.5081417186651943, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3667367983905896, 0.0, 0.0, 1.0, 0.17405908088808175, 0.0, 0.0, 0.0, 1.0, 0.32859392735626314, 0.073691723078804, 0.0, 1.0, 0.3111894964100129, 0.0, 0.0, 0.5740024805315719, 0.032257175166284346, 0.0, 0.0, 0.9329566255282273, 0.5865117810374487, 0.526082518417403, 0.0, 0.28733438101345554, 0.0, 0.47130827457412117, 0.0, 0.0, 1.0, 0.0, 0.19934548947118313, 0.5876335127253189, 0.0, 0.42421413722558843, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5439731112849675, 1.0, 0.1510761305239272, 0.0, 0.0, 0.8123261802470616, 0.34283896480545073, 0.11148768783878193, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3014630594588007, 0.5993729928719863, 0.7987362118655276, 0.1097633782042291, 0.0, 0.0, 0.49799180226081785, 0.0, 1.0, 0.05451192743782629, 1.0, 0.5008010531586682, 0.0, 0.0, 0.08710928946143404, 0.5126155583279571, 0.691416057513152, 1.0, 0.0, 0.0, 0.0, 0.0, 0.553558532662358, 1.0, 0.0, 0.31219188378638796, 0.7251111599333161, 0.0, 0.0, 0.0, 0.0, 0.6013840706885634, 0.3392202983917838, 0.5445954487107494, 1.0, 0.0, 0.5540444549078982, 0.02002322973218762, 0.0, 0.38746646382175665, 0.4165784809815649, 1.0, 0.0, 0.4802942587913558, 0.33829615451865325, 0.7808739353291991, 0.11284318718362141, 0.0, 0.5153104830636925, 1.0, 0.0, 1.0, 0.5313568317526952, 0.39577767966043076, 1.0, 0.0, 0.7003313161585092, 0.0, 0.0, 1.0, 0.31932762677426296, 0.0, 0.48902925695493793, 0.4287642911146835, 0.053781964177377906, 0.02208584530117974, 0.0, 0.0, 0.0, 0.13836820088819002, 0.0, 0.14303558522376103, 0.06128536462596501, 0.49236230351962584, 1.0, 0.8555511234358725, 0.0, 0.0, 0.9367245558534901, 0.0, 0.497253886590878, 0.17841609656349577, 0.8918449854266433, 0.0, 0.0, 0.6741754159805513, 0.8082637826097335, 0.0, 0.5839192892611353, 0.7930063987549418, 0.14859425210852606, 0.0, 0.0, 0.3196155862374779, 1.0, 0.17232480521872817, 1.0, 0.7890228445481342, 1.0, 0.8594528720044571, 0.7135262622554164, 0.0, 0.0, 0.16346910923909652, 0.0, 0.0, 0.0, 0.6937321129953853, 0.2650812843385726, 1.0, 0.8071294313103857, 0.9072851891897301, 0.0, 0.1783584302210447, 0.0, 0.7918913237957292, 0.0, 0.0, 0.05731031001048681, 0.1745898512471864, 0.29257372483806765, 0.0, 0.10164472483233467, 0.0, 0.8758926322862226, 0.8785850944950279, 0.2788676426431763, 0.0, 0.6716145003833947, 0.0, 0.9752351224238488, 0.24881902701993186, 1.0, 0.7203636815067938, 0.13637032746756583, 0.0, 0.18685234483201507, 0.7425210238562752, 0.22558050539369667, 1.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0031409060481221163, 0.0034343437110175845, 0.00566581452956727, 0.00608874823983907, 0.008411591129726004, 0.010243586590665377, 0.011480659749377842, 0.012907227980991975, 0.01340262643216561, 0.013698550408914545, 0.015508330626592182, 0.015823171996820817, 0.01794567856849183, 0.02104249295889593, 0.023967301399796193, 0.02583537137198444, 0.027519185140415292, 0.029257846322751857, 0.030392273151904625, 0.031778484357324444, 0.03280962412860844, 0.03773855339084331, 0.040173481924071, 0.042837555119113246, 0.04417551627924776, 0.04605673418995637, 0.04678584497176852, 0.0496872470694083, 0.05079137312948778, 0.05190094358730901, 0.05335556600645375, 0.055334267828904826, 0.05745406032309475, 0.058454614108553904, 0.059716488970889325, 0.06367884603084317, 0.06642891654235195, 0.06871283251826776, 0.07057330552688601, 0.0713397129851171, 0.074042217912348, 0.07462981433708171, 0.07566110390411085, 0.07737694191221034, 0.08132220300649573, 0.083396698357589, 0.08526888504349639, 0.08703896258765864, 0.08893129723261639, 0.0969062721234617, 0.0982349921890805, 0.09859423024193648, 0.10392488820542667, 0.10601479495303923, 0.10761418475985884, 0.10994297453474744, 0.11153589007707931, 0.11230434441121917, 0.11428576999797946, 0.11706604142416865, 0.1177414439051524, 0.11854922032497861, 0.12017808604830471, 0.12123075020708551, 0.12201550301516517, 0.12264438779473996, 0.12438283124132432, 0.12612504447898165, 0.1271997626874496, 0.1279516615529923, 0.13105574772085493, 0.13237237903497245, 0.13603841926498983, 0.13699095393277305, 0.13788526935601042, 0.14043476835305424, 0.14394191357223085, 0.14691037659634953, 0.14741504506165726, 0.14821746209932463, 0.14952838523916234, 0.14970396795695773, 0.1520721162366515, 0.1528326386274258, 0.15380702464160778, 0.16253798746870785, 0.16368380146530148, 0.16693107081750147, 0.17060837304148746, 0.17112872374704136, 0.17208603245262644, 0.17351190980423759, 0.17639357920181054, 0.17788812404902343, 0.1781935560989132, 0.18173919070946298, 0.1832430698804719, 0.18981530297215599, 0.19081682886096896, 0.19121001543646154, 0.1917245604440624, 0.19324941523416816, 0.19524687801030516, 0.19831570680869504, 0.20140672761724876, 0.20366713777268486, 0.20444057394954684, 0.20498120952681642, 0.20618616451842642, 0.20747860803708085, 0.20947948972832653, 0.21228698447229133, 0.21462807325880284, 0.21513817704111982, 0.2162270091277797, 0.21649991915474331, 0.21790870825201347, 0.21865115938559376, 0.219268146799099, 0.22001167308945568, 0.22306206154275687, 0.22370952248405218, 0.22408846719269404, 0.22627525081659983, 0.22633743510433424, 0.22955277892601023, 0.23148063547620878, 0.232055739701156, 0.23417096076509014, 0.2352355848019848, 0.23740360530582472, 0.23915877778224304, 0.24251811521058264, 0.24516218005915225, 0.24613492616307497, 0.24628601881053158, 0.25264603062128665, 0.25363555551403827, 0.2540747911863255, 0.25424662092387396, 0.2565762139233907, 0.25691846036861987, 0.2590187497254215, 0.26193087666148285, 0.26542207687858677, 0.26616801251553746, 0.26758613518733143, 0.26868348029670375, 0.26884674245284335, 0.27028809350257776, 0.27154704741124236, 0.27304061932780677, 0.27514350068498294, 0.2757574044412813, 0.2778451632065655, 0.27893807607347676, 0.2802085466453139, 0.2803344607915209, 0.28236421409137047, 0.2853587250912758, 0.2856995940447645, 0.28703999214119424, 0.28722232378316903, 0.289970118943609, 0.2909862757129682, 0.29151030250720267, 0.29426673663711433, 0.2968692745602808, 0.2984349123618767, 0.2988571352590308, 0.3018015693235002, 0.3022437239265705, 0.30337272878261, 0.3072389618477205, 0.30990344176215656, 0.31100249473268027, 0.31180213695576864, 0.3142994570663561, 0.3153738057350337, 0.31654966526787, 0.31753144787673704, 0.3180495725509187, 0.32005983252098347, 0.32284758754232634, 0.32485993885033193, 0.3256848020639532, 0.32675356064546845, 0.32838122788508106, 0.3332280902161028, 0.3350054837622263, 0.33748032567489816, 0.33885932\u001b[0m\n",
      "\u001b[34m15713035, 0.34366319260910305, 0.34460408444755963, 0.3460059076601988, 0.3466165015213194, 0.34809913443753937, 0.3502029910907303, 0.3518050064103525, 0.3533995560513381, 0.35390987653749195, 0.35504105645195827, 0.35836809117264545, 0.3598016884403762, 0.3620392066840299, 0.3621762547987283, 0.3639575312200317, 0.3647982191445295, 0.36559570100396677, 0.36681037398653593, 0.36791017049375774, 0.369299528841215, 0.3715659525810011, 0.3720066173959019, 0.37479523046955776, 0.3756722518817265, 0.3769855419262801, 0.37909140978229194, 0.3809095255109872, 0.3822522519774584, 0.38357182262812994, 0.38561351286564804, 0.3876735947503942, 0.38962250468167237, 0.39072836561361324, 0.3927937758093434, 0.3952059263099702, 0.39717877742921104, 0.39785435594751895, 0.39910018807372305, 0.3999052068041562, 0.40144563091319363, 0.40244663743366893, 0.405751168615061, 0.4065142370240653, 0.40763285797965576, 0.4081190568259231, 0.4113745714125894, 0.4144697155393433, 0.4149215577937969, 0.41550020446920977, 0.41594390458185504, 0.41781676990741023, 0.41906794673720227, 0.42000407408140494, 0.42265603378895833, 0.4233859928702822, 0.426070977626097, 0.426650654364782, 0.4295959435760647, 0.4303371775089212, 0.4338005122547718, 0.43431182785899425, 0.43550545439815935, 0.4374819266082097, 0.4391255366373824, 0.4417464916377071, 0.4438591884213011, 0.4474681413224578, 0.4480096978792789, 0.4488530716747082, 0.44908474501094675, 0.45011652647481104, 0.45039373146924333, 0.45069022851989604, 0.45086966372282733, 0.452086596811366, 0.4529110702676108, 0.4543131115045266, 0.45515224091548434, 0.4574430558698882, 0.45802221166825874, 0.4615229275886068, 0.4658257532231247, 0.4675073005628534, 0.46926264471316415, 0.47289196563318214, 0.4733762027310404, 0.4747415812184167, 0.47633658394538925, 0.47685697930283477, 0.4780469965214361, 0.47876586751466566, 0.4799259388888496, 0.48029573710551576, 0.4813333765356649, 0.48439118560084926, 0.48534241342648843, 0.48581742891263147, 0.487273605738224, 0.48831861341848826, 0.4898902875011748, 0.49570375023189106, 0.49897111691376594, 0.5007109258366713, 0.501763999500727, 0.5026875538310276, 0.5064990078455918, 0.5085818224714432, 0.5097242467516981, 0.5123003468870806, 0.5139844970224601, 0.520296576918654, 0.5217401158047765, 0.5230847245817847, 0.5250490347362518, 0.5262784603382027, 0.5290499412274855, 0.5299703410214206, 0.5304744579561373, 0.5320216789842518, 0.5332179227688121, 0.5355667637744572, 0.5361857502723201, 0.5370074883513584, 0.5393301701665109, 0.5416464182167599, 0.5447722269827888, 0.5455851826691478, 0.5477846943833194, 0.5484997216514768, 0.5496160437189245, 0.5527623680335831, 0.5533801878657476, 0.5558847535036677, 0.5573105753143085, 0.5579274451507007, 0.559578854465342, 0.5615432847494218, 0.5627116990223392, 0.5633246420330467, 0.5643552095434902, 0.5655499649214404, 0.5662294339819824, 0.5686193512259253, 0.5703914078676366, 0.5719122038506007, 0.5732231944495915, 0.5764724375577539, 0.5788401680355926, 0.579881272152275, 0.5814193783760647, 0.5847590276659596, 0.5858497756717732, 0.591222738770868, 0.5923013710620957, 0.5938024808096155, 0.5948032146777896, 0.5957507281889567, 0.5972356015377481, 0.5990582375269533, 0.600281460528037, 0.6025518431009084, 0.6054117575075872, 0.6058639532173719, 0.6065521534364084, 0.6070257746547087, 0.6094063924182178, 0.611940505337331, 0.6148798800974999, 0.6171557833956468, 0.617931559846298, 0.6193434541369114, 0.6196159269449223, 0.6197345714330892, 0.6226863385936764, 0.6279500527726358, 0.6302087483291442, 0.6320898295062423, 0.6325441099658279, 0.6360707637298251, 0.6383222397918266, 0.6396221800696524, 0.6438143528824058, 0.6444702771210337, 0.6457637595552255, 0.6490746587943931, 0.6507685475587474, 0.655218579927353, 0.6581962945078175, 0.6596199073333251, 0.6624675341161811, 0.6630073461417759, 0.6642017130717857, 0.6677944290526784, 0.6741765392295153, 0.6743038064090484, 0.6758477464643364, 0.6759822755863554, 0.6761253975882903, 0.6774734148234729, 0.6783788228551418, 0.6816959053076527, 0.6824454201304982, 0.6848529608674467, 0.6862934879479348, 0.6874063641362376, 0.6900000628282107, 0.6924702045095437, 0.6953976442258095, 0.6963760618561597, 0.6975525217106201, 0.6991468916467449, 0.6997052060994762, 0.7015650876381233, 0.7032133179801494, 0.7043053259583958, 0.7060190076640246, 0.7090137242870318, 0.7119946540759589, 0.717254310421238, 0.7191180348137562, 0.7200080396631131, 0.7214220673287317, 0.7217215527171793, 0.7231494864646295, 0.7245168513986181, 0.727529230225095, 0.7304963609587902, 0.7326352347008328, 0.7334867464921039, 0.7354841960111618, 0.7371802250072431, 0.7390265577879587, 0.7481919059789975, 0.7489198963348322, 0.7500284121421912, 0.7516761720229193, 0.7524277626155725, 0.7530925733324144, 0.753594630745753, 0.7577687821754331, 0.7584250178691111, 0.7599292595124335, 0.7628555340222888, 0.7631083636013083, 0.7665885239716433, 0.7680054353132096, 0.7707806182638798, 0.7711053951533864, 0.7718577261816213, 0.7725905041386211, 0.7732588155930554, 0.7767904834072271, 0.780189268482995, 0.7807260380761243, 0.7823883294600873, 0.7839486349883128, 0.7863018584296716, 0.7876660257131087, 0.7891137723192119, 0.7894922984240523, 0.791463540889519, 0.792690996812442, 0.7934072581478373, 0.7964216224536396, 0.8001587287180605, 0.8013479918738086, 0.8031121282243164, 0.8067575637891261, 0.8073960303399513, 0.8080792823558299, 0.809183171139031, 0.8103051518253228, 0.8146272209174885, 0.818026749138693, 0.8183695664813373, 0.8187350040742701, 0.8223934188170581, 0.8252861082328968, 0.8265199257340428, 0.8267146599310183, 0.826814973796419, 0.8279107707047406, 0.8287050421783296, 0.8293352414500016, 0.8297228663216244, 0.8309189296440075, 0.8328319018690757, 0.8336431341439584, 0.8339781763571392, 0.8347579495573968, 0.8375308340760557, 0.8383801887141286, 0.8399639802821826, 0.842015661506744, 0.8422307463439479, 0.8442487024058184, 0.8476704105354645, 0.8495342154879013, 0.8525577819015535, 0.855690799278397, 0.8561856496851863, 0.8589566854206295, 0.8610452995033119, 0.8619869084042723, 0.8629105419212435, 0.8630009369463286, 0.866349418589482, 0.8673554223990468, 0.8680346803760383, 0.868900625540571, 0.8700586277320588, 0.8701735510482824, 0.8726358025468353, 0.8737229201822251, 0.8747794404831686, 0.8776470196507814, 0.8798164859419387, 0.8816156398779976, 0.8835410695182875, 0.8845832929211878, 0.8855684813876414, 0.8865591828960833, 0.8871193172236984, 0.8898837264734866, 0.8917108652027459, 0.8941467641220912, 0.8955958702519186, 0.8978504703424619, 0.8987400853848411, 0.8992603589246896, 0.9012960107746488, 0.9024374897607003, 0.9037575717751422, 0.9046283977269414, 0.9055247923296739, 0.9068038804373053, 0.9078320415275677, 0.9100837551402977, 0.9123501638053467, 0.9128924447365754, 0.9169420482009158, 0.9172845384756465, 0.920034605640698, 0.9240268704257328, 0.9257591270116136, 0.928317532848577, 0.9314945933730204, 0.9333061185945511, 0.9352970985453276, 0.9381142983195248, 0.9390570959671871, 0.9412724482418516, 0.9429838168160425, 0.9439823053632096, 0.9467560351737032, 0.9476087044051388, 0.9491121430894405, 0.9495110555875921, 0.949899668246076, 0.9513423363382867, 0.954547499564204, 0.9550385584084489, 0.9562643741200305, 0.9569475972843314, 0.9573228878945872, 0.9619136994006807, 0.9640613250784467, 0.9670526814260348, 0.9696077268480954, 0.9721560924225866, 0.9743722386792576, 0.9754730283140218, 0.9779648397024958, 0.9783972788005959, 0.9801089924137669, 0.9816138578484027, 0.981999911054785, 0.984257087004323, 0.9872851100131065, 0.9917426171678388, 0.992442289374779, 0.994981369325093, 0.9956378335948083, 0.9981201164750894, 0.9995439187190943, 0.9998134718293369, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007866683659327633, 0.03418776593915818, 0.06841051168101009, 0.12574151180664883, 0.1623818946623209, 0.1800530825918999, 0.21616744658113807, 0.2239997929645705, 0.2346740382615511, 0.2833429482655816, 0.3770626170648813, 0.40272592756965897, 0.4159073661469408, 0.4494338352137377, 0.47018259269666507, 0.5207210714237127, 0.556181735039757, 0.5884126333406055, 0.6129441748656059, 0.673566423496707, 0.6882078658665954, 0.7474722179245807, 0.7967978278640275, 0.8378257352832454, 0.8770291914703733, 0.9037239671752705, 0.963346832820399, 0.9914753351450482, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_injuries\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.3927396759654038,\n",
      "      \"sum\" : 3224.0,\n",
      "      \"std_dev\" : 0.8216381229608536,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 4.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 6131.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 1437.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.6,\n",
      "            \"upper_bound\" : 2.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.0,\n",
      "            \"upper_bound\" : 2.4,\n",
      "            \"count\" : 291.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.4,\n",
      "            \"upper_bound\" : 2.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.8,\n",
      "            \"upper_bound\" : 3.2,\n",
      "            \"count\" : 200.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.2,\n",
      "            \"upper_bound\" : 3.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6,\n",
      "            \"upper_bound\" : 4.0,\n",
      "            \"count\" : 150.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2\u001b[0m\n",
      "\u001b[34m.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"vehicle_claim\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 16518.060665123645,\n",
      "      \"sum\" : 1.3559676E8,\n",
      "      \"std_dev\" : 9252.604103061993,\n",
      "      \"min\" : 1000.0,\n",
      "      \"max\" : 51000.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1000.0,\n",
      "            \"upper_bound\" : 6000.0,\n",
      "            \"count\" : 631.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6000.0,\n",
      "            \"upper_bound\" : 11000.0,\n",
      "            \"count\" : 1673.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11000.0,\n",
      "            \"upper_bound\" : 16000.0,\n",
      "            \"count\" : 2305.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 16000.0,\n",
      "            \"upper_bound\" : 21000.0,\n",
      "            \"count\" : 1670.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 21000.0,\n",
      "            \"upper_bound\" : 26000.0,\n",
      "            \"count\" : 600.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 26000.0,\n",
      "            \"upper_bound\" : 31000.0,\n",
      "            \"count\" : 435.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 31000.0,\n",
      "            \"upper_bound\" : 36000.0,\n",
      "            \"count\" : 450.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 36000.0,\n",
      "            \"upper_bound\" : 41000.0,\n",
      "            \"count\" : 319.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 41000.0,\n",
      "            \"upper_bound\" : 46000.0,\n",
      "            \"count\" : 112.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 46000.0,\n",
      "            \"upper_bound\" : 51000.0,\n",
      "            \"count\" : 14.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 4248.0, 16000.0, 17890.0, 11000.0, 15826.0, 10000.0, 2492.0, 5623.0, 17933.0, 7000.0, 17707.0, 13000.0, 8739.0, 4000.0, 11000.0, 9087.0, 6787.0, 5925.0, 16918.0, 16771.0, 2747.0, 25686.0, 11000.0, 6142.0, 22257.0, 10377.0, 18200.0, 17807.0, 12572.0, 18523.0, 12500.0, 14000.0, 8402.0, 12500.0, 8500.0, 6025.0, 17723.0, 16260.0, 12500.0, 14000.0, 21887.0, 11443.0, 12577.0, 14000.0, 11000.0, 11548.0, 31526.0, 10274.0, 12500.0, 10000.0, 2272.0, 12774.0, 14000.0, 6000.0, 4398.0, 18243.0, 11361.0, 33086.0, 10000.0, 18000.0, 20406.0, 18000.0, 6071.0, 17954.0, 8142.0, 10663.0, 12415.0, 14000.0, 17000.0, 16000.0, 35690.0, 17826.0, 16000.0, 10088.0, 21500.0, 10644.0, 14000.0, 15000.0, 9981.0, 17442.0, 12745.0, 12084.0, 27550.0, 11191.0, 17103.0, 18000.0, 27612.0, 27831.0, 10000.0, 7281.0, 7813.0, 26708.0, 23687.0, 16000.0, 28187.0, 7519.0, 7365.0, 19000.0, 28130.0, 11130.0, 13000.0, 8000.0, 11000.0, 16000.0, 24272.0, 4000.0, 10313.0, 18956.0, 12033.0, 13000.0, 13000.0, 31878.0, 22369.0, 23540.0, 12337.0, 39953.0, 10784.0, 12443.0, 7316.0, 12500.0, 11000.0, 14000.0, 16000.0, 2214.0, 18282.0, 11148.0, 16000.0, 19885.0, 12651.0, 14000.0, 16000.0, 40027.0, 5969.0, 18000.0, 4121.0, 11000.0, 7000.0, 7000.0, 27264.0, 11000.0, 12500.0, 18372.0, 16500.0, 9978.0, 13000.0, 8000.0, 14127.0, 17500.0, 16597.0, 18000.0, 4065.0, 8279.0, 8341.0, 14000.0, 16000.0, 30182.0, 27893.0, 6319.0, 21792.0, 13000.0, 10500.0, 15545.0, 13000.0, 16500.0, 6128.0, 3713.0, 10530.0, 16984.0, 16500.0, 8319.0, 16437.0, 14000.0, 3142.0, 15000.0, 11247.0, 15439.0, 14000.0, 8500.0, 16500.0, 22308.0, 16500.0, 11147.0, 19000.0, 10000.0, 1493.0, 12409.0, 21604.0, 12192.0, 22064.0, 17797.0, 8705.0, 11033.0, 27905.0, 9588.0, 7000.0, 16000.0, 19285.0, 4289.0, 17000.0, 20126.0, 3697.0, 19000.0, 8000.0, 17154.0, 17646.0, 8867.0, 18000.0, 14000.0, 21474.0, 11000.0, 13000.0, 11000.0, 16591.0, 9509.0, 11000.0, 11500.0, 21300.0, 16000.0, 13000.0, 16000.0, 14000.0, 12000.0, 13000.0, 28839.0, 13000.0, 9708.0, 8000.0, 22911.0, 18000.0, 34585.0, 8500.0, 12534.0, 3240.0, 13000.0, 7958.0, 16192.0, 8000.0, 12556.0, 16075.0, 3924.0, 8164.0, 8472.0, 15000.0, 11930.0, 14500.0, 11000.0, 13000.0, 21683.0, 8573.0, 16000.0, 18000.0, 40590.0, 36123.0, 11503.0, 16738.0, 16000.0, 14906.0, 17912.0, 11000.0, 11000.0, 13643.0, 7071.0, 16604.0, 14000.0, 7987.0, 14000.0, 23483.0, 12866.0, 16000.0, 11958.0, 2299.0, 10000.0, 15000.0, 10000.0, 7000.0, 18000.0, 7136.0, 15044.0, 12951.0, 12426.0, 11835.0, 31430.0, 18000.0, 14500.0, 32538.0, 16500.0, 16968.0, 8088.0, 16997.0, 7000.0, 10000.0, 16500.0, 12882.0, 11500.0, 23678.0, 9855.0, 6674.0, 8000.0, 18506.0, 24809.0, 17500.0, 25236.0, 18000.0, 27861.0, 14000.0, 4640.0, 19000.0, 19673.0, 33427.0, 18000.0, 7000.0, 3661.0, 7000.0, 13000.0, 8711.0, 15653.0, 11000.0, 16896.0, 11009.0, 12500.0, 21805.0, 11298.0, 22296.0, 12822.0, 15000.0, 6000.0, 35719.0, 7000.0, 2836.0, 20887.0, 15336.0, 14000.0, 15000.0, 14000.0, 12883.0, 22195.0, 8685.0, 28068.0, 8500.0, 15988.0, 15000.0, 14000.0, 11000.0, 17610.0, 10000.0, 2372.0, 15000.0, 18914.0, 14416.0, 4268.0, 16000.0, 28060.0, 6415.0, 18000.0, 26421.0, 15000.0, 8225.0, 14000.0, 16000.0, 2935.0, 22973.0, 8091.0, 8947.0, 17926.0, 12836.0, 15000.0, 28138.0, 10500.0, 10965.0, 32909.0, 18126.0, 24057.0, 27500.0, 14000.0, 16500.0, 6623.0, 33794.0, 12500.0, 11000.0, 7552.0, 11000.0, 16756.0, 11000.0, 7000.0, 24988.0, 8000.0, 29671.0, 8500.0, 18000.0, 15000.0, 19000.0, 16500.0, 18000.0, 18000.0, 21500.0, 10000.0, 24129.0, 19821.0, 17945.0, 11500.0, 27500.0, 11637.0, 14000.0, 15000.0, 6452.0, 8869.0, 14843.0, 10000.0, 10000.0, 16500.0, 24634.0, 40897.0, 17000.0, 14000.0, 17095.0, 14000.0, 11000.0, 14000.0, 4108.0, 16556.0, 16800.0, 16431.0, 34155.0, 19000.0, 28081.0, 26359.0, 30609.0, 15560.0, 14000.0, 15000.0, 17000.0, 8500.0, 15000.0, 12000.0, 7731.0, 19869.0, 4000.0, 7000.0, 10000.0, 16500.0, 4000.0, 7000.0, 10000.0, 16631.0, 13000.0, 9580.0, 22339.0, 17500.0, 6993.0, 8500.0, 8837.0, 12577.0, 15000.0, 14000.0, 19709.0, 10000.0, 18000.0, 3141.0, 10978.0, 16500.0, 16000.0, 11000.0, 11000.0, 18000.0, 18430.0, 5059.0, 25585.0, 1636.0, 10000.0, 14500.0, 20741.0, 18492.0, 18598.0, 17500.0, 3802.0, 16000.0, 11939.0, 18000.0, 13000.0, 9277.0, 3092.0, 16350.0, 27500.0, 17776.0, 17585.0, 15000.0, 12294.0, 12331.0, 4440.0, 16000.0, 14000.0, 15389.0, 3907.0, 16500.0, 15000.0, 11000.0, 19303.0, 3867.0, 11500.0, 28426.0, 15000.0, 29411.0, 14533.0, 12085.0, 14000.0, 12689.0, 36483.0, 12000.0, 9616.0, 14000.0, 15000.0, 14000.0, 25016.0, 2754.0, 6825.0, 13000.0, 20778.0, 11500.0, 4938.0, 4164.0, 3889.0, 18380.0, 3649.0, 19311.0, 28224.0, 19846.0, 10287.0, 7000.0, 10671.0, 16282.0, 18067.0, 16500.0, 15000.0, 23398.0, 18287.0, 19676.0, 13000.0, 31164.0, 4189.0, 8000.0, 22119.0, 14500.0, 12500.0, 18000.0, 14000.0, 18000.0, 18137.0, 12500.0, 15000.0, 14398.0, 8227.0, 10000.0, 9228.0, 5268.0, 16500.0, 11500.0, 11500.0, 8906.0, 13000.0, 17444.0, 8000.0, 17790.0, 20213.0, 11639.0, 18000.0, 14641.0, 21500.0, 10061.0, 19653.0, 11000.0, 17200.0, 19698.0, 16000.0, 14000.0, 17500.0, 13000.0, 30209.0, 4210.0, 16500.0, 2471.0, 1500.0, 19933.0, 13554.0, 11000.0, 4256.0, 10000.0, 11000.0, 28312.0, 9585.0, 24666.0, 13000.0, 8500.0, 15000.0, 15000.0, 6687.0, 2812.0, 18203.0, 19912.0, 11500.0, 14000.0, 14000.0, 14000.0, 7000.0, 9979.0, 13000.0, 4277.0, 15000.0, 14000.0, 8693.0, 12291.0, 8732.0, 27690.0, 8740.0, 11323.0, 9609.0, 15000.0, 17500.0, 18515.0, 9986.0, 15000.0, 3946.0, 10765.0, 20906.0, 15000.0, 31429.0, 10000.0, 28481.0, 14000.0, 10809.0, 17000.0, 32332.0, 14000.0, 8714.0, 16500.0, 16000.0, 31656.0, 16664.0, 16193.0, 11430.0, 27474.0, 3785.0, 11000.0, 14000.0, 14850.0, 11927.0, 16000.0, 26798.0, 17968.0, 14757.0, 15000.0, 4089.0, 17000.0, 19000.0, 14000.0, 3662.0, 7000.0, 34556.0, 16291.0, 2413.0, 9925.0, 15000.0, 25897.0, 1479.0, 5862.0, 18000.0, 5869.0, 3605.0, 2238.0, 11929.0, 12143.0, 10259.0, 14000.0, 14081.0, 32521.0, 40750.0, 16500.0, 6306.0, 14000.0, 5651.0, 2210.0, 12046.0, 27500.0, 15000.0, 10550.0, 11895.0, 15000.0, 17063.0, 10000.0, 16087.0, 1292.0, 3135.0, 14949.0, 14791.0, 8500.0, 10560.0, 11442.0, 18000.0, 8164.0, 21294.0, 11000.0, 14000.0, 8000.0, 8139.0, 11000.0, 13048.0, 7593.0, 15000.0, 12500.0, 12000.0, 12753.0, 13000.0 ], [ 47500.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1135.0, 1461.0, 1467.0, 1500.0, 1500.0, 1521.0, 1557.0, 1635.0, 1717.0, 1763.0, 1844.0, 2000.0, 2000.0, 2000.0, 2240.0, 2293.0, 2342.0, 2355.0, 2392.0, 2424.0, 2448.0, 2640.0, 2737.0, 2826.0, 2843.0, 2925.0, 3000.0, 3000.0, 3062.0, 3163.0, 3279.0, 3374.0, 3475.0, 3500.0, 3500.0, 3500.0, 3515.0, 3587.0, 3600.0, 3601.0, 3618.0, 3674.0, 3693.0, 3707.0, 3752.0, 3806.0, 3857.0, 3904.0, 3926.0, 3944.0, 3969.0, 3983.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4003.0, 4025.0, 4087.0, 4102.0, 4147.0, 4152.0, 4231.0, 4246.0, 4256.0, 4285.0, 4316.0, 4343.0, 4374.0, 4425.0, 4444.0, 4452.0, 4474.0, 4493.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4863.0, 5000.0, 5000.0, 5000.0, 5000.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5529.0, 5551.0, 5603.0, 5677.0, 5707.0, 5768.0, 5801.0, 5868.0, 5919.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6045.0, 6075.0, 6159.0, 6240.0, 6293.0, 6324.0, 6456.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6512.0, 6515.0, 6634.0, 6706.0, 6761.0, 6766.0, 6808.0, 6874.0, 6924.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7005.0, 7132.0, 7156.0, 7210.0, 7250.0, 7291.0, 7312.0, 7346.0, 7376.0, 7388.0, 7415.0, 7493.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7507.0, 7588.0, 7611.0, 7642.0, 7681.0, 7692.0, 7738.0, 7802.0, 7840.0, 7886.0, 7945.0, 7990.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8038.0, 8070.0, 8106.0, 8197.0, 8263.0, 8297.0, 8316.0, 8317.0, 8333.0, 8361.0, 8374.0, 8447.0, 8451.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8597.0, 8650.0, 8659.0, 8750.0, 8772.0, 8781.0, 8822.0, 8837.0, 8840.0, 8879.0, 8934.0, 8941.0, 8965.0, 8976.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9034.0, 9093.0, 9114.0, 9182.0, 9264.0, 9341.0, 9414.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9507.0, 9517.0, 9542.0, 9571.0, 9575.0, 9598.0, 9609.0, 9612.0, 9633.0, 9654.0, 9669.0, 9741.0, 9755.0, 9765.0, 9790.0, 9801.0, 9810.0, 9822.0, 9836.0, 9840.0, 9846.0, 9864.0, 9892.0, 9901.0, 9914.0, 9924.0, 9941.0, 9975.0, 9997.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10016.0, 10023.0, 10074.0, 10148.0, 10195.0, 10235.0, 10272.0, 10279.0, 10295.0, 10385.0, 10396.0, 10411.0, 10421.0, 10431.0, 10451.0, 10455.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10558.0, 10613.0, 10647.0, 10676.0, 10729.0, 10737.0, 10761.0, 10781.0, 10821.0, 10838.0, 10881.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11007.0, 11066.0, 11099.0, 11136.0, 11151.0, 11182.0, 11208.0, 11221.0, 11258.0, 11272.0, 11277.0, 11307.0, 11338.0, 11356.0, 11405.0, 11434.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11542.0, 11604.0, 11609.0, 11637.0, 11648.0, 11671.0, 11679.0, 11740.0, 11796.0, 11809.0, 11847.0, 11913.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12032.0, 12036.0, 12047.0, 12072.0, 12099.0, 12134.0, 12205.0, 12229.0, 12249.0, 12261.0, 12357.0, 12382.0, 12423.0, 12463.0, 12474.0, 12489.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12510.0, 12513.0, 12525.0, 12542.0, 12604.0, 12615.0, 12633.0, 12654.0, 12678.0, 12704.0, 12717.0, 12767.0, 12774.0, 12775.0, 12789.0, 12811.0, 12831.0, 12839.0, 12844.0, 12860.0, 12879.0, 12886.0, 12904.0, 12916.0, 12917.0, 12938.0, 12947.0, 12969.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13062.0, 13093.0, 13147.0, 13380.0, 13416.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13604.0, 13773.0, 13801.0, 13826.0, 13933.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14011.0, 14015.0, 14024.0, 14117.0, 14168.0, 14197.0, 14243.0, 14407.0, 14436.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14525.0, 14623.0, 14685.0, 14701.0, 14707.0, 14744.0, 14795.0, 14802.0, 14810.0, 14889.0, 14897.0, 14916.0, 14948.0, 14971.0, 14979.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15025.0, 15050.0, 15105.0, 15152.0, 15163.0, 15257.0, 15304.0, 15336.0, 15415.0, 15477.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15505.0, 15575.0, 15628.0, 15660.0, 15672.0, 15686.0, 15709.0, 15779.0, 15800.0, 15830.0, 15926.0, 15974.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16002.0, 16011.0, 16025.0, 16093.0, 16127.0, 16160.0, 16200.0, 16220.0, 16252.0, 16284.0, 16344.0, 16360.0, 16380.0, 16445.0, 16483.0, 16491.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16507.0, 16522.0, 16549.0, 16558.0, 16591.0, 16634.0, 16642.0, 16676.0, 16704.0, 16717.0, 16726.0, 16742.0, 16766.0, 16789.0, 16842.0, 16860.0, 16867.0, 16911.0, 16943.0, 16964.0, 16966.0, 16975.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17043.0, 17100.0, 17109.0, 17140.0, 17154.0, 17184.0, 17195.0, 17221.0, 17233.0, 17246.0, 17249.0, 17265.0, 17277.0, 17333.0, 17352.0, 17366.0, 17373.0, 17382.0, 17391.0, 17425.0, 17462.0, 17465.0, 17494.0, 17497.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17501.0, 17506.0, 17601.0, 17640.0, 17649.0, 17659.0, 17732.0, 17743.0, 17794.0, 17827.0, 17840.0, 17848.0, 17898.0, 17925.0, 17972.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18045.0, 18081.0, 18155.0, 18174.0, 18225.0, 18262.0, 18297.0, 18310.0, 18360.0, 18471.0, 18495.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 1856\u001b[0m\n",
      "\u001b[34m4.0, 18574.0, 18585.0, 18609.0, 18647.0, 18688.0, 18716.0, 18749.0, 18783.0, 18819.0, 18862.0, 18873.0, 18891.0, 18917.0, 18930.0, 18939.0, 18955.0, 18997.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19007.0, 19053.0, 19089.0, 19112.0, 19136.0, 19180.0, 19196.0, 19212.0, 19219.0, 19252.0, 19338.0, 19406.0, 19496.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19512.0, 19539.0, 19563.0, 19627.0, 19691.0, 19718.0, 19781.0, 19812.0, 19861.0, 19936.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20007.0, 20042.0, 20121.0, 20137.0, 20188.0, 20249.0, 20279.0, 20293.0, 20425.0, 20442.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20555.0, 20582.0, 20655.0, 20788.0, 20853.0, 20915.0, 21000.0, 21000.0, 21000.0, 21000.0, 21004.0, 21024.0, 21056.0, 21084.0, 21115.0, 21185.0, 21239.0, 21250.0, 21313.0, 21369.0, 21409.0, 21428.0, 21500.0, 21500.0, 21500.0, 21503.0, 21535.0, 21606.0, 21632.0, 21673.0, 21690.0, 21707.0, 21721.0, 21810.0, 21815.0, 21829.0, 21833.0, 21843.0, 21907.0, 21917.0, 21953.0, 21959.0, 21976.0, 22000.0, 22000.0, 22000.0, 22000.0, 22016.0, 22052.0, 22090.0, 22142.0, 22159.0, 22204.0, 22245.0, 22289.0, 22343.0, 22364.0, 22441.0, 22460.0, 22493.0, 22500.0, 22531.0, 22578.0, 22588.0, 22670.0, 22724.0, 22765.0, 22810.0, 22860.0, 22906.0, 22952.0, 22990.0, 23007.0, 23032.0, 23185.0, 23234.0, 23438.0, 23470.0, 23500.0, 23500.0, 23591.0, 23678.0, 23805.0, 23916.0, 24049.0, 24209.0, 24282.0, 24417.0, 24450.0, 24585.0, 24607.0, 24664.0, 24690.0, 24940.0, 25121.0, 25151.0, 25197.0, 25257.0, 25319.0, 25360.0, 25500.0, 25500.0, 25500.0, 25545.0, 25610.0, 25652.0, 25730.0, 25749.0, 25796.0, 25902.0, 25963.0, 26027.0, 26286.0, 26333.0, 26424.0, 26454.0, 26500.0, 26500.0, 26500.0, 26562.0, 26602.0, 26743.0, 26777.0, 26808.0, 26871.0, 26885.0, 27082.0, 27114.0, 27148.0, 27167.0, 27198.0, 27257.0, 27363.0, 27481.0, 27500.0, 27546.0, 27574.0, 27586.0, 27647.0, 27701.0, 27739.0, 27757.0, 27799.0, 27817.0, 27902.0, 27973.0, 28000.0, 28003.0, 28021.0, 28069.0, 28117.0, 28136.0, 28174.0, 28184.0, 28252.0, 28260.0, 28278.0, 28299.0, 28326.0, 28354.0, 28387.0, 28430.0, 28599.0, 28686.0, 28928.0, 28963.0, 29000.0, 29093.0, 29320.0, 29634.0, 29658.0, 29746.0, 29804.0, 29833.0, 29929.0, 30022.0, 30121.0, 30306.0, 30396.0, 30423.0, 30508.0, 30582.0, 30636.0, 30876.0, 30879.0, 30928.0, 31000.0, 31000.0, 31000.0, 31088.0, 31139.0, 31162.0, 31242.0, 31274.0, 31323.0, 31500.0, 31517.0, 31543.0, 31740.0, 31788.0, 31972.0, 32095.0, 32186.0, 32301.0, 32473.0, 32556.0, 32589.0, 32704.0, 32870.0, 32901.0, 33000.0, 33149.0, 33206.0, 33307.0, 33379.0, 33389.0, 33429.0, 33455.0, 33500.0, 33500.0, 33500.0, 33637.0, 33817.0, 33971.0, 33997.0, 34000.0, 34137.0, 34155.0, 34201.0, 34484.0, 34500.0, 34557.0, 34580.0, 34655.0, 34679.0, 34720.0, 34879.0, 34941.0, 34973.0, 35000.0, 35143.0, 35262.0, 35360.0, 35500.0, 35674.0, 35799.0, 36070.0, 36283.0, 36422.0, 36482.0, 36500.0, 36642.0, 36857.0, 36895.0, 36964.0, 36996.0, 37000.0, 37139.0, 37267.0, 37500.0, 37659.0, 37752.0, 37809.0, 38000.0, 38119.0, 38308.0, 38373.0, 38444.0, 38555.0, 38649.0, 38762.0, 38806.0, 39263.0, 39342.0, 39437.0, 39462.0, 39480.0, 39499.0, 39629.0, 39711.0, 39737.0, 39858.0, 39898.0, 39914.0, 39966.0, 40040.0, 40102.0, 40182.0, 40348.0, 40377.0, 40644.0, 40775.0, 41098.0, 41159.0, 41554.0, 41700.0, 42000.0, 42291.0, 42544.0, 42897.0, 43041.0, 43999.0, 44353.0, 45046.0, 47000.0, 47000.0 ], [ 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1500.0, 1500.0, 1500.0, 2000.0, 2000.0, 2000.0, 2000.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2622.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3500.0, 3500.0, 3500.0, 3500.0, 3500.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8803.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11524.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12015.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12915.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14130.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15784.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16234.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16658.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17486.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17719.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18017.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18716.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20758.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21094.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22439.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22572.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24350.0, 24500.0, 24500.0, 24500.0, 24500.0, 24500.0, 24500.0, 24500.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25640.0, 26000.0, 26000.0, 26000.0, 26000.0, 26000.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 27000.0, 27000.0, 27000.0, 27000.0, 27039.0, 27500.0, 27500.0, 27500.0, 27500.0, 27500.0, 27776.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28500.0, 28500.0, 28500.0, 28500.0, 28500.0, 28500.0, 28836.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29500.0, 29500.0, 29500.0, 29500.0, 29500.0, 29500.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30197.0, 30500.0, 30500.0, 30500.0, 30500.0, 30500.0, 30500.0, 30500.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31191.0, 31500.0, 31500.0, 31500.0, 31500.0, 31500.0, 31500.0, 31500.0, 31951.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33423.0, 33500.0, 33500.0, 33500.0, 33500.0, 33500.0, 33500.0, 33701.0, 34000.0, 34000.0, 34000.0, 34000.0, 34000.0, 34000.0, 34000.0, 34000.0, 34000.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34998.0, 35000.0, 35000.0, 35000.0, 35000.0, 35000.0, 35329.0, 35500.0, 35500.0, 35500.0, 35500.0, 35500.0, 35500.0, 35883.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36113.0, 36428.0, 36500.0, 36500.0, 36500.0, 36500.0, 36500.0, 36500.0, 36789.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37500.0, 37500.0, 37500.0, 37500.0, 38000.0, 38000.0, 38000.0, 38000.0, 38065.0, 38500.0, 38500.0, 38500.0, 38500.0, 38500.0, 38761.0, 39000.0, 39000.0, 39000.0, 39000.0, 39000.0, 39195.0, 39500.0, 39500.0, 39500.0, 39500.0, 40000.0, 40000.0, 40000.0, 40500.0, 40500.0, 40500.0, 40500.0, 41000.0, 41000.0, 41000.0, 41500.0, 41500.0, 41500.0, 41500.0, 42000.0, 42000.0, 42000.0, 42000.0, 42323.0, 42500.0, 43000.0, 43000.0, 43000.0, 43500.0, 43500.0, 43500.0, 44500.0, 45000.0, 45500.0, 46500.0, 47000.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_hour\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 11.48434644901937,\n",
      "      \"sum\" : 94275.0,\n",
      "      \"std_dev\" : 4.875677419425378,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 23.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 2.3,\n",
      "            \"count\" : 286.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.3,\n",
      "            \"upper_bound\" : 4.6,\n",
      "            \"count\" : 353.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.6,\n",
      "            \"upper_bound\" : 6.9,\n",
      "            \"count\" : 753.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.9,\n",
      "            \"upper_bound\" : 9.2,\n",
      "            \"count\" : 1535.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 9.2,\n",
      "            \"upper_bound\" : 11.5,\n",
      "            \"count\" : 1085.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.5,\n",
      "            \"upper_bound\" : 13.8,\n",
      "            \"count\" : 1181.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.8,\n",
      "            \"upper_bound\" : 16.1,\n",
      "            \"count\" : 1689.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 16.1,\n",
      "            \"upper_bound\" : 18.4,\n",
      "            \"count\" : 748.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 18.4,\n",
      "            \"upper_bound\" : 20.7,\n",
      "            \"count\" : 386.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 20.7,\n",
      "            \"upper_bound\" : 23.0,\n",
      "            \"count\" : 193.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 14.0, 14.0, 8.0, 11.0, 10.0, 9.0, 16.0, 6.0, 14.0, 14.0, 9.0, 5.0, 19.0, 5.0, 16.0, 18.0, 14.0, 8.0, 6.0, 9.0, 8.0, 12.0, 16.0, 7.0, 12.0, 15.0, 11.0, 16.0, 9.0, 18.0, 10.0, 9.0, 13.0, 14.0, 18.0, 5.0, 16.0, 11.0, 10.0, 7.0, 16.0, 7.0, 16.0, 3.0, 16.0, 5.0, 10.0, 14.0, 11.0, 10.0, 13.0, 7.0, 2.0, 5.0, 8.0, 19.0, 12.0, 12.0, 11.0, 22.0, 10.0, 6.0, 5.0, 21.0, 6.0, 12.0, 11.0, 2.0, 7.0, 14.0, 3.0, 19.0, 17.0, 6.0, 15.0, 14.0, 10.0, 2.0, 12.0, 15.0, 7.0, 5.0, 15.0, 12.0, 7.0, 15.0, 9.0, 9.0, 11.0, 14.0, 15.0, 14.0, 13.0, 14.0, 12.0, 14.0, 14.0, 11.0, 10.0, 13.0, 6.0, 9.0, 16.0, 20.0, 18.0, 5.0, 13.0, 15.0, 5.0, 6.0, 5.0, 2.0, 14.0, 12.0, 18.0, 4.0, 16.0, 16.0, 16.0, 18.0, 16.0, 14.0, 15.0, 12.0, 20.0, 7.0, 18.0, 17.0, 17.0, 15.0, 17.0, 5.0, 17.0, 11.0, 13.0, 12.0, 13.0, 14.0, 10.0, 12.0, 17.0, 15.0, 9.0, 7.0, 11.0, 8.0, 10.0, 16.0, 3.0, 22.0, 14.0, 10.0, 18.0, 2.0, 10.0, 11.0, 5.0, 9.0, 13.0, 5.0, 15.0, 8.0, 5.0, 15.0, 17.0, 7.0, 15.0, 14.0, 6.0, 7.0, 14.0, 10.0, 10.0, 6.0, 12.0, 7.0, 7.0, 18.0, 10.0, 19.0, 10.0, 12.0, 13.0, 9.0, 6.0, 16.0, 14.0, 14.0, 17.0, 16.0, 17.0, 13.0, 14.0, 13.0, 13.0, 12.0, 11.0, 11.0, 7.0, 13.0, 7.0, 13.0, 10.0, 10.0, 16.0, 17.0, 20.0, 7.0, 19.0, 15.0, 5.0, 14.0, 5.0, 13.0, 12.0, 6.0, 14.0, 13.0, 5.0, 14.0, 8.0, 5.0, 7.0, 14.0, 13.0, 13.0, 12.0, 10.0, 16.0, 4.0, 18.0, 9.0, 12.0, 13.0, 10.0, 11.0, 6.0, 17.0, 12.0, 7.0, 6.0, 16.0, 9.0, 15.0, 11.0, 12.0, 7.0, 14.0, 17.0, 9.0, 22.0, 4.0, 4.0, 3.0, 12.0, 11.0, 8.0, 16.0, 10.0, 11.0, 16.0, 13.0, 16.0, 10.0, 15.0, 12.0, 9.0, 8.0, 11.0, 17.0, 13.0, 10.0, 4.0, 12.0, 13.0, 8.0, 13.0, 0.0, 5.0, 18.0, 5.0, 2.0, 20.0, 12.0, 11.0, 7.0, 14.0, 16.0, 14.0, 16.0, 12.0, 5.0, 15.0, 6.0, 14.0, 8.0, 12.0, 7.0, 18.0, 12.0, 15.0, 12.0, 12.0, 9.0, 7.0, 12.0, 12.0, 11.0, 13.0, 17.0, 13.0, 9.0, 13.0, 5.0, 17.0, 10.0, 12.0, 8.0, 15.0, 16.0, 19.0, 8.0, 12.0, 15.0, 8.0, 16.0, 8.0, 18.0, 11.0, 19.0, 6.0, 15.0, 6.0, 11.0, 8.0, 19.0, 19.0, 5.0, 15.0, 14.0, 13.0, 18.0, 16.0, 7.0, 8.0, 14.0, 4.0, 9.0, 14.0, 10.0, 12.0, 5.0, 8.0, 6.0, 16.0, 10.0, 16.0, 14.0, 10.0, 11.0, 14.0, 16.0, 17.0, 14.0, 15.0, 16.0, 6.0, 14.0, 12.0, 8.0, 21.0, 16.0, 10.0, 5.0, 3.0, 9.0, 4.0, 12.0, 12.0, 13.0, 15.0, 5.0, 13.0, 14.0, 11.0, 11.0, 4.0, 11.0, 9.0, 12.0, 11.0, 8.0, 7.0, 9.0, 16.0, 8.0, 18.0, 16.0, 21.0, 8.0, 10.0, 5.0, 6.0, 6.0, 15.0, 17.0, 8.0, 12.0, 11.0, 4.0, 18.0, 6.0, 7.0, 2.0, 9.0, 8.0, 10.0, 8.0, 8.0, 3.0, 10.0, 14.0, 9.0, 11.0, 14.0, 10.0, 2.0, 8.0, 7.0, 5.0, 7.0, 18.0, 6.0, 16.0, 12.0, 18.0, 9.0, 13.0, 11.0, 12.0, 9.0, 13.0, 11.0, 11.0, 9.0, 1.0, 11.0, 12.0, 14.0, 10.0, 15.0, 14.0, 6.0, 6.0, 17.0, 12.0, 6.0, 7.0, 9.0, 3.0, 12.0, 9.0, 15.0, 18.0, 17.0, 7.0, 7.0, 7.0, 12.0, 10.0, 16.0, 18.0, 18.0, 5.0, 5.0, 15.0, 17.0, 6.0, 7.0, 16.0, 11.0, 13.0, 10.0, 19.0, 17.0, 7.0, 18.0, 18.0, 8.0, 15.0, 10.0, 7.0, 13.0, 9.0, 7.0, 14.0, 16.0, 7.0, 8.0, 10.0, 9.0, 15.0, 11.0, 17.0, 16.0, 15.0, 4.0, 11.0, 2.0, 12.0, 14.0, 7.0, 16.0, 14.0, 11.0, 8.0, 18.0, 3.0, 8.0, 7.0, 7.0, 9.0, 13.0, 13.0, 7.0, 17.0, 14.0, 13.0, 12.0, 11.0, 15.0, 10.0, 12.0, 14.0, 19.0, 17.0, 6.0, 9.0, 8.0, 12.0, 12.0, 10.0, 15.0, 20.0, 17.0, 8.0, 21.0, 13.0, 7.0, 10.0, 9.0, 12.0, 10.0, 7.0, 4.0, 4.0, 6.0, 18.0, 11.0, 15.0, 11.0, 6.0, 17.0, 15.0, 14.0, 8.0, 18.0, 8.0, 18.0, 11.0, 6.0, 11.0, 13.0, 7.0, 5.0, 10.0, 14.0, 12.0, 3.0, 8.0, 7.0, 18.0, 11.0, 13.0, 8.0, 9.0, 13.0, 8.0, 2.0, 14.0, 5.0, 16.0, 2.0, 13.0, 10.0, 6.0, 7.0, 18.0, 3.0, 10.0, 13.0, 10.0, 13.0, 13.0, 7.0, 8.0, 5.0, 7.0, 19.0, 13.0, 16.0, 11.0, 13.0, 12.0, 13.0, 6.0, 11.0, 17.0, 13.0, 13.0, 14.0, 12.0, 12.0, 1.0, 12.0, 12.0, 10.0, 15.0, 16.0, 9.0, 11.0, 12.0, 17.0, 3.0, 11.0, 11.0, 16.0, 11.0, 4.0, 12.0, 8.0, 13.0, 12.0, 6.0, 16.0, 14.0, 10.0, 16.0, 8.0, 11.0, 5.0, 7.0, 9.0, 9.0, 6.0, 13.0, 3.0, 12.0, 8.0, 12.0, 7.0, 9.0, 8.0, 5.0, 8.0, 15.0, 6.0, 9.0, 5.0, 15.0, 13.0, 16.0, 18.0, 13.0, 5.0, 8.0, 16.0, 17.0, 10.0, 14.0, 17.0, 12.0, 6.0, 13.0, 5.0, 7.0, 17.0, 12.0, 9.0, 6.0, 6.0, 17.0, 7.0, 15.0, 15.0, 13.0, 19.0, 12.0, 14.0, 16.0, 9.0, 7.0, 11.0, 10.0, 9.0, 14.0, 10.0, 12.0, 12.0, 12.0, 5.0 ], [ 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0,\n",
      " 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_na\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.1811784314549733,\n",
      "      \"sum\" : 1487.2937438138758,\n",
      "      \"std_dev\" : 0.3457976749968297,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 6159.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 150.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 119.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 135.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 148.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 149.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 162.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 141.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 134.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 912.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.06810902472352254, 0.2181743295932732, 0.0, 0.0, 0.4453865259778722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5216645183294442, 0.9789788932737828, 0.0, 0.0, 0.0, 0.0, 0.8372372182218181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244161608716153, 0.0, 0.38510260282302966, 0.14519422120073855, 0.0, 0.1164352716298096, 0.7293800053064033, 0.0, 0.0, 0.9926658491638197, 0.025809392863181735, 0.5532906396230001, 0.47955059583471404, 0.0, 0.2018418353637581, 0.0, 0.0, 1.0, 0.22218875554154927, 0.0, 0.0, 0.0, 0.4511931914507237, 0.3303914736656165, 0.5892146143478555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7567580902469283, 0.6805581617791014, 0.0, 0.9408941791243455, 0.6907263151132631, 0.0, 0.0, 0.0, 0.9088593605553225, 0.2859005337712024, 0.6723898127987045, 0.0, 0.0, 0.6688535108358502, 0.23402842514482092, 0.0, 0.0, 0.5796190972281366, 0.0, 0.0, 0.041428088819387754, 0.967802737648485, 0.0, 0.9631590270650665, 0.8852464005861646, 0.4904085191855132, 0.0, 0.0, 0.38247088493768844, 0.0, 0.0, 0.0, 0.0, 0.7816325580532472, 0.0, 0.0, 0.0, 0.0, 0.3249227944066413, 0.0, 0.0, 0.26975666564213197, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.18953178278453398, 0.7273493526875153, 0.7315621195611339, 0.0, 0.5218843281579432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9408229281364582, 0.0, 0.23107995542883164, 0.0, 0.011078552594309676, 0.7301734533106766, 0.0, 0.0, 0.12757017457137088, 0.4090851486348762, 0.6456228170138647, 0.0, 0.7308796233222077, 0.0, 0.0, 0.0, 0.34985438418085446, 0.0, 0.0, 0.0, 0.6849894928165754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04331527325431195, 0.3006605337473569, 0.0, 1.0, 0.5875969395321339, 0.19575560640562462, 0.5131750822820359, 0.0, 0.0, 0.6826945225795135, 0.08804041580036681, 0.93907127827928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24257826607382516, 0.9086911974553298, 0.6813103960094764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6383529051589555, 0.0, 1.0, 0.0, 0.0, 0.4945211251204079, 0.8783046932733277, 0.0, 0.6839223161567359, 0.0, 0.8083948823040229, 0.0, 0.29574756259502066, 0.0, 0.327420958733448, 0.8353794867634952, 0.8188281491499799, 0.0, 0.0, 0.5640048194294142, 0.40595053443318885, 0.0, 0.06737687152192573, 0.0, 0.17732655322393942, 0.7230716360496688, 1.0, 0.0, 0.0, 0.9853910028911171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7064652075413396, 0.0, 0.6672191310392045, 0.0, 1.0, 0.0, 0.19228218001852038, 0.0, 0.0, 0.018945403374354575, 0.0, 0.2083995736183316, 0.0, 0.6384887847991355, 1.0, 0.05711716337044326, 1.0, 0.0, 1.0, 0.02461798384123859, 0.20945576950951106, 0.41626278068790734, 0.0, 0.0, 0.0, 0.0, 0.680479462524374, 0.0, 0.0, 0.19624476398823731, 0.0, 0.0, 0.0, 0.0, 0.8486288287367251, 0.0, 0.32855814988579846, 0.0, 0.18245804065249005, 0.9652096385457352, 0.42818393986717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31326647658061035, 0.0, 0.0, 0.9931853020998719, 0.0, 0.9215133919074179, 0.18792238899132097, 0.17478862874036893, 0.0, 0.0, 1.0, 0.856838642188807, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8123907241861509, 0.0824059718619482, 0.0, 0.48564686533427714, 0.0, 1.0, 0.0, 0.0, 0.0, 0.08818137131390835, 0.0, 0.0, 0.0, 0.0, 0.6693569842407483, 0.23127992831595545, 0.0, 0.0, 0.0, 0.17712714419825404, 0.0, 0.0, 1.0, 0.0, 0.0, 0.05642585596482286, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3071456481042115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6360473423391266, 0.5982068648905755, 0.0, 0.6921258747256326, 0.0, 0.0, 0.0, 0.9324889235898018, 1.0, 0.5977762651528876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13924684459410952, 0.3879914700405447, 0.0, 0.6738921474874265, 0.07091595948797924, 0.0, 0.8624965074015853, 0.766927188109165, 0.6951874662100657, 0.6296283449385927, 0.0, 0.0, 0.022410039654956804, 0.5826286460403656, 0.9954741523468144, 0.0, 0.0, 0.056162009903313104, 0.0, 0.0, 0.0, 0.1674597445179885, 0.0, 0.9667320288306416, 0.0, 0.41586133940794756, 0.0, 0.39675505645552933, 0.4740062659484451, 0.0, 0.1308251425969127, 0.5300624550517324, 0.0, 0.0, 0.18237662169551383, 0.10494339600016689, 0.0, 0.32645342186860915, 0.8626382540313258, 0.0, 0.9539369363180226, 0.0691759250098859, 0.0, 0.0, 0.688428260417771, 0.0, 0.0, 0.0016437571124496841, 0.0, 0.0, 0.47870485796552253, 0.0, 0.0, 0.0, 0.5129793498209074, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.7055627116496911, 0.0, 0.0, 0.07300359289962732, 0.0, 0.0, 0.23449947767409374, 0.749379016724156, 0.917840883093553, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4522024791035387, 0.0, 0.31348605695674747, 1.0, 0.8774521266031688, 0.0, 0.671587742938926, 0.0, 0.534966673409444, 0.03769772491485279, 0.1919321828839774, 0.6792754755400424, 0.0, 0.2794453073189026, 0.0, 0.11349747335809746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8781204982186164, 0.9817249302764938, 0.0, 0.06864866614787224, 0.9918891959474917, 0.04860313802089389, 0.0, 0.0, 0.0, 0.5718448269698801, 0.06142512925983268, 0.7760754122034105, 0.0, 0.5613524997539452, 0.0, 0.8078656456839812, 0.0, 0.0, 1.0, 0.0, 0.7088991127733161, 0.0, 0.6853710910648012, 0.3259824651160327, 1.0, 0.0, 0.7179326909401018, 0.7163920765828637, 1.0, 0.0, 0.0, 0.042739606061951374, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7877143583314087, 0.8844416233193683, 0.8364209229856395, 0.5024656497627655, 0.0, 0.0, 0.0, 0.6059261954142473, 0.0, 0.12158413695503834, 0.0, 0.7545369159024605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.170178735282715, 0.0, 0.0, 0.0, 0.11822241207245987, 0.5985023894351237, 0.7931285379630564, 0.779491212863352, 0.0, 0.0, 0.0, 0.0, 0.969615938904338, 0.0, 0.6995965330235282, 0.0, 0.11582308223679427, 0.0, 0.5036886093282389, 0.17084935971586013, 0.4918582813348057, 0.6202413542689121, 0.0, 0.0, 1.0, 1.0, 0.6332632016094104, 0.5497175161684742, 0.0, 0.0, 0.8259409191119182, 0.6965614021440462, 0.07592701115431688, 0.8203240881472009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4259975194684281, 0.0, 0.6577653832726, 0.4356046196610104, 0.0, 0.0, 0.47391748158259706, 0.0, 0.7126656189865445, 1.0, 0.5286917254258788, 0.0, 0.6217754847566552, 0.0, 0.0, 0.8006545105288169, 0.0, 0.0, 0.5757858627744116, 0.0, 0.0, 0.6396059599458888, 0.08707120557730819, 1.0, 0.0, 1.0, 0.4560268887150325, 0.0, 0.0, 0.6027285271595403, 0.24555062594449106, 0.0, 0.0, 0.8885123121612181, 0.0, 0.0, 0.0, 0.7597805667916144, 0.5562286609077549, 0.7176320809573438, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8902366217957709, 0.1149063433619103, 0.0038371455078008987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4991989468413318, 0.0, 0.8726258854858964, 0.0, 0.0, 0.30858394248684795, 0.0, 0.0, 1.0, 0.0, 0.9172205918248628, 0.446441467337642, 0.0, 0.5691417246177293, 0.0, 0.2748888400666839, 0.0, 0.16706260768133896, 0.9857682495857412, 1.0, 0.39861592931143663, 0.6607797016082162, 0.4554045512892506, 0.9589318272095946, 1.0, 0.0, 0.0, 0.06250694151041081, 0.6125335361782434, 0.0, 0.0, 0.0, 0.5197057412086442, 0.6617038454813468, 0.21912606467080087, 0.0, 0.59643395462566, 0.48468951693630746, 0.9731323459550647, 0.6195181145069641, 0.0, 0.4686431682473048, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.680672373225737, 0.0, 0.5109707430450621, 0.0, 0.0, 0.9779141546988203, 0.0, 1.0, 0.6123048451609933, 0.86163179911181, 0.0, 0.0, 0.0, 0.5076376964803742, 0.0, 0.14444887656412753, 0.0, 0.0, 0.06327544414650987, 0.4843234489229269, 0.502746113409122, 0.8215839034365042, 0.10815501457335674, 0.0, 0.6141331761875181, 0.3258245840194487, 0.0, 0.0, 0.0, 0.0, 0.8514057478914739, 0.08426436615585109, 0.0, 0.6803844137625221, 0.0, 0.0, 0.0, 0.2109771554518658, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8365308907609035, 0.0, 0.0, 0.0, 0.3062678870046147, 0.7349187156614274, 0.0, 0.19287056868961427, 0.09271481081026989, 0.0, 0.0, 0.8986201575301365, 0.0, 0.0, 1.0, 1.0, 0.0, 0.7074262751619323, 0.2882220550090505, 0.8983552751676653, 0.41731385344541716, 0.1241073677137774, 0.0, 0.7211323573568237, 0.0, 0.0, 0.0, 0.0, 0.7511809729800681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25747897614372484, 0.0, 0.0, 0.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.325061204894064E-4, 0.0018798835249106416, 0.003090781410644672, 0.0036017063209445865, 0.005026552609803114, 0.008257382832161153, 0.009453967229866578, 0.010090606689024728, 0.012714889986893518, 0.015742912995676983, 0.018763625655696115, 0.020449159618243118, 0.022895766948426655, 0.02452697168597817, 0.025237345848264203, 0.02583537137198444, 0.029233793525217044, 0.03273641247363446, 0.03593867492155334, 0.042291749222681196, 0.04267711210541281, 0.04367990661247245, 0.04377780935105169, 0.04496144159155113, 0.04545250043579596, 0.05021443169045525, 0.050887856910559526, 0.05239129559486122, 0.05335556600645375, 0.05607171652354215, 0.057280251077623356, 0.058727551758148366, 0.06100714300539489, 0.06310903307915017, 0.06919270268351019, 0.07161649436369255, 0.07189816449021347, 0.07574572539688407, 0.08220706371178166, 0.08503413492203138, 0.08884024508756438, 0.08991624485970229, 0.0913741048604092, 0.09216795847243231, 0.09342778932783724, 0.09393411431363474, 0.09446116207109889, 0.0957290547443973, 0.09729448955464381, 0.09870398922535117, 0.10173837270729402, 0.10232532732204336, 0.10493471114875419, 0.10559154597664, 0.10640541354986843, 0.11006328420111522, 0.11113714733201241, 0.11344081710391674, 0.11557572449802289, 0.11726561932657797, 0.1177414439051524, 0.11956199775205645, 0.12322265417216605, 0.12535647579238562, 0.12627113710773186, 0.12689115723577238, 0.12736419745316474, 0.12745395942286897, 0.12960065119544195, 0.12994137226794122, 0.13105574772085493, 0.13196531962396174, 0.13264457760095316, 0.13356133247235458, 0.13699906305367138, 0.13801309159572772, 0.14017616460872406, 0.14177439352710186, 0.1438143503148137, 0.14479301498163, 0.14798414736583476, 0.1504657845120987, 0.150608103218274, 0.15177540985110205, 0.15513767251036725, 0.15638180440344795, 0.15830390010561435, 0.1590250037402613, 0.16493405454498, 0.16679564340332564, 0.16811812839929585, 0.16833695591913023, 0.16885420667768614, 0.17129495782167037, 0.173185026203581, 0.17609547133059467, 0.1771709252718655, 0.1817232932281565, 0.18537277908251149, 0.18903952472753172, 0.19081682886096896, 0.19455832318530097, 0.19809551672028958, 0.199411597758535, 0.20065101740376123, 0.20357837754636043, 0.20730900318755796, 0.20853645911048102, 0.20975294768368136, 0.21078144935468823, 0.21111247116613618, 0.21347761760915296, 0.21462807325880284, 0.21927396192387572, 0.22190046078437287, 0.22642789826927967, 0.22740949586137893, 0.22917195121416212, 0.23178359028935003, 0.23276314710128876, 0.23465344177584935, 0.2368916363986917, 0.237517115524447, 0.23832412378633738, 0.2400707404875665, 0.2403823886994838, 0.2422312178245669, 0.24251811521058264, 0.24347796840486724, 0.24640536925424705, 0.24751007314041196, 0.24997158785780882, 0.25108010366516775, 0.2560475651049543, 0.2590187497254215, 0.2626756425986517, 0.2644718166671908, 0.2672526297935953, 0.2695036390412098, 0.27136596353901055, 0.2754831486013819, 0.2768505135353705, 0.2828011306704997, 0.28481354521975877, 0.2855892363734017, 0.2891152833176809, 0.2925150910707418, 0.29507234926430936, 0.29639200687528344, 0.30085310835325507, 0.30228369244670705, 0.30319405946104605, 0.306051463522788, 0.30752979549045634, 0.30883442400734085, 0.31296084941751945, 0.3146046565539943, 0.31810444690347206, 0.3204500728660916, 0.3225265851765271, 0.32387460241170973, 0.32415225353566357, 0.32525390592455194, 0.3299674621924332, 0.3322055709473216, 0.33314557898573216, 0.3369647257174565, 0.3375324658838189, 0.3405448354798969, 0.34167450189692083, 0.34184728549809207, 0.34243968722197693, 0.34366319260910305, 0.3479069381183494, 0.3495747511761357, 0.3518949654658766, 0.3524835351566369, 0.35423624044477453, 0.35552972287896634, 0.35833465667167375, 0.3609678410850792, 0.36346135324664564, 0.3638096411409335, 0.36411277501049943\u001b[0m\n",
      "\u001b[34m, 0.3645563543404774, 0.36709366932156584, 0.3677336508051099, 0.36791017049375774, 0.37324115637923383, 0.37354298032307287, 0.3765302877892983, 0.3774803042702548, 0.3803005598005843, 0.381227922958995, 0.3832842396422014, 0.38551422248836875, 0.3898723529415441, 0.39012023468833923, 0.3905936075817822, 0.3936290555666244, 0.3962030080709039, 0.3969604449467167, 0.39916679451101955, 0.4009417624730467, 0.40244663743366893, 0.4040111578165182, 0.4057092494382253, 0.40667406999858313, 0.40798315721093714, 0.40877726122913205, 0.4097392364429391, 0.41516136831111794, 0.41533190983417523, 0.41644303267518146, 0.41779124023176883, 0.41880457627904344, 0.4229593355380892, 0.4242968858848881, 0.4289849318408905, 0.43108686262328944, 0.4344500350785596, 0.4353709490027369, 0.4363400289712378, 0.4403115551620601, 0.44123405537560234, 0.4435437941745436, 0.44411524649633227, 0.4506864749389131, 0.4511613432799413, 0.4530367486286119, 0.4544148173308522, 0.4551723424548132, 0.4553831354806076, 0.45746563146774855, 0.45835358178324015, 0.45896347937729864, 0.4591892337325618, 0.46144551188731264, 0.46299251164864164, 0.46381424972767993, 0.46497449540106717, 0.4667820772311879, 0.4677424688510239, 0.46840053539556914, 0.4695186653456337, 0.469641774680709, 0.46991537203359535, 0.4712755809015643, 0.4740064284831559, 0.4764135147785471, 0.4769152754182153, 0.47755585459453553, 0.4782598841952235, 0.4870778352252343, 0.49141817752855677, 0.4922323151824083, 0.49350099215440824, 0.4973124461689724, 0.49823600049927297, 0.4992890741633287, 0.5004773158667182, 0.5046190246076956, 0.5074463661197421, 0.5116357178950771, 0.512726394261776, 0.5146575865735116, 0.5153984129811353, 0.517596301315522, 0.5182761764476463, 0.5199526226899144, 0.5206455598621482, 0.5208167705564001, 0.5225397167320532, 0.5240322689883441, 0.5266237972689596, 0.5307373552868359, 0.5330320000363893, 0.5333922153027841, 0.5353581018426609, 0.5367063467272032, 0.538813009039619, 0.5415335754307422, 0.5425569441301118, 0.5448477590845157, 0.5455821217920664, 0.5474148403797259, 0.5493803432702421, 0.5495836567221436, 0.5504717771029405, 0.5511469283252918, 0.5520693646533779, 0.5537987790224563, 0.554356681216369, 0.5583523150641136, 0.5644945456018406, 0.5654199676077424, 0.5684648985079399, 0.5725043496432408, 0.5740622915330605, 0.5772497307686131, 0.5810150933751095, 0.5838785719289077, 0.5842024993125499, 0.5850784422062031, 0.5854839351832077, 0.5861725346792042, 0.588135259582504, 0.5886254285874106, 0.5902326591508927, 0.5930145003605977, 0.594248831384939, 0.5953596612586041, 0.5972924203534693, 0.5985543690868064, 0.6006095425462361, 0.6021169853547795, 0.602553163842865, 0.6038509825402779, 0.6047940736900298, 0.6076062784715255, 0.6123264052496058, 0.6141254971048841, 0.6151963827788968, 0.6164281773718701, 0.6194977514075877, 0.6209085902177081, 0.6218992302125492, 0.6243277481182735, 0.6247400955573337, 0.6265374038558266, 0.6284534886801256, 0.6300398784799822, 0.6320898295062423, 0.6346392564873805, 0.6363068752438598, 0.6401682238281661, 0.6401983115596238, 0.6416319088273545, 0.6448683522461874, 0.6451586397431096, 0.6466004439486619, 0.6497970089092697, 0.6514263327580295, 0.6531140236356144, 0.6543750064235985, 0.6551823922538302, 0.6582175952632383, 0.6591137644695265, 0.6625196743251018, 0.6626890458487724, 0.6649945162377737, 0.6664304505277996, 0.6673503980464284, 0.6714246695306144, 0.6737017335421565, 0.6743151979360468, 0.6771524124576737, 0.677540945503534, 0.6791991512011694, 0.6799726834376081, 0.6807558929604856, 0.6819504274490813, 0.6834132400913489, 0.6837541055770425, 0.6857005429336439, 0.6868367981702229, 0.6880159796735815, 0.6889975052673197, 0.690405721911072, 0.6921136179837506, 0.6954156483280532, 0.69662727121739, 0.6995106143995676, 0.7012171289457484, 0.7031307254397192, 0.7061585021190541, 0.7076883263306187, 0.7084896974927973, 0.7094124401936449, 0.7121687011483941, 0.712845995860955, 0.7176357859086295, 0.721542453626427, 0.7222473762507389, 0.7242425955587187, 0.724856499315017, 0.729234742913643, 0.7311573444549172, 0.7324138648126686, 0.736200425060762, 0.7394082298313118, 0.7428249749063163, 0.743256503690242, 0.7451794953696144, 0.745753379076126, 0.7477943497593724, 0.7521286995435712, 0.7546212215985918, 0.760841222217757, 0.7628933355543641, 0.7649627851961749, 0.7658290392349099, 0.7674486416346199, 0.7704472210739898, 0.7735388915345639, 0.7737247491834002, 0.7747762977315102, 0.7769379384572431, 0.7797746986226849, 0.78019465117681, 0.780731853200901, 0.7813488406144062, 0.7817401273062705, 0.7830166373167329, 0.7839398837552336, 0.784499241132449, 0.7848618229588802, 0.7867083407073091, 0.7888022639053596, 0.7914116322589493, 0.7934072581478373, 0.7938138354815736, 0.7945985915219707, 0.7959753342614213, 0.7963328622273151, 0.7989012725573326, 0.801684293191305, 0.8048028354281175, 0.8061958810037908, 0.8082175444081394, 0.8085723195004575, 0.8088679115511032, 0.809183171139031, 0.8106859279862663, 0.8121571474622259, 0.8132767042269585, 0.8194817716075764, 0.8236064207981895, 0.8259183246885707, 0.8281168290063428, 0.8340989756292138, 0.8347579495573968, 0.8363161985346985, 0.8394609095007669, 0.8399639802821826, 0.8423255047499341, 0.8447894362860214, 0.8470161991714373, 0.8503985504730475, 0.8517825379006754, 0.8547034500931975, 0.8573089023608409, 0.8595652316469458, 0.8643116822077207, 0.8649198537742393, 0.8676276209650275, 0.8692596246510526, 0.8715977272882306, 0.8720483384470077, 0.8738749555210183, 0.8748747428582531, 0.8767674242836752, 0.8785046089122346, 0.8798219139516953, 0.8814507796750214, 0.8821356142820601, 0.8830764644746085, 0.8857142300020205, 0.886890180923427, 0.8887912526617813, 0.8911066860189609, 0.8936627026517728, 0.894265118256414, 0.8957267259261729, 0.8990588000224785, 0.9014170729775877, 0.9035584434325303, 0.9056725737089564, 0.9103736608450579, 0.9129310047746899, 0.9147311149565036, 0.916603301642411, 0.9187347106063773, 0.9202971812194077, 0.9228548314604181, 0.9235831405619486, 0.925178794805027, 0.9269163463311081, 0.9292573980072293, 0.9300683942905659, 0.9310099708852998, 0.9334723917891448, 0.9343078835103408, 0.9368597070726087, 0.9373784381643208, 0.9405284311327192, 0.9423153896731928, 0.9447774792569715, 0.9471960395314719, 0.9519076895879646, 0.9532141550282315, 0.9535350978515088, 0.9547508109811121, 0.9585008328169206, 0.9616657359548132, 0.9638231608784736, 0.9685781784887271, 0.9720252564965911, 0.9760326986002038, 0.9796467150338835, 0.984234499234434, 0.9867489664960895, 0.9885075267018847, 0.9894317657796315, 0.9905460327701334, 0.9912938529374564, 0.9946486415599979, 0.9961229496394411, 0.9968590939518779, 0.9986537290434363, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009072404652724964, 0.0724162721463415, 0.11836286722964984, 0.15734065970252598, 0.17419333657825364, 0.24630116594948082, 0.2941679733434779, 0.33637046382842206, 0.3911697660803798, 0.413031174647697, 0.44877757383140304, 0.5048448818930178, 0.5584126725831979, 0.5987139801001076, 0.6521232455304379, 0.7248265598740583, 0.77529882302732, 0.8306425177506246, 0.8841989781315029, 0.934373855425987, 0.9658122340608418, 0.9866929803571616, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_wa\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.14034816146728335,\n",
      "      \"sum\" : 1152.118057484929,\n",
      "      \"std_dev\" : 0.31386175551326234,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 6614.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 117.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 112.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 107.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 111.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 110.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 104.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 106.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 116.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 712.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.06810902472352254, 0.0, 0.0, 0.466116292658489, 0.5546134740221278, 0.0, 0.24739974705834578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16276278177818193, 1.0, 0.0, 0.0, 0.0, 0.8570391223992478, 0.0, 0.755838391283847, 0.0, 0.0, 0.0, 0.04758469400335641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9741906071368183, 0.0, 0.47955059583471404, 0.0, 0.0, 0.0, 0.0, 0.9175430096537447, 0.0, 0.0, 0.0, 0.5248999867258383, 0.5488068085492763, 0.0, 0.4107853856521445, 0.0, 0.0, 0.0, 0.9840315142791302, 0.0, 0.2432419097530717, 0.6805581617791014, 0.0, 0.059105820875654524, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.16987259440447633, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9585719111806122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8876355180510144, 0.6680135285672972, 0.21836744194675284, 0.5629484781578123, 0.3722545851026636, 0.35254205925445403, 0.0, 0.3249227944066413, 0.0, 0.9616158070461657, 0.730243334357868, 0.5101295232822555, 0.36928255550807076, 0.0, 0.0, 0.0, 0.0, 0.810468217215466, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3242387071047762, 0.0, 0.4314477443953879, 1.0, 0.6328026106615069, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2992744787157362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19881406093740295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5269724966569793, 0.956684726745688, 0.0, 0.0, 0.0, 0.0, 0.8042443935943754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06092872172071995, 0.0, 0.0, 0.6809549256677602, 0.0, 0.0, 0.7574217339261748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9390980669005067, 1.0, 0.7144141014704978, 0.0, 0.12537534923387328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.672579041266552, 0.0, 0.18117185085002008, 0.0, 0.615267423492555, 0.0, 0.0, 0.0, 0.0, 0.1684592136623344, 0.0, 0.27692836395033116, 0.7726709881281666, 0.7148995340913137, 0.0, 0.01460899710888286, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6384887847991355, 0.0, 0.05711716337044326, 0.0, 9.294168699610639E-4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0837249378453484, 0.6140604890630726, 0.0, 0.0, 0.8486288287367251, 0.0, 0.0, 0.0, 0.81754195934751, 0.9652096385457352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7934189837782192, 0.0, 0.0, 0.0, 0.0, 0.47659281493252814, 0.0, 0.812077611008679, 0.0, 0.0, 0.0, 0.765193833754392, 0.143161357811193, 0.3422838527240465, 0.0, 0.02556979908973467, 0.0, 0.0, 0.0, 0.0, 0.9175940281380518, 0.0, 0.5143531346657229, 0.0, 0.0, 0.8713152472468535, 0.0, 1.0, 0.0, 0.0, 0.1466707834412122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3060471662287715, 0.9363152324974833, 0.0, 1.0, 0.0, 0.0, 0.682652605044199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35316277107361904, 0.0, 0.6383505774204318, 0.0, 0.0, 0.9594721829554119, 0.0, 0.0, 0.0, 0.1794478607442812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0661340571537512, 0.0, 0.0, 0.0, 0.9221919280512842, 0.14199425935208465, 0.30424186382719576, 0.0, 0.0, 0.30630099688753754, 0.0, 0.0, 0.34979606180759193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41737135395963443, 0.0, 0.0, 0.0, 0.9438379900966869, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5841386605920524, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046063063681977434, 0.0, 0.0, 0.0, 0.31157173958222895, 0.8456535222773424, 0.0, 0.9983562428875503, 1.0, 0.0, 0.0, 0.0, 0.8945947140438331, 0.0, 0.4870206501790926, 0.0, 0.8222281125770106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6922971866101562, 0.24217465034747054, 0.0, 0.0, 0.0, 0.7655005223259063, 0.0, 0.0, 0.0, 0.0, 0.7502607940873155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6865139430432525, 0.0, 0.12254787339683115, 0.7731835012587582, 0.0, 0.03172249181603115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8865025266419025, 1.0, 0.13707760648901102, 0.0, 0.5346609230755238, 0.14123857016129604, 0.6741186573842096, 0.04595773492191424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8629790899636793, 0.5375846256925658, 0.8150797025328557, 0.0, 0.9385748707401673, 0.22392458779658952, 0.0, 0.0, 0.9774962582088932, 0.19213435431601877, 0.2625900556880538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08419241664932775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8646523546027457, 0.8813393855254612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11555837668063174, 0.0, 0.49753435023723447, 0.0, 0.19701869869089617, 0.0, 0.0, 1.0, 0.8784158630449617, 0.0, 0.0, 0.0, 0.0, 0.29906463498200075, 0.8057264289981986, 0.0, 0.0, 0.654725348498443, 0.4112040672118541, 0.33663746598531863, 0.0, 0.4014976105648763, 0.0, 0.0, 0.0, 0.04918134008356856, 0.7901023704137693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8291506402841399, 0.0, 0.0, 0.0, 0.5218410764441559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17405908088808175, 0.0, 0.07592701115431688, 0.0, 0.0, 0.0, 0.0, 0.3808319557569416, 0.0, 0.6888105035899871, 0.0, 0.0, 0.5740024805315719, 0.9677428248337157, 0.0, 0.4356046196610104, 0.0, 0.0, 0.0, 0.0, 0.28733438101345554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8489238694760728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7146956752357342, 1.0, 0.0, 0.0, 0.0, 1.0, 0.27113019551165884, 0.0, 0.0, 0.0, 0.8902366217957709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9454880725621737, 0.0, 0.0, 0.7834208143727591, 0.12737411451410363, 0.0, 0.0, 0.691416057513152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43085827538227073, 1.0, 0.0, 0.20369933658486783, 0.16706260768133896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4165784809815649, 0.0, 0.0, 0.0, 0.6617038454813468, 0.0, 0.0, 0.0, 0.5153104830636925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.381709201245212, 0.31932762677426296, 0.0, 0.0, 0.0, 0.9462180358226221, 0.0, 0.0, 0.33366089063369264, 0.6123048451609933, 0.0, 0.7381682705368436, 0.0, 0.0, 0.0, 0.0, 0.8555511234358725, 1.0, 0.0, 0.0, 0.5156765510770731, 0.0, 0.0, 0.0, 0.15789313751648837, 0.0, 0.0, 0.19173621739026647, 0.0, 0.41608071073886466, 0.0, 0.0, 0.0, 0.6439069148335783, 0.0, 0.7258796361807993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7135262622554164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26125649038406973, 0.0, 0.0, 0.0, 0.0, 0.9072851891897301, 0.5322228748561939, 0.0, 0.0, 0.0, 0.8115720043515481, 0.5177259999184565, 0.0, 0.8254101487528136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8785850944950279, 0.7211323573568237, 0.0, 0.0, 0.4872120069219139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2719877422038026, 0.8131476551679849, 0.0, 0.0, 0.6144464355986862, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.427814372078842E-4, 0.0028812516656145926, 0.005718581360789288, 0.008257382832161153, 0.012907227980991975, 0.01419467914979422, 0.018386142151597284, 0.022026921223816998, 0.027519185140415292, 0.029668223064739818, 0.03142182151127293, 0.03366917821387272, 0.03557086703554835, 0.04524918901888786, 0.046464902148491194, 0.047103204002172494, 0.05233887578650831, 0.055525032809150554, 0.05768461032680716, 0.059093890078253275, 0.05958079269925309, 0.06290897154120523, 0.06314029292739132, 0.06482791327350668, 0.0683341048456042, 0.07168246715142301, 0.07308365366889191, 0.07462981433708171, 0.07589228408872051, 0.08022224645571407, 0.08261766345926869, 0.08474281508217696, 0.08534133648432485, 0.08676731957854367, 0.08932342056486042, 0.09319611956269469, 0.0977635965377619, 0.10312136240807579, 0.10395920034278094, 0.10585323587790885, 0.10810689674343743, 0.11034796698243365, 0.11153589007707931, 0.11438023575822676, 0.11557572449802289, 0.11843654505924306, 0.12024722651167563, 0.12471405691139048, 0.12512525714174694, 0.12777465278999045, 0.13039391752522256, 0.1318307046734959, 0.133650581410518, 0.13686446226426097, 0.14044360308206316, 0.14217044670389556, 0.1451965128846603, 0.1458640023494957, 0.14821746209932463, 0.1528326386274258, 0.1555714368693023, 0.15732628000182824, 0.1635015093819665, 0.1656966340452325, 0.16716809813092426, 0.17011541730928148, 0.17041244313474968, 0.17264344517385444, 0.17325323197375297, 0.1733816544975113, 0.17521214372221328, 0.1771709252718655, 0.1781935560989132, 0.18074489512853886, 0.18280723665690046, 0.18691444060846163, 0.1878428525377741, 0.18913910002298462, 0.19192071764417007, 0.193410657673723, 0.19831570680869504, 0.20065101740376123, 0.20660598569465227, 0.20795635928938994, 0.20858836774105072, 0.21308500868480817, 0.21339334797568954, 0.21462807325880284, 0.21601264131064457, 0.21615732323232617, 0.21695624586387952, 0.2176116705399127, 0.21794923073624173, 0.21838452080360093, 0.219268146799099, 0.22106337145372845, 0.22609377822933485, 0.22672738232996326, 0.22848793800151235, 0.23025092071051467, 0.23483967118323368, 0.2358575991436871, 0.24038857130020352, 0.24373534210854741, 0.2468126640865972, 0.25045451553111175, 0.25183917361231445, 0.2522056502406276, 0.253223360466282, 0.256743496309758, 0.25943527674049005, 0.2659702374106937, 0.26758613518733143, 0.26804193241436547, 0.270765257086357, 0.27809951506635644, 0.279745967769071, 0.28088196518624375, 0.2824278752684056, 0.2849612811493162, 0.289970118943609, 0.29151030250720267, 0.29426673663711433, 0.2973615313084723, 0.2988571352590308, 0.299748040555479, 0.30048938560043237, 0.3022437239265705, 0.3053462271898246, 0.31189908000428046, 0.31219636821760366, 0.31259363586376243, 0.31372769119409605, 0.3165462225924911, 0.3171957167653986, 0.31833051759837994, 0.3210810970870501, 0.32261267848128317, 0.3244199080497402, 0.32485993885033193, 0.3257411579935009, 0.3321097833081246, 0.33360678902904317, 0.3409644657963192, 0.34481760774616976, 0.3502029910907303, 0.3533995560513381, 0.353903824994937, 0.35836809117264545, 0.35983177617183393, 0.3620392066840299, 0.36310073663401043, 0.3665882597578729, 0.3714859436594342, 0.37220039182521925, 0.3769855419262801, 0.3786555027464704, 0.3803840730550777, 0.3814729412818144, 0.388059494662669, 0.3897593874264921, 0.3918239632835, 0.39413604678262815, 0.39570796357379256, 0.3967805897866278, 0.3973813904853165, 0.39822779395801167, 0.40087941495967483, 0.40976734084910726, 0.414735826967471, 0.4161214280710923, 0.41701557383539756, 0.4223845221843059, 0.4227502692313869, 0.4252204457355848, 0.426650654364782, 0.4274956503567592, 0.4288868788610386, 0.43086209153803334, 0.43138064877407467, 0.4331631113151664, 0.4355076254721907, 0.4367110690461853, 0.4399083025566045, 0.4405735280123073, 0.4436719927429207, 0.4441277131657516, 0.44564331878363095, 0.44760294032021697, 0.4501233611819322, 0.450677520596826, 0.4511613432799413, 0.4519676433357599, 0.45330367170366015, 0.4584664245692578, 0.4593314408005428, 0.4622170652586235, 0.463990131464425, 0.4675073005628534, 0.4733762027310404, 0.4737215396617973, 0.47495096526374825, 0.4780469965214361, 0.4784006039886418, 0.4827606182856681, 0.4848248296662684, 0.487273605738224, 0.48785119719240644, 0.4946751895912833, 0.49689551850004887, 0.49943176986683535, 0.5006661650213817, 0.501763999500727, 0.5063303093542678, 0.5101483804563233, 0.5183651534651377, 0.5197042628944842, 0.52150388374\u001b[0m\n",
      "\u001b[34m40381, 0.5231430206971652, 0.5236005471526117, 0.5258357037280136, 0.5279395658030017, 0.5291326437768232, 0.5315773967749932, 0.5376088230874593, 0.5381565187248897, 0.5416464182167599, 0.5440207242400631, 0.5468759658760446, 0.5483205837264242, 0.5496062685307567, 0.5535580782034513, 0.5547538877152118, 0.5566370579367172, 0.5609044347491715, 0.5646290509972631, 0.5665753621714186, 0.5710150681591095, 0.5754093872861483, 0.5797311661341921, 0.5829844261646024, 0.5843961040926645, 0.586479092188707, 0.5891429081595035, 0.5902607635570609, 0.5914067594224881, 0.5922842293347748, 0.5934857629759347, 0.5952749361703413, 0.5975533625663311, 0.5985543690868064, 0.598845400079439, 0.6024698307034551, 0.6033341962120348, 0.6054117575075872, 0.60687734157693, 0.6101276470584559, 0.6137880071829693, 0.614386487134352, 0.6159573616088996, 0.6172490208487257, 0.6189481930077215, 0.6193103188391342, 0.6196994401994157, 0.6241949841539137, 0.6261761715931382, 0.6279933826040981, 0.6285779981269543, 0.6331896260134641, 0.6363546410805504, 0.6365386467533544, 0.6375532644702298, 0.6425759689471896, 0.6432312883767274, 0.6445911747423436, 0.6452898375257169, 0.6473973940711418, 0.6495867499898026, 0.6540757953719981, 0.6582175952632383, 0.6631594981388967, 0.6666170848793723, 0.6758477464643364, 0.6764996050885262, 0.6803331675594553, 0.6813530132413488, 0.6823053024528378, 0.6874063641362376, 0.6980832999224982, 0.6985306252091371, 0.700867635861432, 0.7024883415884688, 0.7045320753732407, 0.7074849089292582, 0.7144107636265983, 0.7215605917495654, 0.7245168513986181, 0.7251855480273908, 0.7284312352489601, 0.7288525634998152, 0.7302461470901459, 0.7322233245116658, 0.7346125908118054, 0.7370965504320512, 0.7396713007267637, 0.7406261488943705, 0.7434237860766093, 0.745860038627012, 0.7464158830036308, 0.7471863939107994, 0.7514197422850579, 0.7537340704280046, 0.753865073836925, 0.7618836118624439, 0.767944260298844, 0.7685199040870118, 0.7725905041386211, 0.7747762977315102, 0.7764893026510181, 0.7795115653108936, 0.7805560268872138, 0.7809638636444353, 0.7837723890172492, 0.7859252762089134, 0.7880175090977615, 0.79113592929426, 0.7962405955628543, 0.7989012725573326, 0.8019044832797104, 0.8035181084349343, 0.8047531219896948, 0.8087395820854133, 0.8117522168657099, 0.8166821754507181, 0.8196920645772219, 0.8224946492902271, 0.8251321959287038, 0.8266569470247191, 0.8279139675473736, 0.831863113251422, 0.8354802363823276, 0.8382653595457049, 0.8398203522034884, 0.8413211263103151, 0.8442487024058184, 0.8476704105354645, 0.8548034871153397, 0.8561324990137434, 0.8608841511089125, 0.861128673603483, 0.8628805029124124, 0.8629723989869625, 0.8649198537742393, 0.8658201652223552, 0.8684817330836221, 0.8726305265521189, 0.8738749555210183, 0.8754056251218343, 0.8778884840757121, 0.8819921697216359, 0.8855684813876414, 0.8929428214458139, 0.8936562737442254, 0.8989008240062354, 0.8994552125461016, 0.9037575717751422, 0.9050915587326538, 0.9069428088348339, 0.9071998215606223, 0.910187845717226, 0.9124087025940536, 0.9149658650779686, 0.925957782087652, 0.9296058774219892, 0.9308873720608084, 0.9325445893524509, 0.9386690443567174, 0.9402835110291107, 0.9439282834764579, 0.947035987738723, 0.9492006931808914, 0.9513423363382867, 0.9545967185313075, 0.9562643741200305, 0.9615133389830848, 0.9619781517625451, 0.969062355268658, 0.9704959448547941, 0.970766206474783, 0.9720252564965911, 0.9832436955076176, 0.9841868037670379, 0.9853329429537362, 0.9862466719514015, 0.9877495390991885, 0.9885216479954467, 0.9912632267336332, 0.9937425289735298, 0.9948579730593216, 0.9963982936790554, 0.9995439187190943, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01836763694054, 0.06562614457401295, 0.12443755729685635, 0.19923031287012494, 0.2291458914590102, 0.283854528608645, 0.34499066116789145, 0.39163014054035605, 0.4401556876911705, 0.4664880747003044, 0.5048448818930178, 0.5354014033641898, 0.5878843711103869, 0.600798446442198, 0.6253046602139478, 0.7011641136626862, 0.7654387066651713, 0.7836759769634465, 0.8395998946699279, 0.8646088359550367, 0.8790714802281316, 0.8974361480462039, 0.948303162758473, 0.9572702629833256, 0.9866929803571616, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"months_as_customer\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 85.4144231940553,\n",
      "      \"sum\" : 701167.0,\n",
      "      \"std_dev\" : 69.45758920237958,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 496.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 50.5,\n",
      "            \"count\" : 3136.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 50.5,\n",
      "            \"upper_bound\" : 100.0,\n",
      "            \"count\" : 2298.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 100.0,\n",
      "            \"upper_bound\" : 149.5,\n",
      "            \"count\" : 1475.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 149.5,\n",
      "            \"upper_bound\" : 199.0,\n",
      "            \"count\" : 722.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 199.0,\n",
      "            \"upper_bound\" : 248.5,\n",
      "            \"count\" : 342.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 248.5,\n",
      "            \"upper_bound\" : 298.0,\n",
      "            \"count\" : 135.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 298.0,\n",
      "            \"upper_bound\" : 347.5,\n",
      "            \"count\" : 52.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 347.5,\n",
      "            \"upper_bound\" : 397.0,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 397.0,\n",
      "            \"upper_bound\" : 446.5,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 446.5,\n",
      "            \"upper_bound\" : 496.0,\n",
      "            \"count\" : 13.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 40.0, 83.0, 36.0, 27.0, 9.0, 33.0, 2.0, 167.0, 16.0, 45.0, 54.0, 38.0, 10.0, 459.0, 106.0, 33.0, 63.0, 166.0, 11.0, 3.0, 37.0, 95.0, 81.0, 29.0, 38.0, 14.0, 27.0, 3.0, 32.0, 1.0, 14.0, 35.0, 146.0, 9.0, 8.0, 31.0, 3.0, 9.0, 15.0, 35.0, 79.0, 50.0, 41.0, 46.0, 106.0, 46.0, 88.0, 15.0, 11.0, 13.0, 22.0, 28.0, 59.0, 32.0, 6.0, 133.0, 29.0, 42.0, 68.0, 124.0, 126.0, 5.0, 45.0, 132.0, 87.0, 25.0, 16.0, 59.0, 34.0, 73.0, 19.0, 74.0, 30.0, 1.0, 32.0, 6.0, 33.0, 34.0, 22.0, 10.0, 13.0, 35.0, 172.0, 47.0, 80.0, 53.0, 23.0, 66.0, 14.0, 32.0, 8.0, 37.0, 31.0, 61.0, 188.0, 18.0, 27.0, 11.0, 124.0, 72.0, 85.0, 15.0, 99.0, 57.0, 66.0, 349.0, 9.0, 151.0, 37.0, 32.0, 37.0, 9.0, 33.0, 72.0, 8.0, 18.0, 52.0, 40.0, 19.0, 2.0, 81.0, 63.0, 21.0, 27.0, 39.0, 3.0, 41.0, 38.0, 3.0, 83.0, 82.0, 84.0, 118.0, 51.0, 36.0, 35.0, 88.0, 41.0, 179.0, 28.0, 5.0, 1.0, 15.0, 1.0, 6.0, 61.0, 30.0, 20.0, 6.0, 115.0, 41.0, 129.0, 6.0, 54.0, 20.0, 140.0, 14.0, 27.0, 19.0, 35.0, 13.0, 98.0, 19.0, 26.0, 104.0, 49.0, 16.0, 2.0, 11.0, 85.0, 25.0, 25.0, 45.0, 21.0, 45.0, 91.0, 61.0, 18.0, 172.0, 72.0, 168.0, 49.0, 85.0, 24.0, 57.0, 4.0, 27.0, 17.0, 55.0, 3.0, 28.0, 53.0, 42.0, 110.0, 103.0, 8.0, 125.0, 20.0, 12.0, 31.0, 51.0, 73.0, 12.0, 68.0, 2.0, 52.0, 95.0, 61.0, 59.0, 86.0, 57.0, 62.0, 4.0, 128.0, 32.0, 44.0, 49.0, 35.0, 50.0, 84.0, 7.0, 38.0, 121.0, 47.0, 31.0, 106.0, 34.0, 107.0, 8.0, 50.0, 18.0, 17.0, 47.0, 29.0, 14.0, 15.0, 61.0, 7.0, 6.0, 29.0, 87.0, 37.0, 34.0, 41.0, 111.0, 55.0, 29.0, 24.0, 36.0, 23.0, 105.0, 12.0, 39.0, 53.0, 7.0, 26.0, 29.0, 4.0, 69.0, 64.0, 38.0, 47.0, 29.0, 62.0, 3.0, 62.0, 114.0, 29.0, 33.0, 20.0, 20.0, 11.0, 18.0, 22.0, 209.0, 37.0, 178.0, 44.0, 36.0, 5.0, 41.0, 8.0, 96.0, 141.0, 32.0, 186.0, 2.0, 3.0, 2.0, 37.0, 22.0, 7.0, 3.0, 46.0, 38.0, 58.0, 85.0, 72.0, 1.0, 138.0, 49.0, 22.0, 4.0, 71.0, 31.0, 58.0, 106.0, 126.0, 26.0, 21.0, 84.0, 62.0, 51.0, 22.0, 28.0, 95.0, 69.0, 117.0, 80.0, 1.0, 71.0, 64.0, 77.0, 32.0, 27.0, 100.0, 120.0, 24.0, 52.0, 47.0, 85.0, 66.0, 29.0, 37.0, 105.0, 71.0, 9.0, 108.0, 144.0, 89.0, 44.0, 97.0, 114.0, 70.0, 5.0, 13.0, 43.0, 7.0, 162.0, 27.0, 5.0, 107.0, 39.0, 43.0, 57.0, 56.0, 19.0, 56.0, 5.0, 47.0, 33.0, 3.0, 20.0, 17.0, 3.0, 51.0, 123.0, 10.0, 23.0, 131.0, 66.0, 51.0, 27.0, 60.0, 5.0, 160.0, 55.0, 8.0, 37.0, 26.0, 69.0, 9.0, 51.0, 199.0, 49.0, 11.0, 83.0, 62.0, 36.0, 50.0, 79.0, 11.0, 13.0, 35.0, 41.0, 17.0, 67.0, 24.0, 84.0, 40.0, 43.0, 44.0, 60.0, 26.0, 84.0, 51.0, 28.0, 62.0, 15.0, 6.0, 65.0, 160.0, 43.0, 60.0, 63.0, 41.0, 39.0, 40.0, 24.0, 5.0, 3.0, 25.0, 133.0, 11.0, 43.0, 12.0, 7.0, 97.0, 5.0, 29.0, 73.0, 8.0, 30.0, 21.0, 16.0, 9.0, 288.0, 226.0, 56.0, 180.0, 283.0, 233.0, 59.0, 10.0, 22.0, 21.0, 46.0, 27.0, 51.0, 107.0, 35.0, 2.0, 29.0, 19.0, 35.0, 56.0, 3.0, 64.0, 54.0, 40.0, 6.0, 56.0, 87.0, 77.0, 1.0, 119.0, 105.0, 57.0, 20.0, 49.0, 21.0, 1.0, 3.0, 88.0, 311.0, 36.0, 21.0, 5.0, 109.0, 78.0, 42.0, 28.0, 34.0, 69.0, 62.0, 29.0, 9.0, 8.0, 57.0, 39.0, 35.0, 89.0, 51.0, 254.0, 35.0, 61.0, 23.0, 34.0, 39.0, 181.0, 7.0, 124.0, 12.0, 15.0, 80.0, 2.0, 89.0, 28.0, 33.0, 38.0, 35.0, 21.0, 57.0, 19.0, 48.0, 8.0, 64.0, 52.0, 94.0, 15.0, 20.0, 6.0, 47.0, 59.0, 140.0, 35.0, 15.0, 230.0, 26.0, 9.0, 5.0, 161.0, 26.0, 34.0, 132.0, 32.0, 88.0, 51.0, 304.0, 8.0, 67.0, 55.0, 8.0, 82.0, 83.0, 15.0, 64.0, 6.0, 31.0, 26.0, 121.0, 61.0, 17.0, 163.0, 44.0, 51.0, 44.0, 18.0, 15.0, 10.0, 40.0, 63.0, 5.0, 34.0, 79.0, 26.0, 63.0, 2.0, 65.0, 75.0, 82.0, 129.0, 14.0, 41.0, 88.0, 21.0, 104.0, 28.0, 19.0, 54.0, 53.0, 10.0, 29.0, 52.0, 11.0, 6.0, 49.0, 158.0, 30.0, 60.0, 10.0, 92.0, 27.0, 44.0, 173.0, 67.0, 5.0, 62.0, 53.0, 23.0, 51.0, 24.0, 51.0, 27.0, 101.0, 10.0, 29.0, 42.0, 9.0, 17.0, 91.0, 142.0, 49.0, 28.0, 118.0, 25.0, 37.0, 125.0, 25.0, 45.0, 49.0, 17.0, 83.0, 45.0, 38.0, 37.0, 193.0, 67.0, 55.0, 9.0, 40.0, 48.0, 28.0, 19.0, 22.0, 122.0, 29.0, 8.0, 57.0, 57.0, 19.0, 53.0, 48.0, 92.0, 21.0, 31.0, 172.0, 4.0, 27.0, 55.0, 385.0, 70.0, 9.0, 36.0, 200.0, 86.0, 16.0, 19.0, 41.0, 81.0, 31.0, 42.0, 41.0, 80.0, 38.0, 138.0, 154.0, 47.0, 40.0, 18.0, 40.0, 81.0, 110.0, 22.0, 153.0, 10.0, 93.0, 88.0, 181.0, 13.0, 17.0, 80.0, 24.0, 14.0, 40.0, 29.0, 57.0, 70.0, 10.0, 56.0, 32.0, 67.0, 27.0, 141.0, 18.0, 31.0, 73.0, 22.0, 61.0, 116.0, 18.0, 44.0, 21.0, 65.0, 33.0, 18.0, 14.0, 13.0, 26.0, 9.0, 28.0 ], [ 491.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0, 101.0, 101.0, 102.0, 102.0, 102.0, 102.0, 103.0, 103.0, 103.0, 103.0, 103.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 105.0, 105.0, 105.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 110.0, 110.0, 110.0, 110.0, 110.0, 111.0, 111.0, 111.0, 111.0, 111.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 113.0, 113.0, 113.0, 113.0, 113.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 115.0, 115.0, 115.0, 115.0, 116.0, 116.0, 116.0, 116.0, 117.0, 117.0, 117.0, 117.0, 117.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 120.0, 120.0, 120.0, 121.0, 121.0, 121.0, 121.0, 121.0, 122.0, 122.0, 122.0, 122.0, 122.0, 123.0, 123.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 125.0, 125.0, 125.0, 125.0, 125.0, 126.0, 126.0, 126.0, 127.0, 127.0, 128.0, 128.0, 128.0, 128.0, 128.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 131.0, 131.0, 131.0, 132.0, 132.0, 132.0, 132.0, 133.0, 133.0, 133.0, 133.0, 134.0, 134.0, 134.0, 134.0, 135.0, 135.0, 135.0, 135.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 137.0, 137.0, 137.0, 138.0, 138.0, 138.0, 138.0, 139.0, 139.0, 139.0, 139.0, 139.0, 140.0, 140.0, 140.0, 141.0, 142.0, 142.0, 142.0, 142.0, 143.0, 143.0, 144.0, 144.0, 145.0, 145.0, 145.0, 146.0, 146.0, 146.0, 147.0, 147.0, 148.0, 148.0, 148.0, 149.0, 149.0, 150.0, 150.0, 150.0, 150.0, 150.0, 151.0, 151.0, 151.0, 152.0, 152.0, 153.0, 153.0, 153.0, 154.0, 154.0, 155.0, 155.0, 155.0, 156.0, 157.0, 157.0, 157.0, 157.0, 157.0, 158.0, 159.0, 160.0, 160.0, 161.0, 161.0, 161.0, 162.0, 162.0, 163.0, 164.0, 165.0, 166.0, 166.0, 166.0, 167.0, 167.0, 167.0, 168.0, 168.0, 168.0, 169.0, 169.0, 169.0, 170.0, 170.0, 171.0, 171.0, 171.0, 171.0, 172.0, 173.0, 175.0, 175.0, 176.0, 177.0, 177.0, 177.0, 178.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 183.0, 184.0, 184.0, 185.0, 185.0, 186.0, 186.0, 186.0, 187.0, 187.0, 187.0, 188.0, 189.0, 189.0, 190.0, 191.0, 192.0, 193.0, 193.0, 195.0, 195.0, 195.0, 196.0, 196.0, 197.0, 197.0, 199.0, 200.0, 201.0, 201.0, 202.0, 203.0, 203.0, 204.0, 204.0, 206.0, 207.0, 209.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 217.0, 218.0, 222.0, 222.0, 225.0, 229.0, 230.0, 232.0, 232.0, 233.0, 235.0, 237.0, 238.0, 242.0, 242.0, 243.0, 247.0, 249.0, 250.0, 254.0, 255.0, 256.0, 257.0, 263.0, 264.0, 267.0, 269.0, 274.0, 286.0, 291.0, 294.0, 302.0, 306.0, 316.0, 321.0, 336.0, 352.0, 358.0, 378.0, 387.0, 395.0, 414.0, 418.0, 465.0 ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70\u001b[0m\n",
      "\u001b[34m.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 79.0, 79.0, 79.0, 79.0, 79.0, 80.0, 80.0, 80.0, 80.0, 80.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 85.0, 85.0, 85.0, 85.0, 85.0, 86.0, 86.0, 86.0, 86.0, 86.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 92.0, 92.0, 92.0, 92.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 96.0, 96.0, 96.0, 96.0, 96.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 101.0, 101.0, 101.0, 102.0, 102.0, 102.0, 102.0, 103.0, 103.0, 103.0, 103.0, 103.0, 104.0, 104.0, 104.0, 104.0, 104.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 107.0, 107.0, 107.0, 107.0, 107.0, 108.0, 108.0, 108.0, 108.0, 108.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 110.0, 110.0, 110.0, 110.0, 111.0, 111.0, 111.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 114.0, 114.0, 114.0, 114.0, 114.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 116.0, 116.0, 116.0, 116.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 119.0, 119.0, 119.0, 119.0, 119.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 121.0, 121.0, 121.0, 121.0, 122.0, 122.0, 122.0, 122.0, 122.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 124.0, 124.0, 124.0, 124.0, 124.0, 125.0, 125.0, 125.0, 125.0, 125.0, 126.0, 126.0, 126.0, 126.0, 126.0, 127.0, 127.0, 127.0, 127.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 130.0, 130.0, 130.0, 130.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 132.0, 132.0, 132.0, 133.0, 133.0, 133.0, 133.0, 133.0, 134.0, 134.0, 134.0, 135.0, 135.0, 135.0, 135.0, 136.0, 136.0, 136.0, 136.0, 136.0, 137.0, 137.0, 137.0, 138.0, 138.0, 138.0, 138.0, 138.0, 139.0, 139.0, 139.0, 139.0, 140.0, 140.0, 140.0, 140.0, 141.0, 141.0, 141.0, 141.0, 141.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 143.0, 143.0, 143.0, 143.0, 143.0, 144.0, 144.0, 144.0, 144.0, 145.0, 145.0, 145.0, 145.0, 146.0, 146.0, 146.0, 146.0, 147.0, 147.0, 147.0, 148.0, 148.0, 148.0, 149.0, 149.0, 150.0, 150.0, 150.0, 150.0, 151.0, 151.0, 151.0, 152.0, 152.0, 152.0, 153.0, 153.0, 154.0, 154.0, 154.0, 154.0, 155.0, 155.0, 155.0, 156.0, 156.0, 157.0, 157.0, 157.0, 158.0, 158.0, 158.0, 159.0, 159.0, 159.0, 159.0, 160.0, 160.0, 160.0, 161.0, 161.0, 162.0, 162.0, 163.0, 163.0, 163.0, 164.0, 164.0, 165.0, 165.0, 165.0, 165.0, 166.0, 166.0, 166.0, 167.0, 168.0, 168.0, 168.0, 169.0, 169.0, 170.0, 170.0, 170.0, 171.0, 171.0, 171.0, 171.0, 172.0, 172.0, 172.0, 173.0, 173.0, 173.0, 173.0, 174.0, 174.0, 174.0, 175.0, 175.0, 175.0, 176.0, 176.0, 176.0, 176.0, 177.0, 177.0, 177.0, 178.0, 178.0, 179.0, 179.0, 180.0, 180.0, 180.0, 180.0, 181.0, 181.0, 182.0, 183.0, 183.0, 183.0, 184.0, 184.0, 185.0, 185.0, 186.0, 186.0, 186.0, 186.0, 187.0, 187.0, 188.0, 188.0, 188.0, 189.0, 190.0, 191.0, 191.0, 191.0, 192.0, 193.0, 193.0, 194.0, 195.0, 195.0, 195.0, 196.0, 197.0, 197.0, 198.0, 198.0, 199.0, 199.0, 200.0, 200.0, 201.0, 201.0, 202.0, 202.0, 202.0, 202.0, 203.0, 203.0, 203.0, 204.0, 204.0, 206.0, 207.0, 207.0, 208.0, 208.0, 209.0, 210.0, 210.0, 211.0, 212.0, 213.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 220.0, 222.0, 222.0, 223.0, 224.0, 225.0, 226.0, 226.0, 227.0, 228.0, 229.0, 229.0, 230.0, 231.0, 233.0, 233.0, 234.0, 234.0, 236.0, 238.0, 238.0, 239.0, 240.0, 240.0, 241.0, 242.0, 242.0, 244.0, 245.0, 247.0, 248.0, 248.0, 250.0, 250.0, 252.0, 253.0, 255.0, 256.0, 258.0, 259.0, 262.0, 263.0, 264.0, 266.0, 267.0, 268.0, 268.0, 272.0, 274.0, 275.0, 277.0, 279.0, 281.0, 283.0, 286.0, 287.0, 290.0, 292.0, 301.0, 302.0, 306.0, 311.0, 314.0, 317.0, 322.0, 328.0, 333.0, 341.0, 357.0, 370.0, 391.0, 409.0, 443.0, 469.0, 471.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"injury_claim\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 4342.878304300159,\n",
      "      \"sum\" : 3.5650688E7,\n",
      "      \"std_dev\" : 9891.257231791275,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 158000.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 15800.0,\n",
      "            \"count\" : 7383.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 15800.0,\n",
      "            \"upper_bound\" : 31600.0,\n",
      "            \"count\" : 679.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 31600.0,\n",
      "            \"upper_bound\" : 47400.0,\n",
      "            \"count\" : 71.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 47400.0,\n",
      "            \"upper_bound\" : 63200.0,\n",
      "            \"count\" : 62.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 63200.0,\n",
      "            \"upper_bound\" : 79000.0,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 79000.0,\n",
      "            \"upper_bound\" : 94800.0,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 94800.0,\n",
      "            \"upper_bound\" : 110600.0,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 110600.0,\n",
      "            \"upper_bound\" : 126400.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 126400.0,\n",
      "            \"upper_bound\" : 142200.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 142200.0,\n",
      "            \"upper_bound\" : 158000.0,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 25466.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5193.0, 0.0, 13623.0, 0.0, 0.0, 0.0, 35026.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17173.0, 0.0, 0.0, 0.0, 813.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19153.0, 0.0, 0.0, 25111.0, 3045.0, 7189.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16935.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10181.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27967.0, 1956.0, 0.0, 0.0, 8258.0, 0.0, 12849.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23724.0, 0.0, 12164.0, 0.0, 0.0, 0.0, 25267.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30000.0, 0.0, 1246.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9020.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2372.0, 0.0, 6666.0, 0.0, 0.0, 0.0, 14358.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11111.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2601.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11938.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1463.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13900.0, 0.0, 0.0, 0.0, 1899.0, 0.0, 0.0, 0.0, 6093.0, 1805.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13852.0, 0.0, 14486.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29005.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 901.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9764.0, 0.0, 1406.0, 28528.0, 0.0, 0.0, 39219.0, 0.0, 0.0, 5621.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8737.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11008.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1232.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1017.0, 0.0, 6540.0, 0.0, 0.0, 0.0, 0.0, 1287.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 371.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4155.0, 0.0, 10126.0, 14753.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10321.0, 44397.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40993.0, 0.0, 13977.0, 0.0, 29816.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2592.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12731.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20472.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14908.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19963.0, 0.0, 0.0, 0.0, 37833.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9344.0, 0.0, 0.0, 0.0, 7493.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13669.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 722.0, 0.0, 13937.0, 0.0, 0.0, 0.0, 0.0, 1760.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1786.0, 12058.0, 0.0, 0.0, 6676.0, 0.0, 10584.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2608.0, 955.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8085.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17390.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1812.0, 0.0, 10250.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11833.0, 0.0, 0.0, 0.0, 0.0, 39630.0, 14499.0, 0.0, 0.0, 30974.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21776.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3547.0, 43928.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11570.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16706.0, 0.0, 0.0, 1218.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2039.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 158000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 86.0, 260.0, 312.0, 368.0, 445.0, 462.0, 475.0, 525.0, 548.0, 567.0, 579.0, 698.0, 807.0, 843.0, 975.0, 995.0, 1044.0, 1093.0, 1120.0, 1190.0, 1255.0, 1314.0, 1426.0, 1532.0, 1694.0, 1736.0, 1757.0, 1796.0, 1852.0, 1891.0, 1953.0, 1991.0, 2054.0, 2143.0, 2184.0, 2209.0, 2295.0, 2378.0, 2483.0, 2526.0, 2610.0, 2639.0, 2695.0, 2788.0, 2884.0, 2907.0, 2913.0, 2917.0, 2937.0, 2971.0, 2977.0, 3000.0, 3006.0, 3208.0, 3256.0, 3328.0, 3407.0, 3500.0, 3761.0, 3848.0, 3933.0, 4000.0, 4036.0, 4090.0, 4159.0, 4312.0, 4341.0, 4384.0, 4529.0, 4619.0, 4683.0, 4830.0, 4910.0, 4980.0, 4992.0, 5031.0, 5122.0, 5147.0, 5380.0, 5460.0, 5563.0, 5633.0, 5682.0, 5727.0, 5795.0, 5977.0, 6072.0, 6305.0, 6370.0, 6465.0, 6503.0, 6820.0, 6979.0, 7073.0, 7243.0, 7306.0, 7374.0, 7500.0, 7514.0, 7670.0, 7703.0, 7738.0, 7751.0, 7821.0, 7850.0, 7994.0, 8019.0, 8035.0, 8138.0, 8191.0, 8374.0, 8466.0, 8500.0, 8737.0, 8884.0, 9000.0, 9000.0, 9206.0, 9353.0, 9390.0, 9500.0, 9567.0, 9670.0, 9722.0, 9786.0, 9873.0, 9968.0, 10082.0, 10277.0, 10332.0, 10357.0, 10383.0, 10449.0, 10476.0, 10520.0, 10687.0, 10702.0, 10846.0, 10923.0, 10979.0, 11007.0, 11015.0, 11031.0, 11066.0, 11145.0, 11237.0, 11287.0, 11437.0, 11500.0, 11516.0, 11571.0, 11616.0, 11714.0, 11734.0, 11833.0, 11894.0, 11911.0, 11988.0, 12000.0, 12086.0, 12226.0, 12267.0, 12302.0, 12449.0, 12621.0, 12675.0, 12814.0, 12970.0, 13117.0, 13262.0, 13364.0, 13390.0, 13449.0, 13591.0, 13604.0, 13640.0, 13914.0, 14062.0, 14157.0, 14262.0, 14312.0, 14363.0, 14448.0, 14528.0, 14570.0, 14588.0, 14628.0, 14642.0, 14730.0, 14737.0, 14764.0, 14812.0, 14853.0, 14890.0, 14954.0, 14967.0, 14984.0, 14989.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15421.0, 15525.0, 15622.0, 15788.0, 15891.0, 16116.0, 16255.0, 16315.0, 16367.0, 16662.0, 17061.0, 17423.0, 17658.0, 18110.0, 18500.0, 18718.0, 18749.0, 18785.0, 19130.0, 19449.0, 19600.0, 19719.0, 19942.0, 20033.0, 20181.0, 20361.0, 20509.0, 21000.0, 21301.0, 21545.0, 21816.0, 22325.0, 22500.0, 22628.0, 22740.0, 23298.0, 23723.0, 23792.0, 24078.0, 24133.0, 24900.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25043.0, 25203.0, 25212.0, 25280.0, 25308.0, 25431.0, 25440.0, 25463.0, 25646.0, 25873.0, 25972.0, 26095.0, 26227.0, 26439.0, 26928.0, 27333.0, 27643.0, 28002.0, 28277.0, 28408.0, 28593.0, 28672.0, 28819.0, 29036.0, 29072.0, 29191.0, 29197.0, 29259.0, 29357.0, 29452.0, 29539.0, 29881.0, 29965.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30003.0, 30082.0, 30108.0, 30185.0, 30393.0, 30729.0, 31722.0, 33480.0, 33621.0, 33923.0, 34666.0, 35379.0, 37500.0, 38350.0, 40766.0, 41960.0, 42549.0, 46358.0, 48656.0, 49793.0, 50000.0, 50000.0, 50535.0, 50935.0, 52399.0, 73937.0, 94570.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\u001b[0m\n",
      "\u001b[34m.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 1000.0, 1000.0, 1500.0, 1500.0, 1500.0, 2000.0, 2000.0, 2000.0, 2000.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3500.0, 3500.0, 3500.0, 3500.0, 3500.0, 3500.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4105.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4921.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6004.0, 6457.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7079.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7804.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8653.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9962.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10992.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12500.0, 12500.0, 12500.0, 12500.0, 12760.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13500.0, 13500.0, 13500.0, 13500.0, 13784.0, 14000.0, 14000.0, 14000.0, 14000.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15497.0, 15500.0, 15500.0, 15805.0, 16000.0, 16000.0, 16000.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 17000.0, 17000.0, 17000.0, 17500.0, 17500.0, 17500.0, 17500.0, 18000.0, 18000.0, 18000.0, 18500.0, 18500.0, 18500.0, 19000.0, 19000.0, 19000.0, 19000.0, 19064.0, 19500.0, 20000.0, 20000.0, 20000.0, 20500.0, 20500.0, 20500.0, 20500.0, 21000.0, 21000.0, 21500.0, 22000.0, 22000.0, 22500.0, 22500.0, 23000.0, 23000.0, 23000.0, 23500.0, 24000.0, 24500.0, 24735.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25500.0, 25533.0, 26000.0, 26000.0, 27000.0, 27000.0, 27500.0, 28000.0, 28500.0, 29000.0, 29500.0, 29500.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30000.0, 30500.0, 31299.0, 32000.0, 35000.0, 35500.0, 36613.0, 38000.0, 39000.0, 41000.0, 43000.0, 44500.0, 46304.0, 48500.0, 49000.0, 50000.0, 50000.0, 50000.0, 50000.0, 50000.0, 51500.0, 54000.0, 60000.0, 60000.0, 60000.0, 71547.0, 100000.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"police_report_available\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.35716428673798284,\n",
      "      \"sum\" : 2931.961629832101,\n",
      "      \"std_dev\" : 0.4466942192815605,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 4682.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 146.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 156.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 149.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 155.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 155.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 126.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 146.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 154.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 2340.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.49645301848811385, 0.0, 0.7818256704067268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1337075640178187, 0.0, 0.5848750604652789, 0.0, 0.0, 0.021021106726217154, 0.18039044693420014, 0.0, 0.0, 0.0, 0.16276278177818193, 0.4570018673947307, 0.37380810886700244, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5980091173287496, 0.0, 0.8548057787992615, 0.04758469400335641, 0.8835647283701904, 0.27061999469359665, 0.0, 0.474434893620735, 0.007334150836180275, 0.0, 0.0, 0.0, 0.99458198903526, 0.7981581646362419, 0.2581039291604684, 0.0, 0.0, 0.0, 0.17766088854315254, 0.0, 0.0, 0.0, 0.6696085263343835, 0.0, 0.0, 0.4515655866055751, 0.0, 0.0, 0.20351561067041923, 0.0, 0.0, 0.8339251476664863, 0.0, 0.3092736848867369, 0.0, 0.046972991098139794, 0.0, 0.09114063944467754, 0.0, 0.0, 0.8301274055955237, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.02221848202558041, 0.0, 0.0, 0.0, 0.45013582163560184, 0.0, 0.0, 0.5095914808144868, 0.16950409186605864, 0.0, 0.6175291150623116, 0.20778342096169145, 0.587697018287546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.647457940745546, 0.15624495601270638, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2726506473124847, 0.26843788043886607, 0.0, 0.0, 0.0679732998194037, 0.0, 0.0, 0.0, 0.0, 0.4596445973857374, 0.0, 0.381389710906061, 0.0, 0.05917707186354182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4340521760809567, 0.0, 0.0, 0.0, 0.0, 0.2691203766777923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34409668690160045, 0.0, 0.0, 0.22460244007488483, 0.0, 0.17250125836432662, 0.0, 0.5269724966569793, 0.0, 0.0, 0.0, 0.25526327217079003, 0.4124030604678661, 0.8042443935943754, 0.4868249177179641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.305982585894258, 0.1827511659874359, 0.0, 0.584485936937934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4261494020249733, 0.06090193309949332, 0.030930881393566034, 0.7144141014704978, 0.0, 0.0, 0.0, 0.0, 0.7244634328591488, 0.5054788748795921, 0.0, 0.0, 0.31607768384326407, 0.0, 0.0, 0.0, 0.7042524374049793, 0.2557437015483004, 0.0, 0.0, 0.0, 0.2093088980998321, 0.38473257650744497, 0.0, 0.0, 0.5896534951515476, 0.9326231284780743, 0.8315407863376656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6396245076368293, 0.39516057063741883, 0.3874512959225387, 0.0, 0.30880227534961535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8859139954974249, 0.8160790423433513, 0.0, 0.26408204644801125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9753820161587614, 0.0, 0.0, 0.0, 1.0, 0.040288945734542114, 1.0, 0.31952053747562603, 0.9316979736811688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8481138276633697, 0.0, 0.9455339526331624, 0.0, 0.0, 0.42818393986717285, 0.6320192084224364, 0.0, 0.3669614070072005, 0.852772925589483, 0.0, 0.6867335234193896, 0.6360684203522257, 1.0, 0.0, 0.0, 0.0, 0.18792238899132097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.785083657239757, 0.0, 0.0, 0.09750769246387525, 0.0, 0.0, 0.0, 0.0, 0.23127992831595545, 1.0, 0.3060471662287715, 0.0, 0.0, 0.005139627585560302, 0.0, 0.0, 0.682652605044199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013436885885589556, 0.597839986845685, 1.0, 0.0, 0.0, 0.0, 0.6928543518957885, 0.8596795850803329, 0.04052781704458808, 0.0, 0.9118478418633555, 0.19453503316848408, 0.0, 0.0, 0.0, 0.0, 0.5778279715114357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5312101194932091, 0.7056353963689815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30630099688753754, 0.0, 0.0, 0.6502039381924081, 0.0, 0.23307281189083495, 0.0, 0.0, 0.8634846083691153, 0.13228794765103824, 0.0, 0.0, 0.004525847653185644, 0.0, 0.7784827278868942, 0.0, 0.0, 0.4724363510005801, 0.82840363293481, 0.0, 1.0, 0.0, 0.8781119174677295, 0.0, 0.9368700907920335, 0.6032449435444707, 0.0, 0.4512666140731144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14675753080288245, 0.0, 0.13736174596867423, 0.7231300305079877, 0.0, 0.0, 0.33920147030908965, 0.7463628843132415, 0.0, 0.0, 0.0, 0.9983562428875503, 0.0, 1.0, 0.5212951420344775, 0.0, 0.0, 0.44617655936627443, 0.4870206501790926, 0.0, 0.0, 0.24715134411779371, 0.0, 1.0, 0.0, 0.7681587082852736, 0.0, 0.30770281338984384, 0.24217465034747054, 0.0, 0.7440285803476767, 0.0, 0.0, 0.25062098327584403, 0.08215911690644695, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9188357755362855, 0.0, 0.0, 0.31348605695674747, 0.0, 0.0, 0.7731835012587582, 0.328412257061074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7205546926810974, 1.0, 0.8865025266419025, 0.39864249421306397, 0.0, 0.2670750074563324, 1.0, 0.858761429838704, 0.0, 0.0, 0.0, 0.0, 0.9041353525781907, 0.0, 0.008110804052508302, 0.9513968619791061, 0.0, 0.0, 0.8150797025328557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2911008872266839, 0.0, 0.0, 0.0, 0.0, 0.9158075833506722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8646523546027457, 0.0, 0.17187651213592425, 0.4765264708322373, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8364209229856395, 0.0, 0.014381235984152974, 0.19701869869089617, 1.0, 0.0, 0.0, 0.0, 0.04748321031540137, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.829821264717285, 0.345274651501557, 0.0, 0.0, 0.0, 0.0, 0.20687146203694362, 0.0, 0.0, 0.04918134008356856, 0.0, 0.7390814203498319, 0.03038406109566205, 0.7347085702650257, 0.0, 0.1470736161454187, 0.0, 0.29404376341999283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4502824838315258, 0.4688905036624724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6714060726437369, 0.926308276921196, 0.3808319557569416, 0.0, 0.6888105035899871, 0.5519363610604665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06704337447177267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.37822451524334477, 0.0, 0.4131073977271442, 0.8006545105288169, 0.41236648727468106, 0.9277230524268234, 0.0, 0.14634545105888808, 0.7252870843545552, 0.36039404005411124, 0.9129287944226918, 0.7978506007747292, 0.0, 0.0, 0.0, 0.0, 0.8489238694760728, 0.0, 0.0, 0.1876738197529384, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4006270071280137, 0.0, 0.0, 0.8850936566380897, 0.9961628544921991, 0.0, 0.4168721765471307, 0.0, 0.9454880725621737, 0.0, 0.0, 0.7834208143727591, 0.0, 0.912890710538566, 0.48738444167204287, 0.0, 0.0, 0.37575926300248186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20369933658486783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4459555450921018, 0.9799767702678124, 0.9374930584895892, 0.0, 0.5834215190184351, 0.0, 0.38079568270784514, 0.0, 0.0, 0.0, 0.8871568128163786, 0.40356604537434004, 0.0, 0.0, 0.38048188549303585, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.037897895834972495, 0.0, 0.0, 0.0, 0.6667315298575898, 0.0, 0.5712357088853165, 0.9462180358226221, 0.0, 0.35796119453276465, 0.0, 0.0, 0.0, 0.0, 0.856964414776239, 0.938714635374035, 0.0, 0.0, 0.0, 0.0, 0.3094127948704444, 0.0, 0.4843234489229269, 0.0, 0.0, 0.0, 1.0, 0.38586682381248194, 0.0, 0.0, 0.0, 0.0, 0.20699360124505817, 0.0, 0.9157356338441489, 0.3560930851664217, 0.0, 0.0, 0.8276751947812718, 0.0, 0.0, 0.0, 0.0, 0.2864737377445836, 0.0, 0.0, 0.0, 1.0, 0.0, 0.26125649038406973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8216415697789553, 0.0, 0.0, 0.18842799564845192, 0.0, 0.0, 0.0, 0.0, 0.7117779449909495, 0.0, 1.0, 0.0, 0.12141490550497214, 0.0, 0.8162153348920989, 0.32838549961660535, 1.0, 0.0247648775761512, 0.0, 0.0, 0.27963631849320625, 0.0, 0.7280122577961974, 0.0, 0.0, 0.7744194946063033, 0.0, 0.4933142091459972, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.337517843693185E-4, 0.002584014844982385, 0.005315834803512831, 0.00566581452956727, 0.009453967229866578, 0.009913623932517934, 0.010568234220368455, 0.011584010587923466, 0.01803080955385472, 0.01956442972962824, 0.020353284966116547, 0.022026921223816998, 0.02293281126804203, 0.025627761320742404, 0.027420309972657653, 0.029155186022088997, 0.030392273151904625, 0.030937644731341973, 0.0337565892932018, 0.03593018218597299, 0.03798156328985347, 0.042291749222681196, 0.04305240271566857, 0.04477845050466822, 0.045319278960894605, 0.049496853493666615, 0.05280396046852809, 0.053243964826296786, 0.056017694636790405, 0.056136103416210004, 0.057016183183957514, 0.057741051869173776, 0.05947156886728078, 0.060942904032812883, 0.06254222689736844, 0.06449127124916754, 0.06581176069057648, 0.06669388140544885, 0.07074260199277072, 0.07424087298838644, 0.07761464473144086, 0.07970281878059227, 0.08126528939362265, 0.08273403962367076, 0.08642461076254648, 0.08710755526342462, 0.08883171481992092, 0.0920987541995898, 0.09319611956269469, 0.09447520767032613, 0.09608666973962532, 0.0986243504115557, 0.09986682113617817, 0.10274825245242336, 0.10418540262811804, 0.10573488174358603, 0.10640541354986843, 0.11034796698243365, 0.11288068277630159, 0.11310981907657303, 0.11443151861235856, 0.11786438571793989, 0.1223529803492186, 0.12286155848859603, 0.12573752938976224, 0.1279882085335864, 0.12936611851650948, 0.13144849367971123, 0.1318307046734959, 0.13380373627948872, 0.13659923314299816, 0.1378228991592354, 0.1411075940213511, 0.14225523977681542, 0.1431260639249059, 0.14706185056658838, 0.1474422180984465, 0.15158429286987996, 0.15607538738827598, 0.1577692536560521, 0.15802962850329128, 0.16003601971781745, 0.1605390904992331, 0.1617642113521096, 0.1645921691578741, 0.16488477656513845, 0.1652420504426032, 0.16540904740472795, 0.16603431341619546, 0.1662080490811727, 0.16716809813092426, 0.1690810703559925, 0.17143417671054273, 0.1733479425393596, 0.1748693323338848, 0.1768871451438544, 0.17760658118294192, 0.1783520670382288, 0.17998737088064398, 0.18059459817530088, 0.18214369434497046, 0.18522844654740966, 0.1896948481746772, 0.19013981263941382, 0.19197737009344706, 0.19260396966004867, 0.19395386726777486, 0.19447408642394304, 0.19688787177568357, 0.19964512097659337, 0.20028208638128042, 0.20551436635150933, 0.2065927418521627, 0.20730900318755796, 0.20827974073865352, 0.20886407070573998, 0.21059057808641435, 0.21119773609464043, 0.21323049664287264, 0.2139570386882369, 0.2160513650116872, 0.2160904531853075, 0.21798466506703273, 0.21981073151700503, 0.22522370226848976, 0.22609377822933485, 0.2281422738183787, 0.23025092071051467, 0.23148009591298824, 0.2325513583653801, 0.23480913544421533, 0.2370847085173401, 0.2380931798675846, 0.24132360988899515, 0.24173270794394086, 0.24373534210854741, 0.24589231968383596, 0.2461702994307814, 0.24757223738442746, 0.24832382797708075, 0.2507162873042236, 0.25180809402100246, 0.254139961372988, 0.2543219811783167, 0.2584316202918181, 0.25938840074319625, 0.2605917701686882, 0.2628197749927569, 0.2644943935124624, 0.26638416995768754, 0.2669488101400066, 0.2691819712881912, 0.27156876475103986, 0.2756825303233388, 0.2782784472828207, 0.27843940825043456, 0.2799919603368869, 0.2803461833894696, 0.2809225526461444, 0.28226247041293284, 0.28330476242493063, 0.28783129885160585, 0.28988994357829334, 0.29316214421945885, 0.29384149788094593, 0.2954679246267593, 0.2967866820198506, 0.2973615313084723, 0.2987828710542516, 0.30048938560043237, 0.304375347645942, 0.3083819444306807, 0.3100002626910566, 0.3119840203264185, 0.3130501450631469, 0.3148258293516488, 0.31692247734494494, 0.3182513559098388, 0.31902517276175546, 0.32162117714485816, 0.3227265727266384, 0.324158754912624, 0.3256961935909516, 0.3275521651801324, 0.32854506510535675, 0.33024277933640533, 0.3322055709473216, 0.3335695494722004, 0.33581208549458264, 0.33684050186110326, 0.3369926538582241, 0.3373401410170235, 0.3397774715618851, 0.3408156997898466, 0.34109002447422054, 0.3423836360335465, 0.3447175903083418, 0.3453069185686518, 0.3470503418621578, 0.3485736672419705, 0.3547101624742831, 0.35574327634918845, 0.36167776020817344, 0.36275360039915205, 0.36588580955688044, 0.3683564849171084, 0.3707011939892638, 0.3717618895367186, 0.3773136614063236, 0.3789102780588144, 0.3835002731049165, 0.38423962013738133, 0.38512011990250006, 0.3863489098483155, 0.38865279862984703, 0.3923937215284745, 0.39344784656359155, 0.39451874947405463, 0.3961490174597221, 0.39788301464522047, 0.40087941495967483, 0.40146842431563434, 0.40233495523733276, 0.40276439846225187, 0.4042397296442092, 0.4045686564040174, 0.4065567838081042, 0.4076986289379043, 0.4095689101773067, 0.41085709184049646, 0.411864740417496, 0.4142009255718303, 0.4178561924222015, 0.41858228553148913, 0.4214440415792474, 0.4229593355380892, 0.4245274251963619, 0.4273571468844154, 0.4334246378285814, 0.4345800323922576, 0.436419598729593, 0.4372883009776608, 0.43817234641198766, 0.44059457427264304, 0.4421798080707986, 0.4433065095171753, 0.\u001b[0m\n",
      "\u001b[34m44566252565965514, 0.44723763196641686, 0.4503839562810755, 0.45058576156954666, 0.45150027834852324, 0.45221530561668055, 0.45394684810835706, 0.45441787820793356, 0.4559792757599369, 0.45859794351384, 0.4604437795044949, 0.46118699096038096, 0.46311471383751146, 0.4640666894045047, 0.46660778469721587, 0.46773978666095983, 0.4686834794319409, 0.47086735622317677, 0.4743361099062139, 0.47495096526374825, 0.4754066078500737, 0.47669547504115917, 0.4784961162559619, 0.4816348465348623, 0.4857989599906608, 0.4876996531129194, 0.48937644897067023, 0.49193110010572905, 0.4925990052218141, 0.4972559303146882, 0.5006970539856748, 0.5038336158867806, 0.5045478965390182, 0.5077676848175917, 0.508068899894271, 0.51096422469238, 0.5116813865815117, 0.5172393817143319, 0.5190939992469303, 0.5212341324853343, 0.5221215519777576, 0.5235864852214529, 0.5240322689883441, 0.5259935715168441, 0.5272261808398002, 0.5285781097221971, 0.5315994646044309, 0.5322575311489761, 0.5349447516993556, 0.5368272832486582, 0.5406685591994572, 0.5410365206227014, 0.5417653496071662, 0.5448276575451868, 0.5456868884954734, 0.5468596409751262, 0.5470889297323892, 0.5489804494416418, 0.5498755675802404, 0.5501577920274408, 0.551186354253394, 0.552397059679783, 0.554356681216369, 0.5546877097800863, 0.5558722868342484, 0.5579807387826399, 0.5589278417492163, 0.561255678074924, 0.5649843576752536, 0.5661994877452282, 0.5689131373767106, 0.5696252503092067, 0.5704040564239353, 0.5730414289308493, 0.573929022373903, 0.5757031141151119, 0.5792663538205268, 0.5809320532627977, 0.5821832300925898, 0.5832574924561156, 0.5835569673248185, 0.5850287845999218, 0.5886605335008561, 0.594248831384939, 0.5970469168956917, 0.5975533625663311, 0.5985543690868064, 0.5991205850403252, 0.6021169853547795, 0.6026186095146835, 0.6037969919290961, 0.6042920364262074, 0.6098318054986945, 0.6107707306850386, 0.6133798273661658, 0.6177477480225416, 0.6189915646985882, 0.620773462819551, 0.6225196957297452, 0.6234697122107017, 0.6264451989523181, 0.6264903169616124, 0.6267588436207662, 0.6305180659686197, 0.6344042989960332, 0.6358872249895006, 0.637055728154008, 0.6377319129014088, 0.6379607933159701, 0.6390321589149208, 0.6406355928025865, 0.6466059134228601, 0.6481050345341234, 0.6511099249581764, 0.6520930618816506, 0.6539940923398012, 0.6561340180205807, 0.6575603127780231, 0.6581527145019079, 0.6617368946676516, 0.6626971635325136, 0.6630352742825435, 0.6651461942384054, 0.6668544210142678, 0.6706755253823256, 0.6732464393545315, 0.6761050258143518, 0.6769888016137862, 0.6783918855030131, 0.682468552123263, 0.6852980161158734, 0.686793738929826, 0.68713683914487, 0.6881009199957195, 0.6910440099318473, 0.6938626591204068, 0.69698249301797, 0.6980832999224982, 0.7000342727721044, 0.7040832713213391, 0.7101147663372793, 0.7144912198814884, 0.7150919784690392, 0.7171205684721935, 0.7196655392084791, 0.7197914533546861, 0.7215605917495654, 0.7231282738825542, 0.7242545274991332, 0.7268388310482375, 0.7284529525887576, 0.7286340364609895, 0.7313165197032963, 0.7333248033380224, 0.7339053770018694, 0.7345779231214132, 0.7380691233385172, 0.7409812502745785, 0.7439524348950457, 0.7463644444859617, 0.7471863939107994, 0.7481608263876856, 0.7537139811894684, 0.7565220315951328, 0.7574818847894174, 0.7608574545654768, 0.7618836118624439, 0.7647644151980152, 0.7684515640349512, 0.7692053460734682, 0.772516286079404, 0.7733093479250763, 0.7736625648956658, 0.7760174541349188, 0.7789366285462715, 0.7795115653108936, 0.7807260380761243, 0.782581939851338, 0.7835000808452567, 0.7839873586893554, 0.7852688115160151, 0.7866066520243105, 0.7877130155277087, 0.7894321941951912, 0.7902470523163186, 0.7925213919629192, 0.7955103716964032, 0.7955594260504532, 0.7965635248639088, 0.7989348479500549, 0.800588402241465, 0.804390726955485, 0.8049637303992545, 0.8059789008675837, 0.8067505847658318, 0.8121571474622259, 0.8157486435042809, 0.8167569301195281, 0.8169845557652728, 0.8221118759509766, 0.8237780901011652, 0.8281515186729055, 0.8288712762529586, 0.8295875568652503, 0.8305344564048399, 0.8311457933223139, 0.831863113251422, 0.8332043565966744, 0.8347058890298255, 0.8361189762195178, 0.8409749962597387, 0.8437162904502238, 0.8456784347169206, 0.8472716677218594, 0.8484306284123264, 0.8494785083365864, 0.8510002638507566, 0.8527280198757112, 0.8530896234036505, 0.8582256064728981, 0.8613196258150908, 0.8628805029124124, 0.8634657303414633, 0.8668549958219031, 0.8669334683518837, 0.8708255547568896, 0.8725143198597538, 0.8731088427642276, 0.8752859430886095, 0.8772617628261795, 0.877964947875605, 0.8782380888747252, 0.879341020176528, 0.8815849608240681, 0.8822585560948476, 0.883809043474554, 0.8849643081805878, 0.8870567915888264, 0.8888874240036297, 0.8899367157988848, 0.8950652888512458, 0.8958626420797126, 0.8971863409646189, 0.9012627931173341, 0.9036078443467951, 0.9055388379289011, 0.9060658856863653, 0.9069428088348339, 0.9070708556206101, 0.907380164712847, 0.9112326058922315, 0.9156986853886496, 0.9177929362882183, 0.9231925589307187, 0.9242870707946612, 0.9253701856629183, 0.9278889070705648, 0.9286602870148829, 0.9312871674817322, 0.9351720867264933, 0.9362671394132192, 0.9368909669208498, 0.938894960041275, 0.9393710739335318, 0.9404485057361726, 0.9422589481308262, 0.9446657321710952, 0.9481083201714422, 0.9491121430894405, 0.9499814231788878, 0.9527975276012943, 0.9558244837207522, 0.9562221906489483, 0.9576577212276162, 0.9580359265563657, 0.9623102029877842, 0.9665475165520824, 0.9691420956919276, 0.96945054290662, 0.9707421536772481, 0.9724808148595847, 0.9747626541517358, 0.9755015517323476, 0.977031676545176, 0.9774521179903679, 0.9793286311080955, 0.9795508403817569, 0.9820495370159625, 0.9838403128554378, 0.9851745550906748, 0.9863659760941785, 0.9889683857375342, 0.9903131172590323, 0.9933178707761122, 0.9939112517601609, 0.9942814186392107, 0.9946538391456355, 0.9968321514192983, 0.9995572185627921, 0.9998116004434181, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001120111480109487, 0.009851627249352957, 0.036763346559868126, 0.05141664514856625, 0.09526150795462629, 0.1037786973149617, 0.13271465381927738, 0.16400193621879056, 0.20320217213597247, 0.24294073238877667, 0.2970028764548822, 0.32643357650329297, 0.33836764962885324, 0.3674594667736939, 0.3981446163379915, 0.41988777030453195, 0.4575213642806325, 0.4766768283303684, 0.4951551181069822, 0.5217300466362131, 0.5354014033641898, 0.5463063653947173, 0.5667532510283444, 0.5946898169142566, 0.5977235652558643, 0.6061887135611715, 0.6257032328602073, 0.6621120101065646, 0.7149240402022476, 0.7353502986657526, 0.7536988340505192, 0.7653259617384489, 0.7836759769634465, 0.8258066634217464, 0.8463419618388873, 0.8528218216919013, 0.8686648735906219, 0.8816371327703502, 0.9184735104475733, 0.9412375042323865, 0.9607805514869769, 0.9706055542434927, 0.994917860181974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_other\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.032964520632328444,\n",
      "      \"sum\" : 270.60574987078417,\n",
      "      \"std_dev\" : 0.1671553705106137,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7864.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 29.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 25.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 190.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6277454148973364, 0.0, 0.0, 0.0, 0.0, 0.03838419295383433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9833241865101608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3305610023062908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31730547742048654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6434286740491809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162750621546516, 0.0, 0.37394713447906747, 0.0, 0.0, 0.0, 0.0, 0.05446604736683758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9744302009102653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.822872855801746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19675509533519375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5487333859268856, 0.0, 0.0, 0.0, 0.0, 0.8176233783044862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4624153743074342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5704094914036416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6716145003833947, 0.0, 0.0, 0.0, 0.5921103914927199, 0.7203636815067938, 0.0, 0.0, 0.18685234483201507, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.861958440859569E-4, 0.008227119020750573, 0.01419004939576718, 0.023274761337421124, 0.04485356802356866, 0.05947156886728078, 0.06738455478552252, 0.06982903456157541, 0.07462981433708171, 0.07647995549931308, 0.08932342056486042, 0.10392488820542667, 0.11395663471431716, 0.12210884095867247, 0.12273823717382049, 0.15928744524280514, 0.1762219098988348, 0.1896948481746772, 0.2029363675749022, 0.20375940443714569, 0.2176116705399127, 0.22370952248405218, 0.2533571700596614, 0.2778451632065655, 0.292516425476252, 0.3083819444306807, 0.3171957167653986, 0.3289447161400856, 0.3504132500101974, 0.35390987653749195, 0.36290916291909503, 0.3653607435126195, 0.38512011990250006, 0.3910427630581744, 0.4081190568259231, 0.4474863852172748, 0.4720604341969983, 0.4742884204312605, 0.4767869450291251, 0.4868169162432212, 0.5221215519777576, 0.5318890790075141, 0.5665753621714186, 0.5771727832875501, 0.5905221469947961, 0.5988082963834914, 0.6058639532173719, 0.613777418815699, 0.6602311728488821, 0.6817486440901612, 0.7047217107796899, 0.7234047656122863, 0.74176898033384, 0.754107680316164, 0.7658155531845143, 0.7732588155930554, 0.7844701312086682, 0.7880175090977615, 0.8041591874130811, 0.8137662883195864, 0.8223934188170581, 0.8309189296440075, 0.8420744373985792, 0.8589566854206295, 0.8728002373125504, 0.8755112265526162, 0.8880390643601178, 0.8944525568242322, 0.8978504703424619, 0.9063275792940898, 0.9177929362882183, 0.923431741566461, 0.9427197489223766, 0.9554050916270385, 0.9619781517625451, 0.9841789082344176, 0.9998134718293369, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\u001b[0m\n",
      "\u001b[34m, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003346362042979223, 0.3323146253551089, 0.39446184235511716, 0.4774808083654769, 0.5530014525919584, 0.7328989183413418, 0.7744598575562646, 0.9118360349599111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_insurers_past_5_years\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.606894871482519,\n",
      "      \"sum\" : 13191.0,\n",
      "      \"std_dev\" : 0.995693599321264,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 5.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.4,\n",
      "            \"count\" : 5452.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.4,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.2,\n",
      "            \"count\" : 1282.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.2,\n",
      "            \"upper_bound\" : 2.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.6,\n",
      "            \"upper_bound\" : 3.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.0,\n",
      "            \"upper_bound\" : 3.4,\n",
      "            \"count\" : 839.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.4,\n",
      "            \"upper_bound\" : 3.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.8,\n",
      "            \"upper_bound\" : 4.2,\n",
      "            \"count\" : 519.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.2,\n",
      "            \"upper_bound\" : 4.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.6,\n",
      "            \"upper_bound\" : 5.0,\n",
      "            \"count\" : 117.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 1.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 4.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 4.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 1.0, 3.0, 1.0, 4.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 1.0, 2.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 3.0, 1.0, 4.0, 1.0, 1.0, 4.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 4.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 4.0, 1.0, 2.0, 4.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 4.0, 4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 4.0, 1.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 4.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 4.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 1.0, 3.0, 5.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0 ], [ 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0 ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3\u001b[0m\n",
      "\u001b[34m.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_gender_female\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.3920982400082388,\n",
      "      \"sum\" : 3218.734452227632,\n",
      "      \"std_dev\" : 0.472601209428071,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 4691.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 66.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 80.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 83.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 86.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 66.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 76.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 69.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 58.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 2934.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24739974705834578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021021106726217154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5429981326052693, 0.37380810886700244, 0.0, 0.0, 0.8570391223992478, 0.0, 0.0, 0.0, 0.0, 0.8548057787992615, 0.0, 0.8835647283701904, 0.0, 0.0, 0.474434893620735, 0.0, 0.9741906071368183, 0.0, 0.0, 0.99458198903526, 0.2018418353637581, 0.0, 0.0, 1.0, 0.22218875554154927, 0.0, 0.09723621203549127, 0.0, 0.0, 0.6696085263343835, 0.0, 0.0, 0.4515655866055751, 0.0, 0.9840315142791302, 0.20351561067041923, 0.2432419097530717, 0.6805581617791014, 0.0, 0.0, 0.0, 0.0, 0.9530270089018602, 0.9280517502288481, 0.0, 0.0, 0.0, 0.8301274055955237, 0.0, 0.0, 0.0, 0.5863213210147397, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5498641783643982, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.41230298171245405, 0.0, 0.0, 0.0, 0.5629484781578123, 0.3722545851026636, 0.0, 0.0, 0.0, 0.0, 0.9616158070461657, 0.730243334357868, 0.0, 0.0, 0.0, 0.38772423430612757, 0.0, 0.0, 0.0, 0.7273493526875153, 0.26843788043886607, 0.0, 0.0, 1.0, 0.0, 0.0, 0.10986194655308601, 0.0, 0.0, 0.0, 1.0, 0.0, 0.9408229281364582, 0.6328026106615069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12757017457137088, 0.0, 0.6456228170138647, 0.0, 0.0, 0.0, 0.5890200909809116, 0.0, 0.6501456158191455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17250125836432662, 0.2545405429216612, 0.0, 0.0, 0.3006605337473569, 0.0, 0.25526327217079003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08804041580036681, 0.06092872172071995, 0.0, 0.0, 0.6809549256677602, 0.0, 0.0, 0.0, 0.0, 0.6813103960094764, 0.0, 0.0, 0.4261494020249733, 0.0, 0.969069118606434, 0.0, 0.0, 0.12537534923387328, 0.25361277085970824, 0.0, 0.0, 0.0, 0.12169530672667228, 0.0, 0.0, 0.0, 0.8083948823040229, 0.0, 0.0, 0.7442562984516996, 0.0, 0.0, 0.0, 0.0, 0.38473257650744497, 0.5640048194294142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7148995340913137, 0.0, 0.01460899710888286, 0.0, 0.39516057063741883, 0.6125487040774613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.18392095765664873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6802568045923051, 0.0, 0.8623702656016387, 0.9990705831300389, 0.09677637265529271, 0.02461798384123859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4877852923229484, 0.0, 0.9316979736811688, 0.0, 0.0, 0.0837249378453484, 0.6140604890630726, 0.0, 0.0, 0.0, 0.8481138276633697, 0.0, 0.0, 0.0, 0.9652096385457352, 0.42818393986717285, 0.0, 0.0, 0.0, 0.0, 0.7934189837782192, 0.0, 1.0, 0.6017194509109456, 0.006814697900128119, 0.47659281493252814, 0.0, 0.18792238899132097, 0.0, 0.0, 0.0, 1.0, 0.143161357811193, 1.0, 0.0, 0.02556979908973467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.454076466691, 0.0, 0.0, 0.0, 0.273698457678371, 0.9118186286860916, 0.09750769246387525, 0.0, 0.6718399276463922, 0.053772311661983374, 0.0, 0.23127992831595545, 0.0, 0.0, 0.9363152324974833, 0.0, 0.9948603724144397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3750202516239648, 0.0, 0.3071456481042115, 0.0, 0.9594721829554119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5982068648905755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.14199425935208465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23307281189083495, 0.6951874662100657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4625935471051531, 0.03326797116935842, 0.0, 0.5841386605920524, 0.06312990920796646, 0.39675505645552933, 0.0, 0.0, 0.1308251425969127, 0.46993754494826756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33920147030908965, 0.0, 0.688428260417771, 0.0, 0.0, 0.0, 0.37641496252069395, 0.4292385190409266, 0.5212951420344775, 0.0, 0.8945947140438331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12380752173044396, 0.0, 0.0, 0.2944372883503089, 0.6922971866101562, 0.0, 0.9269964071003727, 0.0, 0.0, 0.0, 0.749379016724156, 0.917840883093553, 0.0, 0.0, 0.0, 0.27450667350707825, 0.0, 0.0, 0.0, 0.0, 0.31348605695674747, 0.0, 0.0, 0.0, 0.671587742938926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7825001443802936, 0.0, 0.601357505786936, 0.13707760648901102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9817249302764938, 0.09586464742180933, 0.0, 0.0, 0.0, 0.13702091003632066, 0.5375846256925658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2625900556880538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15568513584761756, 0.0, 0.7179326909401018, 0.7163920765828637, 0.0, 0.9792419678760358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1390022051990777, 0.0, 0.0, 0.0, 0.0, 0.8364209229856395, 0.5024656497627655, 0.0, 0.0, 0.0, 0.0, 0.49629161291592927, 0.0, 0.9525167896845986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.969615938904338, 0.7347085702650257, 0.0, 0.0, 0.0, 0.0, 0.5036886093282389, 0.0, 0.0, 0.0, 0.0, 0.4781589235558441, 0.0, 0.6285664006472832, 0.0, 0.5497175161684742, 0.0, 0.0, 0.17405908088808175, 0.6965614021440462, 0.07592701115431688, 0.0, 0.0, 0.6714060726437369, 0.926308276921196, 0.6191680442430584, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28733438101345554, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8006545105288169, 0.41236648727468106, 0.0722769475731766, 0.0, 0.8536545489411119, 0.0, 0.36039404005411124, 0.0, 0.7978506007747292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4437713390922451, 0.7176320809573438, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12737411451410363, 0.0, 0.48738444167204287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9172205918248628, 0.0, 0.7007679956989394, 0.0, 0.31219188378638796, 0.0, 0.7963006634151322, 0.16706260768133896, 0.0, 0.7912842924966835, 0.0, 0.6607797016082162, 0.0, 0.0, 0.25517492447008694, 0.4459555450921018, 0.02002322973218762, 0.0, 0.0, 0.5834215190184351, 0.0, 0.0, 0.0, 0.6617038454813468, 0.0, 0.0, 0.0, 0.5153104830636925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6131519111030179, 0.1943977812297617, 0.0, 0.0, 0.0, 0.0, 0.31932762677426296, 0.33326847014241023, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.856964414776239, 0.0, 0.0, 0.0, 0.0, 0.5817088889065141, 0.0, 0.0, 0.4843234489229269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4445027198303686, 0.41608071073886466, 0.20699360124505817, 0.0, 0.0, 0.0, 0.0, 0.7258796361807993, 0.0, 0.0, 0.0, 0.0, 0.8594528720044571, 0.2864737377445836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7918913237957292, 0.0, 1.0, 0.0, 0.8254101487528136, 0.0, 0.7117779449909495, 0.0, 0.41731385344541716, 0.0, 0.0, 0.7211323573568237, 0.18378466510790115, 0.0, 0.0, 0.0, 0.7511809729800681, 0.0, 0.0, 0.0, 0.2719877422038026, 0.8131476551679849, 0.0, 0.7744194946063033, 0.38555356440131383, 0.4933142091459972, 0.8560010748931528 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020185177482339167, 0.0028812516656145926, 0.0036017063209445865, 0.005584732441126561, 0.00608874823983907, 0.007557710625221037, 0.010493641139944443, 0.011164468610835532, 0.014628258877675715, 0.017149781915198115, 0.02462672285357914, 0.027519185140415292, 0.030392273151904625, 0.03079004966044785, 0.03773855339084331, 0.04196407344363429, 0.042837555119113246, 0.0507993068191086, 0.051255604850289016, 0.053243964826296786, 0.055525032809150554, 0.059226700310499036, 0.059816808747917394, 0.06482791327350668, 0.0683341048456042, 0.07566110390411085, 0.08503413492203138, 0.08978696513224338, 0.09209525323290235, 0.09226456682248729, 0.09729448955464381, 0.09861690335806506, 0.10312136240807579, 0.10810689674343743, 0.11111257599637026, 0.11153589007707931, 0.11887439117707199, 0.12323257571632484, 0.12556557863725137, 0.12736419745316474, 0.1299299245357013, 0.13480665260218894, 0.1384354933293943, 0.14225523977681542, 0.14577809365913197, 0.150608103218274, 0.15415044954003232, 0.16493405454498, 0.16530228613796127, 0.16758281658974727, 0.17011541730928148, 0.1733479425393596, 0.1817232932281565, 0.1832430698804719, 0.19111870949600263, 0.20947948972832653, 0.2136422669385185, 0.21550075886755105, 0.2162505281865289, 0.21980534882319003, 0.2264611084654361, 0.22674118440694457, 0.22748371392059596, 0.23178359028935003, 0.23389693147220347, 0.23528085852372083, 0.23714446597771122, 0.24751007314041196, 0.24854705554065637, 0.24997158785780882, 0.25264603062128665, 0.25382107815669486, 0.25943527674049005, 0.2659702374106937, 0.26699638037164664, 0.2695075225177006, 0.27154704741124236, 0.2742740896358967, 0.2757454725008668, 0.27934485471688675, 0.28481354521975877, 0.28722232378316903, 0.2898645682019342, 0.29426673663711433, 0.2986167144403099, 0.3003100909412916, 0.306051463522788, 0.3131632018297771, 0.31810444690347206, 0.3182620413857259, 0.32245905449646595, 0.32485993885033193, 0.3257411579935009, 0.32629826645784354, 0.33199829423776517, 0.3331333394490783, 0.3348538057615946, 0.3373028364674864, 0.34191741525080965, 0.34460408444755963, 0.3452909246437009, 0.34809913443753937, 0.3518949654658766, 0.364354238428232, 0.3665882597578729, 0.3674558900341721, 0.3732598144627589, 0.3765221694807036, 0.3772677177071667, 0.3779604376290062, 0.379127658375647, 0.38076096794641834, 0.38480361722110323, 0.3918239632835, 0.39413604678262815, 0.3959615887476049, 0.396708194285057, 0.3969604449467167, 0.4009417624730467, 0.40244663743366893, 0.4072290591298152, 0.414735826967471, 0.41779124023176883, 0.4211598319644074, 0.4295959435760647, 0.43098390192082203, 0.4315351014920601, 0.4331631113151664, 0.43667535796695334, 0.4417464916377071, 0.4436719927429207, 0.44452825305015964, 0.44620122097754367, 0.4529110702676108, 0.45394684810835706, 0.4552277730172112, 0.4559792757599369, 0.4574430558698882, 0.46144551188731264, 0.463990131464425, 0.46672809376795044, 0.4701187389114738, 0.4764612712393995, 0.4784006039886418, 0.4800473773100856, 0.48172382355235366, 0.48581742891263147, 0.48985161954367673, 0.4929175759397333, 0.49599623640367396, 0.5010288830862341, 0.5042962497681089, 0.5063303093542678, 0.5116357178950771, 0.5207399100854625, 0.5231430206971652, 0.5257562195591349, 0.5343174582377205, 0.5381565187248897, 0.5413696101572687, 0.5455821217920664, 0.5469632513713881, 0.549309771480104, 0.568887594902995, 0.5719122038506007, 0.5754093872861483, 0.5791752553747221, 0.5821438075777985, 0.5846680901658248, 0.5850287845999218, 0.5885049351589888, 0.5918809431740769, 0.5934857629759347, 0.5952749361703413, 0.5970957701867198, 0.6025518431009084, 0.6042920364262074, 0.6054812505259454, 0.6101002537089194, 0.6185270587181856, 0.6241949841539137, 0.6252047695304422, 0.6285140563405658, 0.633072653499513, 0.6360424687799683, 0.6378237452012717, 0.6428189148001743, 0.6440289675116057, 0.6473973940711418, 0.6504252488238643, 0.6522353531324407, 0.6602297577011562, 0.6663932109709568, 0.6678902166918754, 0.6758477464643364, 0.6791991512011694, 0.6821938806266105, 0.6869498549368531, 0.690405721911072, 0.695624652354058, 0.6997052060994762, 0.7040832713213391, 0.7144107636265983, 0.720584115823928, 0.7267492241681967, 0.7354841960111618, 0.7416026194517855, 0.745753379076126, 0.7466428299403386, 0.7494260059808087, 0.752638294071836, 0.7537558390293999, 0.754192560693847, 0.7600106361300425, 0.7650057224653084, 0.7735721017307203, 0.7739062217706651, 0.7762904775159478, 0.7802932096085996, 0.7807260380761243, 0.7821712630912462, 0.7860429613117631, 0.7925213919629192, 0.7960074024272833, 0.7997179136187196, 0.8001587287180605, 0.8035181084349343, 0.8098601873605862, 0.8109604752724683, 0.8219266359399297, 0.8224946492902271, 0.8267146599310183, 0.8288712762529586, 0.8318818716007041, 0.839816162145531, 0.846080490217095, 0.8476722143373212, 0.8571916570595887, 0.8629105419212435, 0.8676276209650275, 0.8722253472100095, 0.874170682157026, 0.8800463069761101, 0.8842986818196978, 0.8871193172236984, 0.8950652888512458, 0.9072489443564058, 0.9111682851800791, 0.9172659603763292, 0.9228548314604181, 0.9232771731471148, 0.9286602870148829, 0.9373784381643208, 0.9402835110291107, 0.9513423363382867, 0.9638231608784736, 0.9672635875263655, 0.9691420956919276, 0.970844813977911, 0.9793286311080955, 0.9820495370159625, 0.9858099506042328, 0.9863014495910855, 0.9885193402506222, 0.9916960733724518, 0.9946841651964872, 0.9961229496394411, 0.9986537290434363, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      " 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_rear\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.19140053782024805,\n",
      "      \"sum\" : 1571.2070149664162,\n",
      "      \"std_dev\" : 0.36011618732478035,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 6132.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 126.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 141.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 120.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 132.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 131.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 101.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 129.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 110.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 1087.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.5035469815118861, 0.9318909752764775, 0.7818256704067268, 0.0, 0.0, 0.0, 0.014567154751278899, 0.24739974705834578, 0.8662924359821813, 0.0, 0.41512493953472107, 0.0, 0.0, 0.0, 0.0, 0.1751462325128964, 0.0, 0.0, 0.16276278177818193, 1.0, 0.6261918911329976, 0.0, 0.0, 0.8570391223992478, 0.0, 0.0, 0.5980091173287496, 0.6148973971769703, 0.8548057787992615, 0.0, 0.8835647283701904, 0.27061999469359665, 0.8058371309539177, 0.474434893620735, 0.007334150836180275, 0.9741906071368183, 0.44670936037699993, 0.0, 0.99458198903526, 0.7981581646362419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6696085263343835, 0.0, 0.4542783967898225, 0.4515655866055751, 0.0630721362688611, 0.9840315142791302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3092736848867369, 0.27121377774342403, 0.046972991098139794, 0.9280517502288481, 0.0, 0.0, 0.0, 0.8301274055955237, 0.05541588844224443, 0.0, 0.7659715748551791, 0.0, 0.6529729219079393, 0.0, 0.0, 0.9885399870457067, 0.0, 0.0, 0.0, 0.03684097293493349, 0.0, 0.5095914808144868, 0.16950409186605864, 0.0, 0.0, 0.0, 0.587697018287546, 0.0, 0.0, 0.0, 0.5629484781578123, 0.3722545851026636, 0.0, 0.0, 0.6750772055933587, 0.0, 0.9616158070461657, 0.730243334357868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0679732998194037, 0.0, 0.0, 0.0, 0.6522751108990502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6328026106615069, 0.0, 0.0, 0.9889214474056903, 0.0, 0.5717893159359805, 0.4340521760809567, 0.0, 0.0, 0.0, 0.0, 0.2691203766777923, 0.7007255212842638, 0.0, 0.0, 0.0, 0.7561980622898204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17250125836432662, 0.0, 0.5269724966569793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8042443935943754, 0.4868249177179641, 0.8694954403625602, 0.5594608401270053, 0.0, 0.0, 0.06092872172071995, 0.0, 0.0, 0.6809549256677602, 0.41551406306206595, 0.0, 0.0, 0.09130880254467022, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7144141014704978, 0.0, 0.12537534923387328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.411906362394553, 0.31607768384326407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16462051323650484, 0.0, 0.7906911019001679, 0.38473257650744497, 0.43599518057058584, 0.5940494655668112, 0.5896534951515476, 0.0, 0.0, 0.8226734467760606, 0.0, 0.0, 0.0, 0.4210223534458548, 0.01460899710888286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29353479245866043, 0.26599769309265797, 0.3327808689607955, 0.4425950356858128, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9810545966256454, 0.0, 0.0, 0.8670719572920174, 0.3615112152008645, 0.0, 0.9428828366295567, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5837372193120927, 0.0, 0.0, 1.0, 0.0, 0.31952053747562603, 0.9316979736811688, 1.0, 0.0, 0.0837249378453484, 0.6140604890630726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9455339526331624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6330385929927995, 0.852772925589483, 1.0, 0.6867335234193896, 0.0, 0.0, 0.0, 0.47659281493252814, 0.07848660809258212, 0.0, 0.8252113712596311, 0.0, 0.0, 0.0, 0.143161357811193, 0.0, 0.6415685666849944, 0.02556979908973467, 0.7879701335909316, 0.0, 0.0, 0.18760927581384912, 0.0, 0.400032141738934, 0.0, 0.0, 0.0, 0.0, 1.0, 0.273698457678371, 0.0, 0.09750769246387525, 0.0, 0.0, 0.0, 0.3306430157592517, 0.0, 0.0, 0.3060471662287715, 0.9363152324974833, 0.0, 1.0, 0.0, 0.0, 0.682652605044199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6249797483760352, 0.0, 0.6928543518957885, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3233553651801525, 0.0, 0.0, 0.5778279715114357, 0.3078741252743674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46878988050679093, 0.0, 0.0, 0.14199425935208465, 0.0, 0.0, 0.6120085299594553, 0.0, 0.0, 0.9290840405120208, 0.0, 0.13750349259841466, 0.23307281189083495, 0.0, 0.0, 0.0, 1.0, 0.9775899603450432, 0.0, 0.004525847653185644, 0.0, 0.2215172721131058, 0.0, 0.25563909379536154, 0.0, 0.0, 0.0, 0.0, 0.03326797116935842, 0.0, 0.5841386605920524, 0.9368700907920335, 0.0, 0.0, 0.4512666140731144, 0.8691748574030873, 0.46993754494826756, 1.0, 0.4107092453916662, 0.0, 0.0, 0.8532424691971175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7463628843132415, 0.0, 0.0, 0.2596032837084785, 0.9983562428875503, 0.37641496252069395, 0.0, 0.5212951420344775, 0.0, 0.8945947140438331, 0.0, 0.4870206501790926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.24217465034747054, 0.0, 1.0, 0.7110009619498112, 0.0, 0.0, 0.0, 0.8919710425084207, 0.0, 0.0, 0.0, 0.3753360257162832, 0.0, 0.0, 0.2609085780070469, 0.0, 0.0, 0.0, 0.7731835012587582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7205546926810974, 0.0, 0.8865025266419025, 1.0, 0.13707760648901102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12187950178138363, 0.0, 0.0, 0.0, 0.008110804052508302, 0.0, 0.0, 0.5375846256925658, 0.18492029746714433, 0.42815517303011985, 0.0, 0.0, 0.0, 0.4386475002460548, 0.0, 0.0, 0.2625900556880538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3146289089351988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02075803212396421, 0.23911402232849033, 0.0, 0.8646523546027457, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.21228564166859132, 0.0, 0.0, 0.0, 0.014381235984152974, 0.0, 0.0, 0.0, 0.49629161291592927, 0.0, 0.04748321031540137, 0.0, 0.5545470702657121, 0.0, 0.0, 0.0, 0.552798967783562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20687146203694362, 0.0, 0.8140384924425823, 0.04918134008356856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5081417186651943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4502824838315258, 0.0, 0.0, 0.17405908088808175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9329566255282273, 0.0, 0.0, 0.24068914484979476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5868926022728558, 0.0, 0.41236648727468106, 0.9277230524268234, 0.42421413722558843, 0.14634545105888808, 0.7252870843545552, 0.36039404005411124, 0.0, 0.0, 0.4545096595051643, 0.0, 0.0, 0.0, 0.8489238694760728, 0.0, 0.0, 0.1876738197529384, 0.0, 0.0, 0.0, 0.5815642044379887, 0.0, 0.0, 0.0, 0.0, 0.08095373611568812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1097633782042291, 0.8850936566380897, 0.0, 0.0, 0.0, 0.5789653202958044, 0.9454880725621737, 0.6859561930815675, 0.5008010531586682, 0.21657918562724088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.553558532662358, 0.0, 0.0, 0.31219188378638796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6013840706885634, 0.3392202983917838, 0.0, 0.04106817279040542, 0.0, 0.0, 0.0, 0.9374930584895892, 0.0, 0.5834215190184351, 0.5357960510478733, 0.0, 0.0, 0.0, 0.7808739353291991, 0.0, 0.0, 0.0, 0.026867654044935296, 0.0, 0.8938744145090045, 0.0, 0.6042223203395692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31932762677426296, 0.0, 0.48902925695493793, 0.5712357088853165, 0.9462180358226221, 0.02208584530117974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49236230351962584, 0.0, 0.0, 0.5817088889065141, 0.0, 0.9367245558534901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38586682381248194, 0.0, 0.0, 0.0, 0.41608071073886466, 0.7930063987549418, 0.14859425210852606, 0.0, 0.0, 0.0, 0.7258796361807993, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2864737377445836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26125649038406973, 0.0, 0.2650812843385726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8254101487528136, 0.29257372483806765, 0.0, 0.0, 0.0, 0.8758926322862226, 0.0, 0.0, 0.8162153348920989, 0.32838549961660535, 0.0, 0.0, 0.24881902701993186, 0.0, 0.27963631849320625, 0.0, 0.7280122577961974, 0.8131476551679849, 0.0, 0.7744194946063033, 0.0, 0.4933142091459972, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002103843175883413, 0.0031409060481221163, 0.005142026940678446, 0.005718581360789288, 0.006435211496795712, 0.009453967229866578, 0.010568234220368455, 0.013251033503910548, 0.013634023905821469, 0.015765500765566043, 0.016061864981006146, 0.018000088945214987, 0.018386142151597284, 0.019795658347254386, 0.022026921223816998, 0.02381302501191629, 0.029257846322751857, 0.030392273151904625, 0.031115599917357684, 0.032645677545668605, 0.03617683912152636, 0.038021848237454914, 0.042633209287032736, 0.04533996996669254, 0.0496872470694083, 0.05233887578650831, 0.055525032809150554, 0.05947156886728078, 0.06110466761963229, 0.06367884603084317, 0.06569211648965922, 0.06642891654235195, 0.06669388140544885, 0.06939319515346298, 0.07074260199277072, 0.0713397129851171, 0.0746384310794288, 0.07764077598878127, 0.0827154615243535, 0.08676731957854367, 0.08883171481992092, 0.089812154282774, 0.0918708877100447, 0.09319611956269469, 0.09523365831988206, 0.09858292702241234, 0.09967873192572851, 0.10125991461515893, 0.10274825245242336, 0.1036785807342765, 0.10430203680062766, 0.1063647466538663, 0.10794371464646435, 0.10851998437649324, 0.11080796217980704, 0.11153589007707931, 0.11193592702153032, 0.1141399693096321, 0.11647784967333707, 0.11786438571793989, 0.12017808604830471, 0.12073134000216179, 0.12273823717382049, 0.12512525714174694, 0.1284022727117694, 0.13105574772085493, 0.13237237903497245, 0.13380373627948872, 0.1370894580787565, 0.13788526935601042, 0.14204490908494283, 0.14225523977681542, 0.1483603372895168, 0.15067610770987738, 0.1528326386274258, 0.15862414452637796, 0.16161981128587144, 0.16246916592394434, 0.1645921691578741, 0.16540904740472795, 0.16590102437078624, 0.16605252148153637, 0.16716809813092426, 0.16931148947992314, 0.17112872374704136, 0.17184848132709452, 0.17351190980423759, 0.17682598440433972, 0.1771709252718655, 0.18131927992550523, 0.184585129537033, 0.187286380106938, 0.18903952472753172, 0.19111870949600263, 0.1944476444316886, 0.19688787177568357, 0.19964512097659337, 0.20109872744266744, 0.20245263946280057, 0.20498120952681642, 0.20551436635150933, 0.2062561496194837, 0.20747860803708085, 0.21323049664287264, 0.21418735453162685, 0.21523031817501204, 0.21601264131064457, 0.2162505281865289, 0.21825987269372948, 0.2202253013773151, 0.22361443449631124, 0.22669065207492367, 0.22696469436536415, 0.22955277892601023, 0.23480913544421533, 0.23528085852372083, 0.240655672077134, 0.2415749821308889, 0.24516218005915225, 0.2461702994307814, 0.24757223738442746, 0.24977216244651979, 0.25180809402100246, 0.253223360466282, 0.25424662092387396, 0.25943527674049005, 0.2607052648352268, 0.2659702374106937, 0.2682752634357871, 0.26895894582647106, 0.2711474365001848, 0.27149875418186786, 0.2742835367800509, 0.27514350068498294, 0.2757574044412813, 0.2768717261174458, 0.27843940825043456, 0.2798926522464269, 0.2803461833894696, 0.28157077018126475, 0.282745689578762, 0.28732671650890196, 0.2891152833176809, 0.29380681703664135, 0.2959428888586566, 0.2973615313084723, 0.2984349123618767, 0.3003100909412916, 0.30337272878261, 0.30449253274895083, 0.30554954386929123, 0.3100002626910566, 0.3119840203264185, 0.3130501450631469, 0.3142994570663561, 0.31692247734494494, 0.3180495725509187, 0.31912348982046257, 0.31965205529206253, 0.32245905449646595, 0.3240177244136446, 0.3257411579935009, 0.32629826645784354, 0.3330284830090927, 0.3350054837622263, 0.3369579954995078, 0.3373109541512276, 0.3376493019992346, 0.3408862355304735, 0.34481760774616976, 0.34592044750169426, 0.3470503418621578, 0.3533940865771399, 0.353903824994937, 0.35513164775381256, 0.36167776020817344, 0.36244673552977025, 0.3647982191445295, 0.3656602602887957, 0.36709366932156584, 0.3697912516708558, 0.3756722518817265, 0.3779604376290062, 0.37909140978229194, 0.3803840730550777, 0.3810518069922785, 0.38252628024400825, 0.38305597261549806, 0.385120119902500\u001b[0m\n",
      "\u001b[34m06, 0.3907551523296371, 0.3927937758093434, 0.3944952333841235, 0.39694797293429285, 0.39785435594751895, 0.39910018807372305, 0.40232712468655596, 0.4035145250145784, 0.4042492718110433, 0.40472506382965867, 0.4094778530052039, 0.411864740417496, 0.41418985402809805, 0.414735826967471, 0.4149604360796805, 0.41621805884534935, 0.4189849066248905, 0.4198486976863176, 0.4211598319644074, 0.42282721671244994, 0.4288868788610386, 0.43098390192082203, 0.4353709490027369, 0.4367110690461853, 0.4385384885374355, 0.4423665331024188, 0.4441277131657516, 0.44662098387329263, 0.44812286357881437, 0.45058576156954666, 0.45394684810835706, 0.4559792757599369, 0.4575289965373439, 0.4580099251102341, 0.4604437795044949, 0.4622170652586235, 0.4640666894045047, 0.468338976235517, 0.46926264471316415, 0.4737215396617973, 0.4759677310116559, 0.47892680949161215, 0.48357561178138897, 0.4848248296662684, 0.487273605738224, 0.49193110010572905, 0.4972559303146882, 0.4989121197378029, 0.4995546908692585, 0.5015756999179484, 0.5061075548467509, 0.5068384318204826, 0.5070824240602667, 0.5134023377562469, 0.5146410168401129, 0.5181325207253834, 0.5221215519777576, 0.5231430206971652, 0.5251134564937814, 0.5257562195591349, 0.5272261808398002, 0.5298812610885262, 0.5302562370093162, 0.5313165205680591, 0.5320216789842518, 0.5322602133390402, 0.532675886761555, 0.5351523336803503, 0.5385544881126874, 0.5398377355115603, 0.5489804494416418, 0.549402981016866, 0.5498766388180678, 0.5531119710583715, 0.5565441636180959, 0.5578201919292014, 0.5619928474668068, 0.5644923745278093, 0.5646757785447638, 0.5649843576752536, 0.568887594902995, 0.5718091636071537, 0.5747795542644152, 0.5773108866038105, 0.5797311661341921, 0.5821482297799723, 0.5847590276659596, 0.5865835507047386, 0.5886605335008561, 0.5916936572405489, 0.5923671420203442, 0.5938024808096155, 0.5948032146777896, 0.6024698307034551, 0.6033341962120348, 0.6098318054986945, 0.6107707306850386, 0.6127627288219041, 0.614386487134352, 0.6174196764293646, 0.6190904744890128, 0.6234697122107017, 0.6245588903320873, 0.6252047695304422, 0.6281195312435718, 0.6320898295062423, 0.6330439207951993, 0.6350891059097188, 0.6360424687799683, 0.637055728154008, 0.6375686773841709, 0.6440289675116057, 0.6477131710629215, 0.6505116477917158, 0.6517106479109683, 0.6539940923398012, 0.6580549838612207, 0.6581962945078175, 0.6595941566504353, 0.6624675341161811, 0.6639929410098913, 0.6700325378075668, 0.6758477464643364, 0.6789784930380419, 0.686272308805904, 0.6874063641362376, 0.6906797711480066, 0.6913012566268047, 0.6927610381522795, 0.696805940538954, 0.7005564895081133, 0.7019243494751772, 0.7036079931247166, 0.7113144044693619, 0.7147096616426836, 0.7171988693295003, 0.7200080396631131, 0.7243174696766612, 0.7284312352489601, 0.7313165197032963, 0.7324487318380898, 0.7333248033380224, 0.7338831308025413, 0.7346125908118054, 0.7359956500405341, 0.7385058785105187, 0.7397303320855406, 0.74171206151293, 0.7457686162513044, 0.745860038627012, 0.7466428299403386, 0.7494260059808087, 0.7521266412715764, 0.753594630745753, 0.7537558390293999, 0.7562705174756582, 0.7592487330608428, 0.7608574545654768, 0.7631083636013083, 0.7653465582241507, 0.7672368528987112, 0.7684515640349512, 0.7697538315721301, 0.7707806182638798, 0.7726426999039012, 0.7736625648956658, 0.7739668032113479, 0.7762904775159478, 0.7774554671823856, 0.7791973702143609, 0.7815568171166929, 0.7837729908722203, 0.786522382390847, 0.7877130155277087, 0.790014841559882, 0.7920436407106101, 0.7927577002311217, 0.7955391139452882, 0.7965085197237084, 0.8023607794088699, 0.8047531219896948, 0.8080226299065529, 0.8171927633430995, 0.8219266359399297, 0.8229584462214861, 0.8247878562777867, 0.8266569470247191, 0.8273565548261456, 0.8316630440808698, 0.8339781763571392, 0.8403750985678328, 0.8416960998943857, 0.8420744373985792, 0.8448623274896327, 0.8476704105354645, 0.8510002638507566, 0.8518220717700545, 0.8541359976505043, 0.8566046299891075, 0.8646861920335402, 0.8699522174888613, 0.8729037597815608, 0.8737229201822251, 0.875118044558047, 0.877138441511404, 0.8776232426748221, 0.87986267736116, 0.8804380022479436, 0.8819921697216359, 0.8844242755019771, 0.8880390643601178, 0.8899367157988848, 0.8955958702519186, 0.8960751117945733, 0.8976746726779566, 0.9031907788344291, 0.9055247923296739, 0.9058911047877604, 0.9069428088348339, 0.9070708556206101, 0.9112326058922315, 0.9124087025940536, 0.9156076194554577, 0.9169420482009158, 0.9177929362882183, 0.9232771731471148, 0.9273551805862972, 0.9283835056363074, 0.9308072973164898, 0.9349944318387654, 0.9353833201559139, 0.9381142983195248, 0.9404192073007469, 0.9422589481308262, 0.9423834540022769, 0.9446657321710952, 0.9466444339935463, 0.9485029432181947, 0.949440812040461, 0.9513423363382867, 0.9546807210391054, 0.9558244837207522, 0.965538740575, 0.9666163982136188, 0.9702353444148768, 0.9716887255973322, 0.9748346527811119, 0.977031676545176, 0.9771042330515733, 0.9794791852706748, 0.9820543214315082, 0.9858099506042328, 0.9872851100131065, 0.9889683857375342, 0.9916960733724518, 0.997078967378638, 0.9996674938795106, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010815090186641063, 0.029394445756507293, 0.03921944851302306, 0.06841051168101009, 0.13271465381927738, 0.1693574822493754, 0.20085908986229417, 0.2271772199831955, 0.2386900313010175, 0.28139096057752677, 0.3467369807626699, 0.40128601989989243, 0.4322407838925123, 0.44636864651258557, 0.48235638155159155, 0.5342422059764451, 0.5709045018441643, 0.5885542289732454, 0.5967386388761682, 0.612257985881158, 0.6691106370108281, 0.7270406251436851, 0.7410173483981863, 0.7760002070354295, 0.8205026765761666, 0.8376181053376791, 0.8757800332719406, 0.9118360349599111, 0.951549974355327, 0.9645204722702085, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_age\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 42.784626629309294,\n",
      "      \"sum\" : 351219.0,\n",
      "      \"std_dev\" : 13.376439324058074,\n",
      "      \"min\" : 18.0,\n",
      "      \"max\" : 75.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 18.0,\n",
      "            \"upper_bound\" : 23.7,\n",
      "            \"count\" : 592.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 23.7,\n",
      "            \"upper_bound\" : 29.4,\n",
      "            \"count\" : 907.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 29.4,\n",
      "            \"upper_bound\" : 35.1,\n",
      "            \"count\" : 1207.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 35.1,\n",
      "            \"upper_bound\" : 40.8,\n",
      "            \"count\" : 1065.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 40.8,\n",
      "            \"upper_bound\" : 46.5,\n",
      "            \"count\" : 1287.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 46.5,\n",
      "            \"upper_bound\" : 52.2,\n",
      "            \"count\" : 1171.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 52.2,\n",
      "            \"upper_bound\" : 57.9,\n",
      "            \"count\" : 710.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 57.9,\n",
      "            \"upper_bound\" : 63.6,\n",
      "            \"count\" : 615.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 63.6,\n",
      "            \"upper_bound\" : 69.3,\n",
      "            \"count\" : 430.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 69.3,\n",
      "            \"upper_bound\" : 75.0,\n",
      "            \"count\" : 225.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 41.0, 33.0, 36.0, 38.0, 31.0, 23.0, 31.0, 55.0, 21.0, 32.0, 28.0, 49.0, 34.0, 67.0, 46.0, 47.0, 35.0, 56.0, 44.0, 37.0, 47.0, 30.0, 32.0, 24.0, 29.0, 51.0, 31.0, 20.0, 35.0, 21.0, 32.0, 28.0, 48.0, 25.0, 23.0, 25.0, 21.0, 24.0, 33.0, 28.0, 53.0, 47.0, 25.0, 41.0, 46.0, 47.0, 43.0, 49.0, 29.0, 30.0, 40.0, 42.0, 40.0, 25.0, 24.0, 43.0, 26.0, 53.0, 30.0, 39.0, 63.0, 20.0, 28.0, 38.0, 51.0, 43.0, 32.0, 40.0, 53.0, 38.0, 28.0, 47.0, 25.0, 31.0, 39.0, 23.0, 30.0, 38.0, 45.0, 28.0, 32.0, 23.0, 52.0, 28.0, 65.0, 34.0, 20.0, 24.0, 39.0, 28.0, 31.0, 32.0, 25.0, 29.0, 42.0, 24.0, 33.0, 47.0, 30.0, 36.0, 39.0, 28.0, 48.0, 35.0, 45.0, 59.0, 39.0, 53.0, 21.0, 44.0, 48.0, 20.0, 34.0, 37.0, 20.0, 39.0, 41.0, 25.0, 23.0, 18.0, 32.0, 52.0, 23.0, 43.0, 30.0, 31.0, 27.0, 40.0, 18.0, 29.0, 33.0, 44.0, 43.0, 25.0, 29.0, 34.0, 41.0, 46.0, 41.0, 37.0, 20.0, 20.0, 53.0, 18.0, 21.0, 43.0, 32.0, 35.0, 45.0, 40.0, 30.0, 48.0, 27.0, 40.0, 52.0, 43.0, 22.0, 24.0, 29.0, 47.0, 50.0, 43.0, 36.0, 57.0, 40.0, 47.0, 51.0, 30.0, 50.0, 55.0, 58.0, 34.0, 46.0, 28.0, 28.0, 45.0, 45.0, 25.0, 41.0, 50.0, 41.0, 27.0, 57.0, 22.0, 43.0, 20.0, 35.0, 29.0, 45.0, 20.0, 37.0, 27.0, 32.0, 45.0, 62.0, 28.0, 65.0, 25.0, 43.0, 29.0, 48.0, 55.0, 29.0, 67.0, 21.0, 48.0, 31.0, 45.0, 45.0, 46.0, 49.0, 29.0, 43.0, 44.0, 35.0, 45.0, 43.0, 25.0, 34.0, 33.0, 45.0, 21.0, 43.0, 33.0, 23.0, 39.0, 39.0, 49.0, 20.0, 40.0, 25.0, 35.0, 39.0, 23.0, 27.0, 49.0, 39.0, 21.0, 22.0, 40.0, 51.0, 30.0, 23.0, 25.0, 57.0, 32.0, 41.0, 32.0, 32.0, 41.0, 41.0, 41.0, 41.0, 56.0, 28.0, 51.0, 25.0, 19.0, 43.0, 38.0, 26.0, 53.0, 30.0, 48.0, 35.0, 50.0, 50.0, 41.0, 49.0, 27.0, 39.0, 28.0, 40.0, 43.0, 67.0, 35.0, 60.0, 47.0, 48.0, 19.0, 30.0, 19.0, 31.0, 63.0, 51.0, 48.0, 29.0, 33.0, 30.0, 28.0, 40.0, 40.0, 18.0, 48.0, 29.0, 32.0, 40.0, 44.0, 20.0, 52.0, 51.0, 23.0, 19.0, 25.0, 30.0, 53.0, 62.0, 60.0, 56.0, 23.0, 41.0, 47.0, 49.0, 38.0, 37.0, 41.0, 36.0, 69.0, 32.0, 18.0, 48.0, 46.0, 45.0, 34.0, 23.0, 39.0, 49.0, 27.0, 37.0, 46.0, 44.0, 51.0, 24.0, 33.0, 42.0, 51.0, 32.0, 36.0, 46.0, 34.0, 27.0, 31.0, 49.0, 31.0, 18.0, 36.0, 35.0, 46.0, 63.0, 45.0, 21.0, 36.0, 38.0, 38.0, 39.0, 37.0, 33.0, 52.0, 31.0, 43.0, 31.0, 33.0, 49.0, 21.0, 18.0, 30.0, 36.0, 44.0, 38.0, 40.0, 37.0, 40.0, 23.0, 43.0, 45.0, 55.0, 39.0, 26.0, 39.0, 26.0, 29.0, 44.0, 41.0, 64.0, 28.0, 30.0, 37.0, 50.0, 35.0, 36.0, 59.0, 32.0, 21.0, 34.0, 43.0, 21.0, 45.0, 33.0, 44.0, 36.0, 26.0, 42.0, 44.0, 26.0, 49.0, 48.0, 27.0, 33.0, 41.0, 41.0, 44.0, 56.0, 57.0, 39.0, 64.0, 33.0, 39.0, 24.0, 41.0, 45.0, 36.0, 58.0, 51.0, 47.0, 32.0, 20.0, 19.0, 43.0, 47.0, 28.0, 71.0, 23.0, 26.0, 26.0, 25.0, 30.0, 52.0, 73.0, 28.0, 53.0, 52.0, 72.0, 28.0, 28.0, 35.0, 38.0, 32.0, 26.0, 34.0, 57.0, 52.0, 20.0, 25.0, 45.0, 38.0, 33.0, 19.0, 54.0, 41.0, 46.0, 24.0, 38.0, 39.0, 42.0, 20.0, 45.0, 43.0, 43.0, 37.0, 45.0, 32.0, 20.0, 24.0, 35.0, 62.0, 37.0, 27.0, 20.0, 46.0, 46.0, 45.0, 29.0, 24.0, 48.0, 50.0, 23.0, 21.0, 21.0, 26.0, 44.0, 28.0, 44.0, 36.0, 49.0, 26.0, 28.0, 33.0, 42.0, 36.0, 37.0, 34.0, 54.0, 32.0, 25.0, 42.0, 18.0, 38.0, 24.0, 35.0, 42.0, 32.0, 36.0, 44.0, 37.0, 52.0, 26.0, 51.0, 55.0, 40.0, 32.0, 37.0, 28.0, 35.0, 52.0, 36.0, 37.0, 49.0, 72.0, 42.0, 24.0, 21.0, 40.0, 33.0, 29.0, 44.0, 36.0, 47.0, 47.0, 61.0, 31.0, 44.0, 46.0, 24.0, 42.0, 40.0, 23.0, 37.0, 24.0, 26.0, 38.0, 47.0, 33.0, 42.0, 54.0, 46.0, 54.0, 45.0, 44.0, 28.0, 28.0, 40.0, 37.0, 26.0, 24.0, 29.0, 36.0, 52.0, 22.0, 43.0, 44.0, 58.0, 61.0, 22.0, 23.0, 34.0, 33.0, 54.0, 27.0, 46.0, 53.0, 49.0, 30.0, 28.0, 27.0, 29.0, 26.0, 41.0, 37.0, 35.0, 31.0, 29.0, 37.0, 44.0, 27.0, 58.0, 52.0, 24.0, 49.0, 56.0, 44.0, 43.0, 49.0, 44.0, 40.0, 41.0, 28.0, 26.0, 23.0, 32.0, 31.0, 48.0, 46.0, 54.0, 27.0, 41.0, 27.0, 27.0, 50.0, 40.0, 29.0, 34.0, 40.0, 52.0, 46.0, 35.0, 37.0, 37.0, 31.0, 40.0, 39.0, 33.0, 41.0, 37.0, 46.0, 52.0, 49.0, 30.0, 23.0, 53.0, 38.0, 36.0, 27.0, 41.0, 51.0, 27.0, 38.0, 42.0, 19.0, 31.0, 37.0, 59.0, 70.0, 50.0, 27.0, 59.0, 41.0, 26.0, 53.0, 49.0, 33.0, 26.0, 30.0, 41.0, 35.0, 36.0, 47.0, 57.0, 50.0, 25.0, 29.0, 37.0, 31.0, 38.0, 49.0, 54.0, 32.0, 46.0, 37.0, 58.0, 33.0, 26.0, 34.0, 27.0, 43.0, 27.0, 22.0, 37.0, 31.0, 46.0, 48.0, 40.0, 34.0, 32.0, 45.0, 49.0, 26.0, 39.0, 28.0, 40.0, 50.0, 49.0, 35.0, 28.0, 42.0, 22.0, 24.0, 33.0, 30.0, 24.0, 25.0, 32.0 ], [ 75.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0 ], [ 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 42.0, 4\u001b[0m\n",
      "\u001b[34m2.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_or\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.06733881333809533,\n",
      "      \"sum\" : 552.7843186924246,\n",
      "      \"std_dev\" : 0.22851503619667152,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7442.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 55.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 60.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 52.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 48.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 56.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 42.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 63.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 48.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 343.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.533883707341511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18039044693420014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1164352716298096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.520449404165286, 0.0, 0.2018418353637581, 0.0, 0.0, 0.0, 0.22218875554154927, 0.17766088854315254, 0.0, 0.0, 0.0, 0.3303914736656165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31944183822089856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.041428088819387754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6175291150623116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03838419295383433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9833241865101608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23107995542883164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8724298254286291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34409668690160045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08804041580036681, 0.0, 0.0, 0.1827511659874359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10467597053553335, 0.0, 0.0, 0.06090193309949332, 0.0, 0.0, 0.0, 0.0, 0.25361277085970824, 0.0, 0.0, 0.5054788748795921, 0.0, 0.0, 0.0, 0.37303156547128347, 0.0, 0.3883535806100076, 0.7042524374049793, 0.0, 0.0, 0.0, 0.8188281491499799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9326231284780743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6396245076368293, 0.0, 0.0, 0.8634798949128131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8859139954974249, 0.0, 0.0, 0.26408204644801125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8623702656016387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162750621546516, 0.0, 0.37394713447906747, 0.0, 0.15137117126327493, 0.0, 0.0, 0.0, 0.0, 0.03479036145426484, 0.0, 0.6320192084224364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5234071850674719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06368476750251673, 0.0, 0.0, 0.0, 0.0, 0.317347394955801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3071456481042115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9324889235898018, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1308251425969127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32645342186860915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47870485796552253, 0.0, 0.0, 0.44617655936627443, 0.0, 0.0, 0.0, 0.0, 0.732859187331831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7578253496525295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22681649874124177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2670750074563324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9817249302764938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4624153743074342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7374099443119462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8443148641523824, 0.0, 0.7179326909401018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17187651213592425, 0.4765264708322373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7009353650179992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7390814203498319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4963113906717611, 0.17084935971586013, 0.0, 0.6202413542689121, 0.0, 0.0, 0.0, 0.6285664006472832, 0.0, 0.5497175161684742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5643953803389896, 0.0, 0.4134882189625513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5172934821522531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6396059599458888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.912890710538566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7912842924966835, 0.0, 0.6607797016082162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33829615451865325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35796119453276465, 0.0, 0.38769515483900674, 0.0, 0.0, 0.0, 0.938714635374035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7387435096159303, 0.0, 0.0, 0.0, 0.0, 0.09271481081026989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12141490550497214, 0.2788676426431763, 0.0, 0.6716145003833947, 0.0, 0.0247648775761512, 0.7511809729800681, 0.5921103914927199, 0.7203636815067938, 0.0, 0.0, 0.18685234483201507, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0038171341243471435, 0.005351358440002119, 0.00608874823983907, 0.00979110641237857, 0.010971641649826114, 0.014628258877675715, 0.025237345848264203, 0.02654261002382685, 0.029250042329329817, 0.032947318573965156, 0.038021848237454914, 0.04783082039410547, 0.051154044168869595, 0.05693810259302845, 0.05770292841589886, 0.06100714300539489, 0.07074260199277072, 0.07647995549931308, 0.0875912974059464, 0.09305719116516609, 0.09729448955464381, 0.10392488820542667, 0.10480806499757211, 0.10910963176574973, 0.11541670707881224, 0.1223529803492186, 0.1271997626874496, 0.12786429997752347, 0.12960065119544195, 0.13074037534894745, 0.13306653164811633, 0.13801309159572772, 0.14882573914722919, 0.1662080490811727, 0.16885420667768614, 0.17129495782167037, 0.17477344282737717, 0.17998737088064398, 0.19081682886096896, 0.19178245559186058, 0.19865200812619144, 0.2079063662394568, 0.2100293495162816, 0.21083915341126858, 0.21900410638500856, 0.22769898483465711, 0.2404175898853682, 0.2422312178245669, 0.245807439306153, 0.24858025771494208, 0.2521614255879282, 0.25382107815669486, 0.2560475651049543, 0.2624342509071732, 0.2645158039888382, 0.26896803159538596, 0.2705362301683363, 0.27437279972558415, 0.27775262374926113, 0.2799919603368869, 0.28783129885160585, 0.29231167366938127, 0.2970565590213232, 0.30247902916792657, 0.3093202288519934, 0.31924410703951445, 0.32188616904579126, 0.3238195749024314, 0.32838122788508106, 0.3289447161400856, 0.33579828692821434, 0.34776464686755926, 0.35346074054678245, 0.3548608307461478, 0.364354238428232, 0.3683564849171084, 0.3712070938899983, 0.3732598144627589, 0.38068968116086577, 0.386222581184301, 0.39451733078559537, 0.40397787632654825, 0.41085709184049646, 0.42082474462527786, 0.4303371775089212, 0.4411505522306324, 0.44452825305015964, 0.45039373146924333, 0.4543131115045266, 0.45441787820793356, 0.4561942721337626, 0.45835358178324015, 0.4656825417622795, 0.4677424688510239, 0.47273481908474346, 0.4822643612521922, 0.48836141748098594, 0.49141817752855677, 0.49350099215440824, 0.4954521034609818, 0.5079455106175994, 0.5133682102249155, 0.5221215519777576, 0.5259935715168441, 0.5272261808398002, 0.530358225319291, 0.5318890790075141, 0.5361857502723201, 0.5451055282606997, 0.5474714898623186, 0.549402981016866, 0.5511469283252918, 0.5536131097368052, 0.5625180733917903, 0.5656881721410058, 0.5691379084619667, 0.5773439662110417, 0.5811954237209566, 0.5908674412710415, 0.5990582375269533, 0.602145644052481, 0.6058639532173719, 0.6134731386391763, 0.6148798800974999, 0.6251964322182036, 0.6302087483291442, 0.6344042989960332, 0.6358872249895006, 0.6481949935896475, 0.6583254981030792, 0.6591843002101534, 0.6611406784286965, 0.6664304505277996, 0.6774720221535848, 0.6817486440901612, 0.686272308805904, 0.6938626591204068, 0.7000342727721044, 0.7037923109905077, 0.7197914533546861, 0.7243444063295397, 0.7311532575471567, 0.7330036196283534, 0.7339807219946193, 0.7362288825285501, 0.7401613687614631, 0.7457387685551354, 0.7459252088136745, 0.7495454844688882, 0.7507295069993472, 0.7546212215985918, 0.7596176113005162, 0.7628555340222888, 0.7718577261816213, 0.7735388915345639, 0.7799113231286134, 0.7867695033571274, 0.7876660257131087, 0.7983441882243283, 0.8132767042269585, 0.8223934188170581, 0.8330689291824985, 0.8343716529717347, 0.846080490217095, 0.8479278837633485, 0.8484306284123264, 0.8510002638507566, 0.8560580864277691, 0.863009046067227, 0.8669334683518837, 0.8686505918550933, 0.8726358025468353, 0.876777345827834, 0.8839773186518307, 0.8890224754148519, 0.8936627026517728, 0.8960407996572191, 0.8987400853848411, 0.9078320415275677, 0.9112326058922315, 0.923431741566461, 0.9301709654384246, 0.9439823053632096, 0.9558244837207522, 0.959826518075929, 0.9638231608784736, 0.965538740575, 0.969062355268658, 0.9748580417227273, 0.9833056568184674, 0.9851745550906748, 0.9894317657796315, 0.991588408870274, 0.995480490704257, 0.999713804155914, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      " 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052649537368961274, 0.10946759867911515, 0.2311309124276466, 0.27811237207306494, 0.3793585899224238, 0.41089146552910516, 0.5217300466362131, 0.5584126725831979, 0.7270406251436851, 0.7760002070354295, 0.8944799309680674, 0.9420795394412017, 0.9607805514869769, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_claims_past_year\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.06029967109270313,\n",
      "      \"sum\" : 495.0,\n",
      "      \"std_dev\" : 0.33095682995312153,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 7.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 7838.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 1.4,\n",
      "            \"count\" : 297.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.4,\n",
      "            \"upper_bound\" : 2.1,\n",
      "            \"count\" : 52.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.1,\n",
      "            \"upper_bound\" : 2.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.8,\n",
      "            \"upper_bound\" : 3.5,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.5,\n",
      "            \"upper_bound\" : 4.2,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.2,\n",
      "            \"upper_bound\" : 4.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.9,\n",
      "            \"upper_bound\" : 5.6,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.6,\n",
      "            \"upper_bound\" : 6.3,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 6.3,\n",
      "            \"upper_bound\" : 7.0,\n",
      "            \"count\" : 0.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\u001b[0m\n",
      "\u001b[34m.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_self\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.6432726362369159,\n",
      "      \"sum\" : 5280.625070868842,\n",
      "      \"std_dev\" : 0.4357568971749935,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 2137.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 192.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 200.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 214.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 196.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 207.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 193.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 167.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 184.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 4519.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 0.9318909752764775, 0.7818256704067268, 0.0, 1.0, 0.5546134740221278, 1.0, 1.0, 0.8662924359821813, 1.0, 0.41512493953472107, 0.0, 0.47833548167055584, 0.021021106726217154, 1.0, 1.0, 1.0, 1.0, 0.16276278177818193, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.755838391283847, 1.0, 0.6148973971769703, 0.0, 0.9524153059966436, 0.0, 0.0, 1.0, 0.0, 0.007334150836180275, 0.9741906071368183, 0.44670936037699993, 0.520449404165286, 0.0, 0.0, 1.0, 1.0, 0.0, 0.7778112444584507, 1.0, 1.0, 0.5248999867258383, 0.5488068085492763, 0.0, 0.4107853856521445, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2432419097530717, 0.31944183822089856, 0.8339251476664863, 0.059105820875654524, 0.3092736848867369, 1.0, 1.0, 1.0, 0.09114063944467754, 0.7140994662287976, 0.0, 0.16987259440447633, 1.0, 0.3311464891641498, 0.7659715748551791, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9585719111806122, 0.03219726235151499, 1.0, 0.03684097293493349, 0.11475359941383545, 0.0, 0.8304959081339414, 0.9490251229775576, 0.6175291150623116, 0.7922165790383086, 1.0, 0.0, 0.0, 0.21836744194675284, 1.0, 0.3722545851026636, 1.0, 0.15624495601270638, 0.6750772055933587, 0.31270443741748244, 0.9616158070461657, 0.730243334357868, 0.0, 0.0, 1.0, 0.0, 0.016675813489839153, 0.8052265023127742, 0.0, 0.2726506473124847, 0.26843788043886607, 1.0, 0.47811567184205683, 0.9320267001805963, 0.0, 0.0, 1.0, 0.6522751108990502, 0.4596445973857374, 0.3242387071047762, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.9889214474056903, 0.0, 1.0, 1.0, 0.8724298254286291, 0.0, 0.3543771829861353, 0.0, 0.0, 0.7007255212842638, 0.5890200909809116, 1.0, 0.6501456158191455, 1.0, 0.34409668690160045, 1.0, 0.3150105071834246, 0.22460244007488483, 0.06915356771850123, 0.0, 1.0, 1.0, 0.956684726745688, 0.0, 0.6694389976937092, 0.0, 0.4124030604678661, 0.8042443935943754, 0.4868249177179641, 1.0, 1.0, 0.0, 0.9119595841996332, 0.06092872172071995, 0.305982585894258, 1.0, 1.0, 1.0, 0.0, 0.7574217339261748, 0.09130880254467022, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3616470948410445, 1.0, 0.0, 1.0, 1.0, 0.5054788748795921, 0.12169530672667228, 1.0, 0.31607768384326407, 1.0, 0.1916051176959771, 1.0, 0.7042524374049793, 0.7442562984516996, 0.672579041266552, 0.16462051323650484, 0.18117185085002008, 1.0, 0.615267423492555, 0.43599518057058584, 0.5940494655668112, 1.0, 0.9326231284780743, 1.0, 0.8226734467760606, 0.27692836395033116, 0.0, 1.0, 1.0, 0.01460899710888286, 1.0, 1.0, 0.6125487040774613, 0.0, 1.0, 0.29353479245866043, 1.0, 0.3327808689607955, 1.0, 0.0, 0.6625679177387851, 0.0, 1.0, 1.0, 0.9810545966256454, 0.26408204644801125, 0.7916004263816684, 1.0, 0.3615112152008645, 0.0, 0.9428828366295567, 0.0, 1.0, 0.0, 0.9753820161587614, 0.0, 0.5837372193120927, 0.3565713259508191, 1.0, 1.0, 1.0, 0.31952053747562603, 0.0, 1.0, 0.0, 0.0837249378453484, 1.0, 0.6260528655209325, 0.0, 0.15137117126327493, 1.0, 0.6714418501142015, 0.9455339526331624, 0.81754195934751, 0.03479036145426484, 0.5718160601328272, 0.6320192084224364, 0.0, 1.0, 1.0, 1.0, 0.6867335234193896, 1.0, 1.0, 0.006814697900128119, 1.0, 0.07848660809258212, 0.812077611008679, 0.8252113712596311, 0.20494198239386885, 0.32373082561042366, 0.0, 0.143161357811193, 0.0, 1.0, 0.02556979908973467, 1.0, 1.0, 0.0, 0.18760927581384912, 0.9175940281380518, 1.0, 0.5143531346657229, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9118186286860916, 0.0, 0.1466707834412122, 1.0, 1.0, 0.3306430157592517, 0.7687200716840445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.9435741440351771, 0.12874837260134742, 0.0, 1.0, 0.8032449046648062, 0.9865631141144104, 1.0, 0.9180342653563378, 0.0, 1.0, 0.0, 0.0, 1.0, 0.9594721829554119, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36395265766087337, 0.0, 1.0, 0.3078741252743674, 0.5227999205820387, 1.0, 1.0, 0.0, 0.0, 0.4022237348471124, 1.0, 1.0, 1.0, 1.0, 0.30424186382719576, 0.8607531554058905, 0.6120085299594553, 0.6936990031124625, 0.32610785251257346, 0.9290840405120208, 1.0, 0.13750349259841466, 0.0, 0.30481253378993434, 0.37037165506140735, 0.8634846083691153, 1.0, 0.9775899603450432, 0.41737135395963443, 0.0, 1.0, 0.2215172721131058, 0.9438379900966869, 1.0, 1.0, 0.17159636706519, 0.8325402554820115, 1.0, 0.03326797116935842, 0.8781119174677295, 0.5841386605920524, 1.0, 0.6032449435444707, 0.5259937340515549, 0.4512666140731144, 0.8691748574030873, 0.46993754494826756, 1.0, 0.4107092453916662, 0.0, 0.8950566039998331, 0.8532424691971175, 0.0, 0.13736174596867423, 0.7231300305079877, 0.046063063681977434, 0.0, 0.33920147030908965, 1.0, 0.0, 0.15434647772265764, 1.0, 0.9983562428875503, 1.0, 1.0, 0.0, 0.13792385742340296, 1.0, 1.0, 0.4870206501790926, 0.281392982172163, 1.0, 0.24715134411779371, 0.0, 1.0, 0.0, 1.0, 0.2944372883503089, 0.6922971866101562, 1.0, 0.9269964071003727, 1.0, 1.0, 0.7655005223259063, 0.25062098327584403, 0.08215911690644695, 1.0, 0.0, 0.2497392059126845, 1.0, 1.0, 1.0, 0.5477975208964613, 1.0, 0.6865139430432525, 0.0, 0.12254787339683115, 1.0, 0.328412257061074, 0.03172249181603115, 0.46503332659055596, 0.9623022750851472, 0.8080678171160226, 0.3207245244599576, 0.0, 0.0, 1.0, 0.8865025266419025, 1.0, 1.0, 0.2670750074563324, 0.0, 1.0, 0.0, 1.0, 0.12187950178138363, 0.018275069723506232, 1.0, 0.9313513338521278, 0.008110804052508302, 0.9513968619791061, 1.0, 0.5375846256925658, 0.18492029746714433, 0.42815517303011985, 0.9385748707401673, 0.22392458779658952, 1.0, 0.4386475002460548, 1.0, 0.19213435431601877, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3146289089351988, 0.6740175348839673, 0.0, 1.0, 0.2820673090598982, 0.28360792341713625, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.17187651213592425, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21228564166859132, 0.11555837668063174, 0.16357907701436047, 0.49753435023723447, 1.0, 0.8029813013091038, 0.01920619458541517, 0.3940738045857527, 0.49629161291592927, 0.8784158630449617, 1.0, 0.0, 1.0, 1.0, 0.7009353650179992, 0.19427357100180143, 1.0, 0.829821264717285, 1.0, 0.4112040672118541, 0.33663746598531863, 0.8817775879275401, 0.0, 0.0, 0.220508787136648, 1.0, 1.0, 1.0, 1.0, 0.03038406109566205, 1.0, 0.3004034669764718, 0.1470736161454187, 0.8841769177632057, 1.0, 0.4963113906717611, 0.8291506402841399, 0.5081417186651943, 0.0, 0.47774212639953595, 1.0, 0.0, 0.0, 0.3667367983905896, 0.0, 1.0, 1.0, 0.17405908088808175, 0.0, 0.9240729888456831, 0.17967591185279908, 1.0, 1.0, 1.0, 0.6191680442430584, 1.0, 0.3111894964100129, 0.5519363610604665, 0.0, 0.5740024805315719, 1.0, 0.0, 0.5643953803389896, 0.9329566255282273, 1.0, 0.526082518417403, 0.24068914484979476, 0.28733438101345554, 0.0, 0.0, 1.0, 0.37822451524334477, 0.0, 1.0, 0.19934548947118313, 0.0, 1.0, 0.42421413722558843, 1.0, 1.0, 0.0, 0.9129287944226918, 0.0, 1.0, 0.0, 0.5439731112849675, 1.0, 1.0, 0.3972714728404597, 0.7544493740555089, 1.0, 0.0, 0.11148768783878193, 0.4295905085963584, 0.5815642044379887, 0.2853043247642658, 0.24021943320838557, 0.4437713390922451, 0.28236791904265623, 1.0, 1.0, 0.0, 0.3014630594588007, 0.5993729928719863, 1.0, 0.1097633782042291, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5008010531586682, 0.21657918562724088, 0.12737411451410363, 0.912890710538566, 1.0, 0.691416057513152, 0.26175110013448244, 0.37575926300248186, 0.0, 0.19033697509504754, 0.0, 0.553558532662358, 1.0, 0.43085827538227073, 1.0, 0.7251111599333161, 0.7963006634151322, 0.832937392318661, 0.014231750414258837, 0.0, 0.6013840706885634, 0.3392202983917838, 0.5445954487107494, 0.04106817279040542, 0.0, 1.0, 1.0, 0.0, 0.38746646382175665, 0.4165784809815649, 1.0, 1.0, 0.4802942587913558, 0.33829615451865325, 0.7808739353291991, 1.0, 0.0, 0.5153104830636925, 0.026867654044935296, 0.38048188549303585, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.037897895834972495, 0.0, 1.0, 0.31932762677426296, 1.0, 0.48902925695493793, 1.0, 1.0, 0.02208584530117974, 0.35796119453276465, 0.0, 0.38769515483900674, 0.13836820088819002, 0.7381682705368436, 1.0, 0.938714635374035, 0.49236230351962584, 1.0, 0.8555511234358725, 0.5817088889065141, 0.3094127948704444, 0.9367245558534901, 0.5156765510770731, 0.497253886590878, 0.17841609656349577, 0.8918449854266433, 0.0, 0.0, 0.6741754159805513, 1.0, 1.0, 1.0, 1.0, 0.14859425210852606, 0.9157356338441489, 0.3560930851664217, 0.3196155862374779, 1.0, 1.0, 1.0, 0.7890228445481342, 1.0, 1.0, 0.7135262622554164, 0.0, 0.0, 0.16346910923909652, 1.0, 0.07140311846936165, 1.0, 0.6937321129953853, 0.2650812843385726, 1.0, 0.8071294313103857, 0.9072851891897301, 0.4677771251438061, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.29257372483806765, 0.7117779449909495, 0.10164472483233467, 0.5826861465545828, 0.8758926322862226, 1.0, 0.2788676426431763, 1.0, 0.32838549961660535, 0.5127879930780861, 1.0, 0.24881902701993186, 0.40788960850728007, 0.27963631849320625, 0.13637032746756583, 0.2719877422038026, 0.8131476551679849, 0.7425210238562752, 0.0, 1.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.865281706631139E-4, 0.0013462709565636999, 0.0031409060481221163, 0.005351358440002119, 0.00608874823983907, 0.006682129223887778, 0.007557710625221037, 0.00979110641237857, 0.011478352004553272, 0.012907227980991975, 0.01340262643216561, 0.015765500765566043, 0.01582109176558244, 0.018386142151597284, 0.02104249295889593, 0.022141475472629457, 0.024684157224584613, 0.027519185140415292, 0.029257846322751857, 0.030549457093379973, 0.031778484357324444, 0.034939246405988444, 0.03798156328985347, 0.038334264045186806, 0.03983221527125458, 0.04404037938846439, 0.04524918901888786, 0.046464902148491194, 0.04678584497176852, 0.047202472398705675, 0.050018576821112215, 0.05280396046852809, 0.05439074852231118, 0.055334267828904826, 0.05716885858673826, 0.05768461032680716, 0.05846708971555892, 0.05958079269925309, 0.06262156183567924, 0.06367884603084317, 0.06468689351513157, 0.06569211648965922, 0.0683409355322604, 0.0691126279391916, 0.06980065461462892, 0.07071159773794056, 0.07074260199277072, 0.07267087161001629, 0.07436266997466423, 0.07482120519497304, 0.07571292920533879, 0.07656825843353898, 0.07714516853958187, 0.07996539435930194, 0.08126528939362265, 0.08202368521147085, 0.083396698357589, 0.08474281508217696, 0.08534133648432485, 0.08893129723261639, 0.0920987541995898, 0.0936724207059102, 0.09608666973962532, 0.09954651280877513, 0.10536753395280596, 0.10573488174358603, 0.10761418475985884, 0.11034796698243365, 0.11188061654912385, 0.1141399693096321, 0.11573760667870536, 0.11692353552539148, 0.11786438571793989, 0.11854922032497861, 0.11982900201764635, 0.12013732263884003, 0.12123075020708551, 0.12201550301516517, 0.12286155848859603, 0.12389480740195746, 0.12471405691139048, 0.12573752938976224, 0.1263564813145106, 0.1271997626874496, 0.12793692451178318, 0.1279516615529923, 0.1284022727117694, 0.1299299245357013, 0.13074037534894745, 0.13136036017657438, 0.13237237903497245, 0.13417983477764484, 0.13533960785958232, 0.13603841926498983, 0.14043476835305424, 0.1426910976391591, 0.14350659723742643, 0.14529654990680252, 0.14821746209932463, 0.14899973614924344, 0.14931973939515375, 0.1519841147505986, 0.1528326386274258, 0.15380702464160778, 0.1555714368693023, 0.15792556260142077, 0.16003601971781745, 0.1605390904992331, 0.16333664808905723, 0.1652420504426032, 0.16590102437078624, 0.16713201147122125, 0.17098226745450895, 0.17351190980423759, 0.1748678040712962, 0.17521214372221328, 0.17760658118294192, 0.1796224925510267, 0.18129294288076725, 0.18358921503496928, 0.18672329577304148, 0.1878428525377741, 0.18974141330046868, 0.19081682886096896, 0.19121001543646154, 0.19197737009344706, 0.193410657673723, 0.1944476444316886, 0.19519716457188252, 0.19584081258691888, 0.19714879100445404, 0.1984910746053491, 0.20028208638128042, 0.20140672761724876, 0.2044608860547118, 0.20551436635150933, 0.2064293454611984, 0.20660598569465227, 0.20827974073865352, 0.20947948972832653, 0.21119773609464043, 0.21302986508233368, 0.2137240432429055, 0.21513817704111982, 0.21550075886755105, 0.2160601162447664, 0.2162505281865289, 0.21698336268326712, 0.21741806014866205, 0.21849435225781788, 0.21882957621308075, 0.219268146799099, 0.22001167308945568, 0.2202253013773151, 0.22306206154275687, 0.22408846719269404, 0.22554132992573261, 0.2264611084654361, 0.22674118440694457, 0.22737727255061746, 0.232645538562681, 0.23417096076509014, 0.23483967118323368, 0.23528085852372083, 0.23710666444563588, 0.2380931798675846, 0.23915877778224304, 0.240655672077134, 0.2414981190836093, 0.2437294825243418, 0.24589231968383596, 0.2478713004564288, 0.2517671686681041, 0.2522056502406276, 0.2535841169963692, 0.2540747911863255, 0.2548822489148823, 0.256743496309758, 0.25717502509368373, 0.25823101966616, 0.2605917701686882, 0.26290344956794875, 0.263799574939238, 0.2675512681619102, 0.2676007988617075, 0.26868348029670375, 0.2690196467983105, 0.2742740896358967, 0.27514350068498294, 0.2757574044412813, 0.27843940825043456, 0.2785779326712683, 0.2802085466453139, 0.2803461833894696, 0.28226247041293284, 0.2824278752684056, 0.2849612811493162, 0.28703999214119424, 0.28732671650890196, 0.2891152833176809, 0.2905875598063551, 0.29151030250720267, 0.29332446632230014, 0.29384149788094593, 0.2954679246267593, 0.2968692745602808, 0.2984349123618767, 0.3014693747908629, 0.30337272878261, 0.30458435167194675, 0.30619444303258825, 0.3069722822090182, 0.3078863820162494, 0.31123745918863466, 0.3119840203264185, 0.3131632018297771, 0.3142994570663561, 0.3162458944229575, 0.31658675990865115, 0.3180495725509187, 0.3186089627636072, 0.31924410703951445, 0.32005983252098347, 0.3225279778464152, 0.32284758754232634, 0.3238917685855889, 0.3256848020639532, 0.32629826645784354, 0.3290569952574921, 0.3303973838660381, 0.33303487180539837, 0.3335695494722004, 0.33720372579027835, 0.33751605305839183, 0.34037063360525777, 0.3408156997898466, 0.3414252696042983, 0.3438659819794193, 0.34481760774616976, 0.34592044750169426, 0.34688597636438556, 0.3485736672419705, 0.3502029910907303, 0.3547101624742831, 0.35513164775381256, 0.3571810851998257, 0.35936440719741347, 0.3598016884403762, 0.36037781993034756, 0.36171025485958064, 0.3624313226158291, 0.36369312475614024, 0.36776184913213905, 0.36801131960381095, 0.3694190584169077, 0.3707011939892638, 0.3715465113198744, 0.37346259614417343, 0.37480356778179635, 0.37557455352827196, 0.3765221694807036, 0.3781007697874508, 0.3789102780588144, 0.37922653718044896, 0.38050224859241233, 0.38076096794641834, 0.3816119398672001, 0.38423962013738133, 0.3853758830473618, 0.38587450289511593, 0.3863231730764659, 0.3866201726338342, 0.3873925856686593, 0.3892292693149614, 0.3907551523296371, 0.39312265842307004, 0.39413604678262815, 0.3952059263099702, 0.3961490174597221, 0.39694797293429285, 0.39785435594751895, 0.39910018807372305, 0.40087941495967483, 0.4011917036165086, 0.40144563091319363, 0.40233495523733276, 0.4036784811396317, 0.4047984290851998, 0.4064614308768528, 0.4083063427594511, 0.41106692505443587, 0.41149506484101117, 0.4121309302627716, 0.41382746532079584, 0.4144697155393433, 0.4148151193889472, 0.4149712154000782, 0.41594390458185504, 0.41798993387048433, 0.42011872784772497, 0.42265603378895833, 0.42282721671244994, 0.4252204457355848, 0.42593770846693946, 0.42863054697047576, 0.4296228638968441, 0.43378498424738343, 0.4353709490027369, 0.4355589093\u001b[0m\n",
      "\u001b[34m211175, 0.4399083025566045, 0.4411505522306324, 0.4424099364806695, 0.4433065095171753, 0.44564331878363095, 0.44579091457722897, 0.4474681413224578, 0.4488530716747082, 0.4495282228970595, 0.4504163432778564, 0.45058576156954666, 0.4506196567297579, 0.4519676433357599, 0.45440315447995283, 0.4546188787816975, 0.45515224091548434, 0.4574430558698882, 0.4580099251102341, 0.46118699096038096, 0.46173281361238216, 0.4632936532727968, 0.4658257532231247, 0.4667820772311879, 0.4675073005628534, 0.46773978666095983, 0.4686834794319409, 0.47289196563318214, 0.4747415812184167, 0.4759677310116559, 0.47639945284738827, 0.47746028326794676, 0.4780469965214361, 0.4790700631033512, 0.4792600899145375, 0.47980947674844554, 0.4816348465348623, 0.4822643612521922, 0.48250042023536066, 0.4846015870188647, 0.48534241342648843, 0.487273605738224, 0.4883642821049229, 0.4898902875011748, 0.49255363388025786, 0.4946751895912833, 0.49604783867988655, 0.5005682301331646, 0.5011529991820097, 0.501763999500727, 0.502490876826932, 0.5063303093542678, 0.5077676848175917, 0.51096422469238, 0.5129221647747657, 0.5146410168401129, 0.5217401158047765, 0.5227601415618698, 0.5231430206971652, 0.5235387287606005, 0.5235864852214529, 0.5245933921499263, 0.5257115795687395, 0.5259935715168441, 0.5262784603382027, 0.5272261808398002, 0.5287244190984357, 0.5299915229264187, 0.5302562370093162, 0.5304813346543663, 0.5315994646044309, 0.532675886761555, 0.5349447516993556, 0.5353868311910291, 0.5368272832486582, 0.5385544881126874, 0.5395562204955051, 0.5406685591994572, 0.5415335754307422, 0.5417653496071662, 0.5425343685322515, 0.5440207242400631, 0.5446168645193924, 0.5448276575451868, 0.5455851826691478, 0.5467005205567683, 0.5469632513713881, 0.5484997216514768, 0.5489804494416418, 0.5493426449027576, 0.5525136147827252, 0.5546573480350956, 0.5555805472487985, 0.5558847535036677, 0.5564562058254564, 0.5578132255110699, 0.5599419534906013, 0.561255678074924, 0.5627116990223392, 0.5644923745278093, 0.5646757785447638, 0.5689131373767106, 0.5703914078676366, 0.5718091636071537, 0.5719122038506007, 0.5757031141151119, 0.5764724375577539, 0.5773108866038105, 0.5811954237209566, 0.5821438075777985, 0.5829844261646024, 0.5835569673248185, 0.5846680901658248, 0.5848386316888821, 0.5899478828018088, 0.5902855429531597, 0.591222738770868, 0.5918809431740769, 0.5933259300014169, 0.5940827805697124, 0.5948032146777896, 0.5970957701867198, 0.5986939757802878, 0.5990582375269533, 0.5996275684599214, 0.600899811926277, 0.6025518431009084, 0.6032031529136835, 0.6045657320070856, 0.6054117575075872, 0.6063709444333756, 0.6089572369418256, 0.6096310116569019, 0.6101002537089194, 0.6102406125735079, 0.6148798800974999, 0.6159573616088996, 0.6171557833956468, 0.617931559846298, 0.6189481930077215, 0.6196994401994157, 0.6215235765141309, 0.6226863385936764, 0.6240071100586886, 0.6250291860852057, 0.6264570196769271, 0.6279500527726358, 0.6320154860204185, 0.6322663491948901, 0.6329063306784342, 0.633072653499513, 0.6350891059097188, 0.6354436456595226, 0.6358872249895006, 0.6360707637298251, 0.6363546410805504, 0.637090837080905, 0.6378770926636339, 0.6396055611776819, 0.6426746576724236, 0.6444702771210337, 0.6457637595552255, 0.6465392594532176, 0.6475164648433631, 0.6481949935896475, 0.6504252488238643, 0.6511099249581764, 0.6540757953719981, 0.6575603127780231, 0.6580825847491903, 0.6581962945078175, 0.6589099755257795, 0.6596199073333251, 0.6617368946676516, 0.6630352742825435, 0.6643261669609404, 0.6668544210142678, 0.6668666605509217, 0.6679006346068636, 0.6700325378075668, 0.6716187721149189, 0.6741765392295153, 0.6746078529162162, 0.6761082314144111, 0.6769002983336627, 0.6778919957708145, 0.6795499271339084, 0.6807558929604856, 0.6816694824016201, 0.6818955530965279, 0.6828042832346014, 0.6853953434460057, 0.6862934879479348, 0.6881009199957195, 0.6900000628282107, 0.6913012566268047, 0.6933351537347067, 0.6959697275520004, 0.696805940538954, 0.6977562760734295, 0.6995106143995676, 0.7019243494751772, 0.7036079931247166, 0.7060190076640246, 0.7074849089292582, 0.7108847166823191, 0.7144107636265983, 0.7171988693295003, 0.7217215527171793, 0.7221779272182656, 0.7245168513986181, 0.727529230225095, 0.7286340364609895, 0.7298603088484784, 0.7304924774822994, 0.7308180287118088, 0.7321226068429558, 0.7327473702064047, 0.7339807219946193, 0.7346125908118054, 0.7351045527632666, 0.7362398101338331, 0.7375657490928268, 0.7392947351647732, 0.7431161523542852, 0.7456780188216833, 0.7466428299403386, 0.7498507644364663, 0.7514529444593436, 0.7528684453386081, 0.753594630745753, 0.7540230349283823, 0.7556600592135339, 0.7577687821754331, 0.7596176113005162, 0.7616758762136626, 0.7628555340222888, 0.7641424008563129, 0.7653465582241507, 0.7665885239716433, 0.767960171098894, 0.7697490792894853, 0.7708280487858379, 0.7725905041386211, 0.7735721017307203, 0.7742722761608726, 0.7751097831840875, 0.7764893026510181, 0.7789366285462715, 0.7803997761472745, 0.7807260380761243, 0.7823883294600873, 0.7838426767676738, 0.7853719267411972, 0.7877130155277087, 0.7888875288338638, 0.7892185506453118, 0.7894922984240523, 0.7901580051435906, 0.791463540889519, 0.7920936337605432, 0.792690996812442, 0.7944808178535061, 0.7964216224536396, 0.7970636324250978, 0.7997187639648612, 0.800588402241465, 0.8013479918738086, 0.8021305581275875, 0.8040956696335928, 0.8060461327322251, 0.8087395820854133, 0.8092740124091053, 0.8109604752724683, 0.8146272209174885, 0.8171927633430995, 0.8183695664813373, 0.8219266359399297, 0.8239045286694053, 0.8252861082328968, 0.8259177073160304, 0.8273565548261456, 0.828488133895241, 0.8293324051412837, 0.8306885105200769, 0.83136770622197, 0.8316630440808698, 0.8318818716007041, 0.8332043565966744, 0.8353725302842461, 0.8372630071385088, 0.8385492149028282, 0.8409749962597387, 0.8416960998943857, 0.843618195596552, 0.8476704105354645, 0.8493125129991662, 0.849391896781726, 0.8495342154879013, 0.8518412368739476, 0.8529819953305915, 0.8561324990137434, 0.8582256064728981, 0.8610452995033119, 0.8613196258150908, 0.8624762251829846, 0.8669334683518837, 0.8675953865035454, 0.8681692953265041, 0.868410787941382, 0.8689442522791451, 0.8696060824747774, 0.8701735510482824, 0.8706338814834905, 0.8711512879997452, 0.8726305265521189, 0.8729037597815608, 0.8733366617238478, 0.8737288628922681, 0.8747794404831686, 0.8772394571622004, 0.877566101641059, 0.8797527734883244, 0.8819921697216359, 0.8824594404560998, 0.883809043474554, 0.8842986818196978, 0.8852030727487199, 0.8865591828960833, 0.8888874240036297, 0.8908903682342503, 0.8935945864501316, 0.8941467641220912, 0.8951919350024279, 0.8958626420797126, 0.8976746726779566, 0.9003212680742715, 0.9012627931173341, 0.9015830052870676, 0.9027055104453562, 0.9037575717751422, 0.9046283977269414, 0.9055388379289011, 0.9059638955657336, 0.9063275792940898, 0.9077152079267428, 0.9078320415275677, 0.9081291122899553, 0.909278297765069, 0.910187845717226, 0.9108026709698133, 0.9112326058922315, 0.9160804641785706, 0.9172845384756465, 0.9182079996227752, 0.9232771731471148, 0.9235200445006869, 0.9242542746031159, 0.928317532848577, 0.9301709654384246, 0.9308072973164898, 0.9325445893524509, 0.9327307404762548, 0.9341882393094235, 0.9381142983195248, 0.9399317919698225, 0.9404485057361726, 0.9409061099217467, 0.9415453858914461, 0.943174822961285, 0.9439823053632096, 0.9473952495864468, 0.9482515377900793, 0.9491121430894405, 0.9497855683095447, 0.9505031465063334, 0.9546807210391054, 0.9550385584084489, 0.9552215494953318, 0.9562643741200305, 0.9573228878945872, 0.9611594157101652, 0.9620184367101465, 0.9662434107067982, 0.9691420956919276, 0.9699786678509281, 0.9707499576706702, 0.970844813977911, 0.9727763228920858, 0.9745918113353297, 0.9751799759755083, 0.9755015517323476, 0.977067188731958, 0.9779648397024958, 0.9794791852706748, 0.9799736440741755, 0.9812363743443039, 0.984257087004323, 0.9853038322872855, 0.9872851100131065, 0.9882752710001314, 0.9905460327701334, 0.9916960733724518, 0.9917728809792494, 0.9943341854704327, 0.9956378335948083, 0.9968321514192983, 0.9970781570816617, 0.9974159851550176, 0.9976824520951861, 0.9995439187190943, 0.9996674938795106, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001120111480109487, 0.017515990862062236, 0.03418776593915818, 0.05792046055879829, 0.08816396504008894, 0.10552006903193256, 0.12844871809319136, 0.14780646665299224, 0.1812143566429063, 0.22470117697268, 0.23579209395920986, 0.2557209344050444, 0.2772656456967736, 0.31195199049513045, 0.33836764962885324, 0.3836122604056218, 0.39920155355780196, 0.4336553339563889, 0.44699854740804157, 0.47018259269666507, 0.4817396333236078, 0.5225191916345231, 0.5326025194007621, 0.5437789079973993, 0.5628346111831735, 0.5974758626319301, 0.6044848301509848, 0.6157420219422428, 0.6325405332263061, 0.6676853746448911, 0.7242853081264119, 0.7474722179245807, 0.7613099686989825, 0.8336224130677277, 0.8542434317552483, 0.8905324013208848, 0.9088355095938083, 0.938482973760765, 0.9572702629833256, 0.963346832820399, 0.9987681648335741, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0\u001b[0m\n",
      "\u001b[34m, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_severity\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.708649298633216,\n",
      "      \"sum\" : 5817.30209248007,\n",
      "      \"std_dev\" : 0.7496594210374982,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 2.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 3643.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 209.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 209.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 224.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 203.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 2090.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.4,\n",
      "            \"count\" : 34.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.4,\n",
      "            \"upper_bound\" : 1.6,\n",
      "            \"count\" : 52.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.6,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 49.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.0,\n",
      "            \"count\" : 1496.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 1.0, 0.0, 0.932232585316978, 0.4453865259778722, 0.0, 0.0, 0.1337075640178187, 0.0, 0.5848750604652789, 0.014330905867001253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8372372182218181, 0.0, 0.0, 1.374670040295767, 0.0, 0.0, 1.0, 0.0, 1.0, 0.38510260282302966, 0.8548057787992615, 1.0, 0.8835647283701904, 0.27061999469359665, 0.0, 0.474434893620735, 0.0, 0.0, 0.5532906396230001, 0.520449404165286, 0.99458198903526, 0.7981581646362419, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.6696085263343835, 0.0, 0.0, 0.4515655866055751, 0.0, 0.0, 0.0, 0.7567580902469283, 0.6805581617791014, 2.0, 0.9408941791243455, 1.0, 0.27121377774342403, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8301274055955237, 0.0, 0.6688535108358502, 0.0, 2.0, 1.0, 0.42038090277186335, 0.02221848202558041, 1.0, 0.9585719111806122, 0.0, 0.0, 0.0, 0.8852464005861646, 0.5095914808144868, 0.16950409186605864, 2.0, 0.0, 0.20778342096169145, 1.0, 2.0, 2.0, 0.0, 0.5629484781578123, 0.3722545851026636, 2.0, 1.0, 0.0, 2.0, 0.9616158070461657, 0.730243334357868, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.810468217215466, 1.2726506473124846, 0.0, 0.0, 0.5218843281579432, 0.0679732998194037, 0.18122556104970955, 0.042803036480765444, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.6328026106615069, 0.0, 0.0, 0.0, 0.2698265466893234, 0.0, 1.0, 0.12757017457137088, 0.5909148513651238, 1.0, 0.3028298889787422, 0.2691203766777923, 0.2992744787157362, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.775397559925115, 0.0, 0.17250125836432662, 1.0, 0.0, 0.0, 0.6993394662526431, 0.0, 0.0, 1.0, 0.19575560640562462, 1.0, 0.0, 0.0, 0.0, 0.0, 0.06092872172071995, 2.0, 1.817248834012564, 0.0, 1.0, 0.09198491062502578, 0.0, 0.9086911974553298, 0.0, 0.10467597053553335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12537534923387328, 0.0, 0.0, 0.0, 0.0, 0.8783046932733277, 0.0, 0.0, 0.37303156547128347, 1.0, 0.3883535806100076, 0.0, 0.2557437015483004, 0.327420958733448, 0.0, 0.0, 1.0, 0.38473257650744497, 1.0, 0.40595053443318885, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9853910028911171, 1.3603754923631706, 0.0, 0.3874512959225387, 0.0, 0.30880227534961535, 0.7064652075413396, 0.0, 0.6672191310392045, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8670719572920174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.9753820161587614, 0.7905442304904889, 0.41626278068790734, 0.0, 1.0, 0.040288945734542114, 2.0, 0.0, 0.9316979736811688, 0.0, 0.8037552360117627, 0.0837249378453484, 0.6140604890630726, 0.0, 0.0, 0.15137117126327493, 0.0, 0.0, 0.0, 0.81754195934751, 0.9652096385457352, 0.0, 0.0, 0.27388874065536306, 1.0, 0.0, 0.7934189837782192, 1.0, 2.0, 2.0, 0.0, 0.5234071850674719, 0.0, 0.812077611008679, 0.17478862874036893, 0.0, 0.0, 1.0, 0.143161357811193, 1.0, 0.0, 0.02556979908973467, 0.0, 1.0967518949048696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07379479811565492, 0.0, 0.785083657239757, 0.273698457678371, 0.08818137131390835, 0.09750769246387525, 0.0, 0.0, 2.0, 0.6693569842407483, 0.0, 2.0, 0.0, 0.06368476750251673, 0.0, 0.0, 0.0, 0.0, 0.317347394955801, 0.7643771488083516, 0.0, 1.0, 0.7105591050317918, 0.0, 0.0, 1.0, 1.402160013154315, 1.0, 1.353162771073619, 0.3750202516239648, 2.0, 0.6928543518957885, 0.0, 0.04052781704458808, 0.21771251297815153, 2.0, 0.19453503316848408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6921258747256326, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.7056353963689815, 0.9221919280512842, 0.0, 2.0, 0.0, 0.0, 1.0, 0.6738921474874265, 0.0, 0.34979606180759193, 0.0, 0.23307281189083495, 1.0, 0.0, 2.0, 0.0, 0.022410039654956804, 0.41737135395963443, 0.004525847653185644, 0.0, 0.7784827278868942, 0.056162009903313104, 0.0, 0.0, 1.0, 0.0, 0.0, 0.03326797116935842, 2.0, 0.0, 1.0, 1.6032449435444707, 0.0, 0.0, 0.0, 0.46993754494826756, 0.0, 1.0, 0.0, 0.0, 0.14675753080288245, 0.6735465781313908, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.311571739582229, 2.0, 0.0, 0.0016437571124496841, 0.0, 2.0, 0.5212951420344775, 0.0, 0.8945947140438331, 0.0, 0.5129793498209074, 0.0, 0.0, 1.2471513441177937, 0.0, 2.0, 0.0, 0.7681587082852736, 0.0, 0.30770281338984384, 0.7578253496525295, 1.0, 0.7440285803476767, 1.0, 0.23449947767409374, 1.250620983275844, 1.082159116906447, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6865139430432525, 0.8150721006758068, 0.0, 0.22681649874124177, 1.328412257061074, 2.0, 0.534966673409444, 0.0, 0.1919321828839774, 0.0, 0.0, 0.7205546926810974, 0.0, 0.11349747335809746, 0.0, 0.13707760648901102, 1.7329249925436676, 1.0, 2.0, 1.6741186573842097, 2.0, 0.8781204982186164, 0.0, 0.0, 0.06864866614787224, 0.0, 0.0, 0.0, 0.5375846256925658, 1.0, 0.0, 0.0, 0.7760754122034105, 0.0, 0.0, 0.0, 0.8078656456839812, 0.7374099443119462, 0.46295868525802575, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.08419241664932775, 0.0, 1.0, 0.6737178484310535, 0.9792419678760358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.5171487255898952, 0.0, 0.0, 0.0, 1.4975343502372345, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.654725348498443, 0.0, 0.0, 0.0, 0.4014976105648763, 0.20687146203694362, 0.779491212863352, 0.0, 0.0, 0.7901023704137693, 0.0, 1.030384061095662, 0.0, 0.0, 2.0, 0.0, 2.0, 0.5036886093282389, 0.0, 0.0, 0.37975864573108786, 2.0, 0.0, 0.23203002193816846, 0.0, 0.0, 0.4502824838315258, 1.4688905036624724, 0.0, 0.0, 0.30343859785595384, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6888105035899871, 2.0, 1.0, 0.0, 0.0, 0.0, 0.5643953803389896, 0.06704337447177267, 0.4134882189625513, 0.0, 1.0, 0.7126656189865445, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.41236648727468106, 1.0, 0.0, 1.0, 1.0, 0.36039404005411124, 0.0, 0.0, 0.0, 0.7929429166169671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6571610351945493, 0.8885123121612181, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4006270071280137, 0.20126378813447243, 0.0, 0.8850936566380897, 1.0, 0.5020081977391821, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.12737411451410363, 0.0, 0.0, 0.0, 0.0, 2.0, 0.17061484985762543, 1.1903369750950477, 0.08277940817513718, 0.0, 0.0, 0.43085827538227073, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9374930584895892, 0.0, 0.5834215190184351, 0.0, 2.0, 0.0, 0.6617038454813468, 0.21912606467080087, 0.0, 1.0, 0.48468951693630746, 0.0, 0.0, 0.0, 0.0, 0.6042223203395692, 0.0, 2.0, 0.2996686838414908, 2.0, 0.0, 0.0, 0.680672373225737, 2.0, 0.0, 0.0, 0.0, 0.0, 1.6420388054672355, 1.0, 0.38769515483900674, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.6905872051295556, 0.06327544414650987, 0.5156765510770731, 0.0, 0.0, 0.10815501457335674, 1.0, 0.38586682381248194, 0.0, 0.0, 2.0, 0.41608071073886466, 0.0, 0.8514057478914739, 0.0, 1.6439069148335783, 0.0, 0.0, 0.8276751947812718, 0.0, 0.0, 0.0, 0.0, 0.2864737377445836, 0.4819228348024389, 0.0, 0.0, 2.0, 2.0, 0.7387435096159303, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.8115720043515481, 1.0, 0.9426896899895132, 0.8254101487528136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7211323573568237, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8131476551679849, 0.0, 0.7744194946063033, 0.0, 1.0, 0.0 ], [ 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.325061204894064E-4, 0.0037377134751231944, 0.004519509295742963, 0.005351358440002119, 0.008257382832161153, 0.009453967229866578, 0.010568234220368455, 0.016159687144562174, 0.018346676147552143, 0.019483177998893986, 0.020353284966116547, 0.021938182026471464, 0.027580000959896656, 0.030392273151904625, 0.032645677545668605, 0.03617683912152636, 0.04305240271566857, 0.04485356802356866, 0.047202472398705675, 0.049496853493666615, 0.050559187959538954, 0.05280396046852809, 0.05488581124399128, 0.057016183183957514, 0.060942904032812883, 0.06290897154120523, 0.06581176069057648, 0.06669388140544885, 0.07424087298838644, 0.07970281878059227, 0.08103861046505678, 0.08305795179908415, 0.08676731957854367, 0.0875912974059464, 0.08986536321786576, 0.09216795847243231, 0.0927510556435942, 0.09305719116516609, 0.0936724207059102, 0.09446116207109889, 0.09756251023929974, 0.10173837270729402, 0.10274825245242336, 0.10536753395280596, 0.10810689674343743, 0.11034796698243365, 0.11196093563988219, 0.11344081710391674, 0.1147969272512801, 0.11726561932657797, 0.12243389835894103, 0.12459437487816571, 0.12627707981777492, 0.1284022727117694, 0.1299299245357013, 0.13074037534894745, 0.13361348574865795, 0.13659923314299816, 0.1375237748170154, 0.13895470049668812, 0.1426910976391591, 0.14798414736583476, 0.1506874870008338, 0.15672190906359762, 0.16161981128587144, 0.1645921691578741, 0.16530228613796127, 0.16605252148153637, 0.16984901700208188, 0.17098226745450895, 0.17211060282277768, 0.17325323197375297, 0.17567310812073078, 0.17807336406007035, 0.18059459817530088, 0.18301544423472715, 0.19013981263941382, 0.191190701464789, 0.19192071764417007, 0.19281068120881195, 0.193410657673723, 0.19415546738216694, 0.2029363675749022, 0.2040246657385787, 0.21119773609464043, 0.21302986508233368, 0.21552986879133185, 0.21751507543606208, 0.21838452080360093, 0.21965213725984145, 0.21981073151700503, 0.22106337145372845, 0.22320951659277288, 0.22554132992573261, 0.2264611084654361, 0.22674118440694457, 0.2281422738183787, 0.23276314710128876, 0.23480913544421533, 0.24347796840486724, 0.24757223738442746, 0.24832382797708075, 0.2507162873042236, 0.2522056502406276, 0.253223360466282, 0.25482050463038564, 0.26290344956794875, 0.2645158039888382, 0.2673647652991672, 0.2691819712881912, 0.2750188300759475, 0.27809951506635644, 0.278457546373573, 0.279745967769071, 0.28191904290472913, 0.28800534592404115, 0.2909862757129682, 0.29231167366938127, 0.299748040555479, 0.30168884277242725, 0.3024474782893799, 0.30420252234455514, 0.30869874337319525, 0.3099999371717893, 0.312271786048796, 0.31313900232497094, 0.313206261070174, 0.31755457986950175, 0.32245905449646595, 0.32301119838621384, 0.3240177244136446, 0.3283577184539702, 0.3334625935960105, 0.3347078980219448, 0.3373109541512276, 0.3375324658838189, 0.344781420072647, 0.34592044750169426, 0.34923145244125264, 0.3522868289370785, 0.35509709470764406, 0.3567687116232726, 0.36039443882231814, 0.36369312475614024, 0.3697912516708558, 0.37142200187304575, 0.3759928899413114, 0.3786555027464704, 0.3803005598005843, 0.38050224859241233, 0.3810084353014118, 0.3827811941220992, 0.3870787603356308, 0.3923937215284745, 0.39413604678262815, 0.39570796357379256, 0.39744683615713505, 0.39883602970372944, 0.4009417624730467, 0.4035145250145784, 0.4042492718110433, 0.4116554604567024, 0.413520907811293, 0.4148151193889472, 0.4178561924222015, 0.42026883386580793, 0.4214440415792474, 0.42281476328825185, 0.423944812913302, 0.42466794857378254, 0.4273571468844154, 0.4315351014920601, 0.4353709490027369, 0.4355076254721907, 0.4372883009776608, 0.44123405537560234, 0.44218677448893007, 0.4436719927429207, 0.44564331878363095, 0.4468880289416285, 0.44812286357881437, 0.45394684810835706, 0.4592654328668958, 0.46299251164864164, 0.46381424972767993, 0.46991537203359535, 0.4737215396617973, 0.47892680949161215, 0.4815493402758543, 0.4876996531129194, 0.49027575324830186, 0.4925990052218141, 0.49750912317306795, 0.5011529991820097, 0.5061075548467509, 0.5066726489827458, 0.5074463661197421, 0.5116253710170613, 0.5146410168401129, 0.5197042628944842, 0.5206455598621482, 0.5231430206971652, 0.5235166162217073, 0.5252584187815833, 0.5271028671890952, 0.5291326437768232, 0.532675886761555, 0.5381565187248897, 0.5425343685322515, 0.5438057278662374, 0.5466852550992888, 0.5474148403797259, 0.5480323566642401, 0.5492237161136362, 0.5496062685307567, 0.5519903021207211, 0.5556346507584856, 0.5572830332204729, 0.5587762863446735, 0.5618276535880123, 0.5636599710287622, 0.5660716464481651, 0.5704040564239353, 0.573929022373903, 0.5792663538205268, 0.5809320532627977, 0.5832574924561156, 0.5850784422062031, 0.5902607635570609, 0.5923671420203442, 0.5930280903657361, 0.5970469168956917, 0.5985543690868064, 0.6011026956243283, 0.602821222570789, 0.6040716770712192, 0.6081417035909211, 0.6098318054986945, 0.6107707306850386, 0.6124047685172305, 0.6133798273661658, 0.6139794562733938, 0.6148798800974999, 0.6172490208487257, 0.6190904744890128, 0.6209085902177081, 0.6218992302125492, 0.6230144580737199, 0.6243277481182735, 0.6267401855372411, 0.6325441099658279, 0.6363546410805504, 0.6375686773841709, 0.6379607933159701, 0.6473973940711418, 0.6495867499898026, 0.6539940923398012, 0.656336807390897, 0.6583254981030792, 0.6594551645201031, 0.6665926778408895, 0.6673503980464284, 0.6720560387522534, 0.6732464393545315, 0.6737017335421565, 0.674746094075448, 0.6783918855030131, 0.6820174486596651, 0.6846261942649663, 0.6874063641362376, 0.6889975052673197, 0.6899154616572449, 0.6927610381522795, 0.6995106143995676, 0.7013832855596901, 0.7037923109905077, 0.7057332633628857, 0.7094124401936449, 0.7117484228326315, 0.7132358680833368, 0.7146412749087242, 0.7171205684721935, 0.7184292298187352, 0.7202964615285208, 0.7215605917495654, 0.7243444063295397, 0.7297119064974222, 0.7311532575471567, 0.7313165197032963, 0.7341488633456865, 0.7345779231214132, 0.7380691233385172, 0.7406261488943705, 0.7434237860766093, 0.7439524348950457, 0.745860038627012, 0.7466428299403386, 0.7537340704280046, 0.754107680316164, 0.7562705174756582, 0.7574818847894174, 0.7623090320219387, 0.7651603288167663, 0.7685193645237912, 0.7692053460734682, 0.7\u001b[0m\n",
      "\u001b[34m732726176700367, 0.7760174541349188, 0.7767366144948037, 0.7809638636444353, 0.7830166373167329, 0.7837494718134711, 0.7839873586893554, 0.786522382390847, 0.7867695033571274, 0.790014841559882, 0.7950187904731836, 0.7962405955628543, 0.805441676814699, 0.8139769999943344, 0.8167569301195281, 0.8218064439010868, 0.8228290747281345, 0.823767395799123, 0.8264880901957624, 0.8279139675473736, 0.8306885105200769, 0.8330689291824985, 0.8363161985346985, 0.843618195596552, 0.8448623274896327, 0.8479278837633485, 0.8493238922901226, 0.8503985504730475, 0.8514486375512653, 0.8525849549383427, 0.8560580864277691, 0.8598238353912759, 0.8621147306439896, 0.863009046067227, 0.8646861920335402, 0.8658201652223552, 0.8689442522791451, 0.870399348804558, 0.8728002373125504, 0.8736135775943329, 0.8756171687586757, 0.8772617628261795, 0.8792686599978382, 0.8814507796750214, 0.8860433652856828, 0.8888628526679876, 0.8935945864501316, 0.8960407996572191, 0.9062430793544434, 0.9124513359722194, 0.9167916907023351, 0.9214421690762729, 0.9245224687318999, 0.9256373300253358, 0.9263454335026835, 0.9292573980072293, 0.9308072973164898, 0.9316658951543958, 0.9353833201559139, 0.9389964220859776, 0.9404485057361726, 0.9415453858914461, 0.9425313075201167, 0.9439823053632096, 0.9446657321710952, 0.948099056412691, 0.9503127529305917, 0.9535350978515088, 0.9547053563869226, 0.9580145710904118, 0.9602340350114305, 0.9671903758713916, 0.9716887255973322, 0.9747626541517358, 0.9778585245273705, 0.9820543214315082, 0.9844916693734078, 0.9863014495910855, 0.9865973735678344, 0.9876595923412518, 0.9897564134093346, 0.9900863760674821, 0.9916960733724518, 0.9933178707761122, 0.9942814186392107, 0.9965656562889824, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.005315834803513, 1.0141946791497942, 1.0296682230647398, 1.0334524834479177, 1.0597791944287152, 1.0644912712491674, 1.0698290345615753, 1.0806125954273273, 1.110977524585148, 1.113109819076573, 1.1183375176672872, 1.135037394884798, 1.136864462264261, 1.1493197393951537, 1.1579255626014207, 1.170236879712355, 1.174867804071296, 1.2002820863812804, 1.206010283631994, 1.212873397398396, 1.230055299748321, 1.2556449978092723, 1.2838284470235202, 1.293078518906435, 1.324859938850332, 1.3330348718053984, 1.3382631053323484, 1.3694190584169077, 1.3886633977833531, 1.3978830146452204, 1.4114950648410112, 1.4350156423247464, 1.4351803992553567, 1.4398177416250881, 1.4463868902631947, 1.4604437795044949, 1.4700084770735813, 1.4747602424798398, 1.4865976622437531, 1.4931615681795174, 1.4999198817284174, 1.5217447054240762, 1.5330320000363893, 1.5388330987460899, 1.545081110492413, 1.550091940458156, 1.5609044347491716, 1.5713694530295244, 1.5895042059394453, 1.5942907505617747, 1.6030395550532832, 1.609631011656902, 1.613676826923534, 1.6285914323498591, 1.6440266262051473, 1.6580825847491902, 1.6643767270220882, 1.6777844965553717, 1.693948536477212, 1.707484908929258, 1.710135431798066, 1.7177375295870672, 1.725627200274416, 1.7286340364609893, 1.7340297625893064, 1.747838574412072, 1.7809958936149914, 1.7837723890172492, 1.790337735860148, 1.8011437222247042, 1.8167232025585447, 1.8216479329617712, 1.8316630440808699, 1.8337919509188274, 1.8440191363010667, 1.84841570713012, 1.8581203942511035, 1.8839773186518307, 1.8888874240036297, 1.9032980143757106, 1.9135753892374536, 1.9299964878669342, 1.9393710739335317, 1.9454999760983698, 1.957657721227616, 1.9690623552686581, 1.975033777879943, 1.979782457854522, 1.9963982936790554, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003346362042979223, 0.01842771873821747, 0.09116449040619168, 0.13271465381927738, 0.1794973234238334, 0.24336419621506533, 0.25252778207541926, 0.32313065707027855, 0.3478767544695621, 0.37429676713979265, 0.41158736665939455, 0.443818264960243, 0.4843984475740406, 0.5433005233632884, 0.5816002113323473, 0.597274072430341, 0.6502941858734539, 0.741311669302092, 0.7713748384750765, 0.8187856433570937, 0.8401215027412188, 0.8837096696607526, 0.9275837278536585, 0.9746998518706899, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.102193619693719, 1.4658128070202485, 1.5967386388761682, 1.775804735792956, 1.9816323630594601, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_id\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.022863221501173158,\n",
      "      \"sum\" : 187.68418530313045,\n",
      "      \"std_dev\" : 0.13916730517450318,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7964.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 18.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 131.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.06462183869288274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32761018720129553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8353794867634952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3679807915775636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7950580176061312, 0.6762691743895763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4772000794179613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3879914700405447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43757062588207907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9572603939380486, 0.0, 0.0, 0.8281234878640757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7877143583314087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34223461672739997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6985369405411993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4991989468413318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2748888400666839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6803844137625221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19287056868961427, 0.0, 0.0, 0.0, 0.10137984246986353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7074262751619323, 0.2882220550090505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8636296725324342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03808630059931928, 0.056825177038715036, 0.06850540662697957, 0.07597312957426716, 0.09644155656746967, 0.10232532732204336, 0.11982900201764635, 0.12237675732517794, 0.1519841147505986, 0.17424340164537955, 0.1959043303664072, 0.21056780580480883, 0.2368916363986917, 0.2695036390412098, 0.2756123386789454, 0.2828011306704997, 0.3211022749221595, 0.3790271262190974, 0.38551422248836875, 0.4059172194302876, 0.441957674851033, 0.4530367486286119, 0.4782598841952235, 0.5138507345765979, 0.5224441454054645, 0.5257115795687395, 0.5332179227688121, 0.5368272832486582, 0.5419777883317413, 0.5494142384304533, 0.5814193783760647, 0.5941418627564575, 0.6016821640182961, 0.6057553031390567, 0.632238150867861, 0.6697572206635947, 0.6868609976750291, 0.6900965582378434, 0.6976706275200751, 0.7366842162467999, 0.7409812502745785, 0.7902470523163186, 0.7945985915219707, 0.8343033659547675, 0.8646603921404177, 0.8943065200937259, 0.9223853552685591, 0.9425459396769053, 0.9562221906489483, 0.9673820516584335, 0.9841768280031792, 0.9981201164750894 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03418776593915818, 0.35925074791624556, 0.4159073661469408, 0.6768693429297215, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_na\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.1811784314549733,\n",
      "      \"sum\" : 1487.2937438138758,\n",
      "      \"std_dev\" : 0.3457976749968297,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 6159.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 150.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 119.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 135.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 148.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 149.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 162.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 141.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 134.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 912.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.06810902472352254, 0.2181743295932732, 0.0, 0.0, 0.4453865259778722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5216645183294442, 0.9789788932737828, 0.0, 0.0, 0.0, 0.0, 0.8372372182218181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244161608716153, 0.0, 0.38510260282302966, 0.14519422120073855, 0.0, 0.1164352716298096, 0.7293800053064033, 0.0, 0.0, 0.9926658491638197, 0.025809392863181735, 0.5532906396230001, 0.47955059583471404, 0.0, 0.2018418353637581, 0.0, 0.0, 1.0, 0.22218875554154927, 0.0, 0.0, 0.0, 0.4511931914507237, 0.3303914736656165, 0.5892146143478555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7567580902469283, 0.6805581617791014, 0.0, 0.9408941791243455, 0.6907263151132631, 0.0, 0.0, 0.0, 0.9088593605553225, 0.2859005337712024, 0.6723898127987045, 0.0, 0.0, 0.6688535108358502, 0.23402842514482092, 0.0, 0.0, 0.5796190972281366, 0.0, 0.0, 0.041428088819387754, 0.967802737648485, 0.0, 0.9631590270650665, 0.8852464005861646, 0.4904085191855132, 0.0, 0.0, 0.38247088493768844, 0.0, 0.0, 0.0, 0.0, 0.7816325580532472, 0.0, 0.0, 0.0, 0.0, 0.3249227944066413, 0.0, 0.0, 0.26975666564213197, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.18953178278453398, 0.7273493526875153, 0.7315621195611339, 0.0, 0.5218843281579432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9408229281364582, 0.0, 0.23107995542883164, 0.0, 0.011078552594309676, 0.7301734533106766, 0.0, 0.0, 0.12757017457137088, 0.4090851486348762, 0.6456228170138647, 0.0, 0.7308796233222077, 0.0, 0.0, 0.0, 0.34985438418085446, 0.0, 0.0, 0.0, 0.6849894928165754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04331527325431195, 0.3006605337473569, 0.0, 1.0, 0.5875969395321339, 0.19575560640562462, 0.5131750822820359, 0.0, 0.0, 0.6826945225795135, 0.08804041580036681, 0.93907127827928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24257826607382516, 0.9086911974553298, 0.6813103960094764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6383529051589555, 0.0, 1.0, 0.0, 0.0, 0.4945211251204079, 0.8783046932733277, 0.0, 0.6839223161567359, 0.0, 0.8083948823040229, 0.0, 0.29574756259502066, 0.0, 0.327420958733448, 0.8353794867634952, 0.8188281491499799, 0.0, 0.0, 0.5640048194294142, 0.40595053443318885, 0.0, 0.06737687152192573, 0.0, 0.17732655322393942, 0.7230716360496688, 1.0, 0.0, 0.0, 0.9853910028911171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7064652075413396, 0.0, 0.6672191310392045, 0.0, 1.0, 0.0, 0.19228218001852038, 0.0, 0.0, 0.018945403374354575, 0.0, 0.2083995736183316, 0.0, 0.6384887847991355, 1.0, 0.05711716337044326, 1.0, 0.0, 1.0, 0.02461798384123859, 0.20945576950951106, 0.41626278068790734, 0.0, 0.0, 0.0, 0.0, 0.680479462524374, 0.0, 0.0, 0.19624476398823731, 0.0, 0.0, 0.0, 0.0, 0.8486288287367251, 0.0, 0.32855814988579846, 0.0, 0.18245804065249005, 0.9652096385457352, 0.42818393986717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31326647658061035, 0.0, 0.0, 0.9931853020998719, 0.0, 0.9215133919074179, 0.18792238899132097, 0.17478862874036893, 0.0, 0.0, 1.0, 0.856838642188807, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8123907241861509, 0.0824059718619482, 0.0, 0.48564686533427714, 0.0, 1.0, 0.0, 0.0, 0.0, 0.08818137131390835, 0.0, 0.0, 0.0, 0.0, 0.6693569842407483, 0.23127992831595545, 0.0, 0.0, 0.0, 0.17712714419825404, 0.0, 0.0, 1.0, 0.0, 0.0, 0.05642585596482286, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3071456481042115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6360473423391266, 0.5982068648905755, 0.0, 0.6921258747256326, 0.0, 0.0, 0.0, 0.9324889235898018, 1.0, 0.5977762651528876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13924684459410952, 0.3879914700405447, 0.0, 0.6738921474874265, 0.07091595948797924, 0.0, 0.8624965074015853, 0.766927188109165, 0.6951874662100657, 0.6296283449385927, 0.0, 0.0, 0.022410039654956804, 0.5826286460403656, 0.9954741523468144, 0.0, 0.0, 0.056162009903313104, 0.0, 0.0, 0.0, 0.1674597445179885, 0.0, 0.9667320288306416, 0.0, 0.41586133940794756, 0.0, 0.39675505645552933, 0.4740062659484451, 0.0, 0.1308251425969127, 0.5300624550517324, 0.0, 0.0, 0.18237662169551383, 0.10494339600016689, 0.0, 0.32645342186860915, 0.8626382540313258, 0.0, 0.9539369363180226, 0.0691759250098859, 0.0, 0.0, 0.688428260417771, 0.0, 0.0, 0.0016437571124496841, 0.0, 0.0, 0.47870485796552253, 0.0, 0.0, 0.0, 0.5129793498209074, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.7055627116496911, 0.0, 0.0, 0.07300359289962732, 0.0, 0.0, 0.23449947767409374, 0.749379016724156, 0.917840883093553, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4522024791035387, 0.0, 0.31348605695674747, 1.0, 0.8774521266031688, 0.0, 0.671587742938926, 0.0, 0.534966673409444, 0.03769772491485279, 0.1919321828839774, 0.6792754755400424, 0.0, 0.2794453073189026, 0.0, 0.11349747335809746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8781204982186164, 0.9817249302764938, 0.0, 0.06864866614787224, 0.9918891959474917, 0.04860313802089389, 0.0, 0.0, 0.0, 0.5718448269698801, 0.06142512925983268, 0.7760754122034105, 0.0, 0.5613524997539452, 0.0, 0.8078656456839812, 0.0, 0.0, 1.0, 0.0, 0.7088991127733161, 0.0, 0.6853710910648012, 0.3259824651160327, 1.0, 0.0, 0.7179326909401018, 0.7163920765828637, 1.0, 0.0, 0.0, 0.042739606061951374, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7877143583314087, 0.8844416233193683, 0.8364209229856395, 0.5024656497627655, 0.0, 0.0, 0.0, 0.6059261954142473, 0.0, 0.12158413695503834, 0.0, 0.7545369159024605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.170178735282715, 0.0, 0.0, 0.0, 0.11822241207245987, 0.5985023894351237, 0.7931285379630564, 0.779491212863352, 0.0, 0.0, 0.0, 0.0, 0.969615938904338, 0.0, 0.6995965330235282, 0.0, 0.11582308223679427, 0.0, 0.5036886093282389, 0.17084935971586013, 0.4918582813348057, 0.6202413542689121, 0.0, 0.0, 1.0, 1.0, 0.6332632016094104, 0.5497175161684742, 0.0, 0.0, 0.8259409191119182, 0.6965614021440462, 0.07592701115431688, 0.8203240881472009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4259975194684281, 0.0, 0.6577653832726, 0.4356046196610104, 0.0, 0.0, 0.47391748158259706, 0.0, 0.7126656189865445, 1.0, 0.5286917254258788, 0.0, 0.6217754847566552, 0.0, 0.0, 0.8006545105288169, 0.0, 0.0, 0.5757858627744116, 0.0, 0.0, 0.6396059599458888, 0.08707120557730819, 1.0, 0.0, 1.0, 0.4560268887150325, 0.0, 0.0, 0.6027285271595403, 0.24555062594449106, 0.0, 0.0, 0.8885123121612181, 0.0, 0.0, 0.0, 0.7597805667916144, 0.5562286609077549, 0.7176320809573438, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8902366217957709, 0.1149063433619103, 0.0038371455078008987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4991989468413318, 0.0, 0.8726258854858964, 0.0, 0.0, 0.30858394248684795, 0.0, 0.0, 1.0, 0.0, 0.9172205918248628, 0.446441467337642, 0.0, 0.5691417246177293, 0.0, 0.2748888400666839, 0.0, 0.16706260768133896, 0.9857682495857412, 1.0, 0.39861592931143663, 0.6607797016082162, 0.4554045512892506, 0.9589318272095946, 1.0, 0.0, 0.0, 0.06250694151041081, 0.6125335361782434, 0.0, 0.0, 0.0, 0.5197057412086442, 0.6617038454813468, 0.21912606467080087, 0.0, 0.59643395462566, 0.48468951693630746, 0.9731323459550647, 0.6195181145069641, 0.0, 0.4686431682473048, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.680672373225737, 0.0, 0.5109707430450621, 0.0, 0.0, 0.9779141546988203, 0.0, 1.0, 0.6123048451609933, 0.86163179911181, 0.0, 0.0, 0.0, 0.5076376964803742, 0.0, 0.14444887656412753, 0.0, 0.0, 0.06327544414650987, 0.4843234489229269, 0.502746113409122, 0.8215839034365042, 0.10815501457335674, 0.0, 0.6141331761875181, 0.3258245840194487, 0.0, 0.0, 0.0, 0.0, 0.8514057478914739, 0.08426436615585109, 0.0, 0.6803844137625221, 0.0, 0.0, 0.0, 0.2109771554518658, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8365308907609035, 0.0, 0.0, 0.0, 0.3062678870046147, 0.7349187156614274, 0.0, 0.19287056868961427, 0.09271481081026989, 0.0, 0.0, 0.8986201575301365, 0.0, 0.0, 1.0, 1.0, 0.0, 0.7074262751619323, 0.2882220550090505, 0.8983552751676653, 0.41731385344541716, 0.1241073677137774, 0.0, 0.7211323573568237, 0.0, 0.0, 0.0, 0.0, 0.7511809729800681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25747897614372484, 0.0, 0.0, 0.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.325061204894064E-4, 0.0018798835249106416, 0.003090781410644672, 0.0036017063209445865, 0.005026552609803114, 0.008257382832161153, 0.009453967229866578, 0.010090606689024728, 0.012714889986893518, 0.015742912995676983, 0.018763625655696115, 0.020449159618243118, 0.022895766948426655, 0.02452697168597817, 0.025237345848264203, 0.02583537137198444, 0.029233793525217044, 0.03273641247363446, 0.03593867492155334, 0.042291749222681196, 0.04267711210541281, 0.04367990661247245, 0.04377780935105169, 0.04496144159155113, 0.04545250043579596, 0.05021443169045525, 0.050887856910559526, 0.05239129559486122, 0.05335556600645375, 0.05607171652354215, 0.057280251077623356, 0.058727551758148366, 0.06100714300539489, 0.06310903307915017, 0.06919270268351019, 0.07161649436369255, 0.07189816449021347, 0.07574572539688407, 0.08220706371178166, 0.08503413492203138, 0.08884024508756438, 0.08991624485970229, 0.0913741048604092, 0.09216795847243231, 0.09342778932783724, 0.09393411431363474, 0.09446116207109889, 0.0957290547443973, 0.09729448955464381, 0.09870398922535117, 0.10173837270729402, 0.10232532732204336, 0.10493471114875419, 0.10559154597664, 0.10640541354986843, 0.11006328420111522, 0.11113714733201241, 0.11344081710391674, 0.11557572449802289, 0.11726561932657797, 0.1177414439051524, 0.11956199775205645, 0.12322265417216605, 0.12535647579238562, 0.12627113710773186, 0.12689115723577238, 0.12736419745316474, 0.12745395942286897, 0.12960065119544195, 0.12994137226794122, 0.13105574772085493, 0.13196531962396174, 0.13264457760095316, 0.13356133247235458, 0.13699906305367138, 0.13801309159572772, 0.14017616460872406, 0.14177439352710186, 0.1438143503148137, 0.14479301498163, 0.14798414736583476, 0.1504657845120987, 0.150608103218274, 0.15177540985110205, 0.15513767251036725, 0.15638180440344795, 0.15830390010561435, 0.1590250037402613, 0.16493405454498, 0.16679564340332564, 0.16811812839929585, 0.16833695591913023, 0.16885420667768614, 0.17129495782167037, 0.173185026203581, 0.17609547133059467, 0.1771709252718655, 0.1817232932281565, 0.18537277908251149, 0.18903952472753172, 0.19081682886096896, 0.19455832318530097, 0.19809551672028958, 0.199411597758535, 0.20065101740376123, 0.20357837754636043, 0.20730900318755796, 0.20853645911048102, 0.20975294768368136, 0.21078144935468823, 0.21111247116613618, 0.21347761760915296, 0.21462807325880284, 0.21927396192387572, 0.22190046078437287, 0.22642789826927967, 0.22740949586137893, 0.22917195121416212, 0.23178359028935003, 0.23276314710128876, 0.23465344177584935, 0.2368916363986917, 0.237517115524447, 0.23832412378633738, 0.2400707404875665, 0.2403823886994838, 0.2422312178245669, 0.24251811521058264, 0.24347796840486724, 0.24640536925424705, 0.24751007314041196, 0.24997158785780882, 0.25108010366516775, 0.2560475651049543, 0.2590187497254215, 0.2626756425986517, 0.2644718166671908, 0.2672526297935953, 0.2695036390412098, 0.27136596353901055, 0.2754831486013819, 0.2768505135353705, 0.2828011306704997, 0.28481354521975877, 0.2855892363734017, 0.2891152833176809, 0.2925150910707418, 0.29507234926430936, 0.29639200687528344, 0.30085310835325507, 0.30228369244670705, 0.30319405946104605, 0.306051463522788, 0.30752979549045634, 0.30883442400734085, 0.31296084941751945, 0.3146046565539943, 0.31810444690347206, 0.3204500728660916, 0.3225265851765271, 0.32387460241170973, 0.32415225353566357, 0.32525390592455194, 0.3299674621924332, 0.3322055709473216, 0.33314557898573216, 0.3369647257174565, 0.3375324658838189, 0.3405448354798969, 0.34167450189692083, 0.34184728549809207, 0.34243968722197693, 0.34366319260910305, 0.3479069381183494, 0.3495747511761357, 0.3518949654658766, 0.3524835351566369, 0.35423624044477453, 0.35552972287896634, 0.35833465667167375, 0.3609678410850792, 0.36346135324664564, 0.3638096411409335, 0.36411277501049943\u001b[0m\n",
      "\u001b[34m, 0.3645563543404774, 0.36709366932156584, 0.3677336508051099, 0.36791017049375774, 0.37324115637923383, 0.37354298032307287, 0.3765302877892983, 0.3774803042702548, 0.3803005598005843, 0.381227922958995, 0.3832842396422014, 0.38551422248836875, 0.3898723529415441, 0.39012023468833923, 0.3905936075817822, 0.3936290555666244, 0.3962030080709039, 0.3969604449467167, 0.39916679451101955, 0.4009417624730467, 0.40244663743366893, 0.4040111578165182, 0.4057092494382253, 0.40667406999858313, 0.40798315721093714, 0.40877726122913205, 0.4097392364429391, 0.41516136831111794, 0.41533190983417523, 0.41644303267518146, 0.41779124023176883, 0.41880457627904344, 0.4229593355380892, 0.4242968858848881, 0.4289849318408905, 0.43108686262328944, 0.4344500350785596, 0.4353709490027369, 0.4363400289712378, 0.4403115551620601, 0.44123405537560234, 0.4435437941745436, 0.44411524649633227, 0.4506864749389131, 0.4511613432799413, 0.4530367486286119, 0.4544148173308522, 0.4551723424548132, 0.4553831354806076, 0.45746563146774855, 0.45835358178324015, 0.45896347937729864, 0.4591892337325618, 0.46144551188731264, 0.46299251164864164, 0.46381424972767993, 0.46497449540106717, 0.4667820772311879, 0.4677424688510239, 0.46840053539556914, 0.4695186653456337, 0.469641774680709, 0.46991537203359535, 0.4712755809015643, 0.4740064284831559, 0.4764135147785471, 0.4769152754182153, 0.47755585459453553, 0.4782598841952235, 0.4870778352252343, 0.49141817752855677, 0.4922323151824083, 0.49350099215440824, 0.4973124461689724, 0.49823600049927297, 0.4992890741633287, 0.5004773158667182, 0.5046190246076956, 0.5074463661197421, 0.5116357178950771, 0.512726394261776, 0.5146575865735116, 0.5153984129811353, 0.517596301315522, 0.5182761764476463, 0.5199526226899144, 0.5206455598621482, 0.5208167705564001, 0.5225397167320532, 0.5240322689883441, 0.5266237972689596, 0.5307373552868359, 0.5330320000363893, 0.5333922153027841, 0.5353581018426609, 0.5367063467272032, 0.538813009039619, 0.5415335754307422, 0.5425569441301118, 0.5448477590845157, 0.5455821217920664, 0.5474148403797259, 0.5493803432702421, 0.5495836567221436, 0.5504717771029405, 0.5511469283252918, 0.5520693646533779, 0.5537987790224563, 0.554356681216369, 0.5583523150641136, 0.5644945456018406, 0.5654199676077424, 0.5684648985079399, 0.5725043496432408, 0.5740622915330605, 0.5772497307686131, 0.5810150933751095, 0.5838785719289077, 0.5842024993125499, 0.5850784422062031, 0.5854839351832077, 0.5861725346792042, 0.588135259582504, 0.5886254285874106, 0.5902326591508927, 0.5930145003605977, 0.594248831384939, 0.5953596612586041, 0.5972924203534693, 0.5985543690868064, 0.6006095425462361, 0.6021169853547795, 0.602553163842865, 0.6038509825402779, 0.6047940736900298, 0.6076062784715255, 0.6123264052496058, 0.6141254971048841, 0.6151963827788968, 0.6164281773718701, 0.6194977514075877, 0.6209085902177081, 0.6218992302125492, 0.6243277481182735, 0.6247400955573337, 0.6265374038558266, 0.6284534886801256, 0.6300398784799822, 0.6320898295062423, 0.6346392564873805, 0.6363068752438598, 0.6401682238281661, 0.6401983115596238, 0.6416319088273545, 0.6448683522461874, 0.6451586397431096, 0.6466004439486619, 0.6497970089092697, 0.6514263327580295, 0.6531140236356144, 0.6543750064235985, 0.6551823922538302, 0.6582175952632383, 0.6591137644695265, 0.6625196743251018, 0.6626890458487724, 0.6649945162377737, 0.6664304505277996, 0.6673503980464284, 0.6714246695306144, 0.6737017335421565, 0.6743151979360468, 0.6771524124576737, 0.677540945503534, 0.6791991512011694, 0.6799726834376081, 0.6807558929604856, 0.6819504274490813, 0.6834132400913489, 0.6837541055770425, 0.6857005429336439, 0.6868367981702229, 0.6880159796735815, 0.6889975052673197, 0.690405721911072, 0.6921136179837506, 0.6954156483280532, 0.69662727121739, 0.6995106143995676, 0.7012171289457484, 0.7031307254397192, 0.7061585021190541, 0.7076883263306187, 0.7084896974927973, 0.7094124401936449, 0.7121687011483941, 0.712845995860955, 0.7176357859086295, 0.721542453626427, 0.7222473762507389, 0.7242425955587187, 0.724856499315017, 0.729234742913643, 0.7311573444549172, 0.7324138648126686, 0.736200425060762, 0.7394082298313118, 0.7428249749063163, 0.743256503690242, 0.7451794953696144, 0.745753379076126, 0.7477943497593724, 0.7521286995435712, 0.7546212215985918, 0.760841222217757, 0.7628933355543641, 0.7649627851961749, 0.7658290392349099, 0.7674486416346199, 0.7704472210739898, 0.7735388915345639, 0.7737247491834002, 0.7747762977315102, 0.7769379384572431, 0.7797746986226849, 0.78019465117681, 0.780731853200901, 0.7813488406144062, 0.7817401273062705, 0.7830166373167329, 0.7839398837552336, 0.784499241132449, 0.7848618229588802, 0.7867083407073091, 0.7888022639053596, 0.7914116322589493, 0.7934072581478373, 0.7938138354815736, 0.7945985915219707, 0.7959753342614213, 0.7963328622273151, 0.7989012725573326, 0.801684293191305, 0.8048028354281175, 0.8061958810037908, 0.8082175444081394, 0.8085723195004575, 0.8088679115511032, 0.809183171139031, 0.8106859279862663, 0.8121571474622259, 0.8132767042269585, 0.8194817716075764, 0.8236064207981895, 0.8259183246885707, 0.8281168290063428, 0.8340989756292138, 0.8347579495573968, 0.8363161985346985, 0.8394609095007669, 0.8399639802821826, 0.8423255047499341, 0.8447894362860214, 0.8470161991714373, 0.8503985504730475, 0.8517825379006754, 0.8547034500931975, 0.8573089023608409, 0.8595652316469458, 0.8643116822077207, 0.8649198537742393, 0.8676276209650275, 0.8692596246510526, 0.8715977272882306, 0.8720483384470077, 0.8738749555210183, 0.8748747428582531, 0.8767674242836752, 0.8785046089122346, 0.8798219139516953, 0.8814507796750214, 0.8821356142820601, 0.8830764644746085, 0.8857142300020205, 0.886890180923427, 0.8887912526617813, 0.8911066860189609, 0.8936627026517728, 0.894265118256414, 0.8957267259261729, 0.8990588000224785, 0.9014170729775877, 0.9035584434325303, 0.9056725737089564, 0.9103736608450579, 0.9129310047746899, 0.9147311149565036, 0.916603301642411, 0.9187347106063773, 0.9202971812194077, 0.9228548314604181, 0.9235831405619486, 0.925178794805027, 0.9269163463311081, 0.9292573980072293, 0.9300683942905659, 0.9310099708852998, 0.9334723917891448, 0.9343078835103408, 0.9368597070726087, 0.9373784381643208, 0.9405284311327192, 0.9423153896731928, 0.9447774792569715, 0.9471960395314719, 0.9519076895879646, 0.9532141550282315, 0.9535350978515088, 0.9547508109811121, 0.9585008328169206, 0.9616657359548132, 0.9638231608784736, 0.9685781784887271, 0.9720252564965911, 0.9760326986002038, 0.9796467150338835, 0.984234499234434, 0.9867489664960895, 0.9885075267018847, 0.9894317657796315, 0.9905460327701334, 0.9912938529374564, 0.9946486415599979, 0.9961229496394411, 0.9968590939518779, 0.9986537290434363, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009072404652724964, 0.0724162721463415, 0.11836286722964984, 0.15734065970252598, 0.17419333657825364, 0.24630116594948082, 0.2941679733434779, 0.33637046382842206, 0.3911697660803798, 0.413031174647697, 0.44877757383140304, 0.5048448818930178, 0.5584126725831979, 0.5987139801001076, 0.6521232455304379, 0.7248265598740583, 0.77529882302732, 0.8306425177506246, 0.8841989781315029, 0.934373855425987, 0.9658122340608418, 0.9866929803571616, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_side\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.22251943052505865,\n",
      "      \"sum\" : 1826.6620051802065,\n",
      "      \"std_dev\" : 0.37842192339330555,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 5797.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 148.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 139.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 152.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 143.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 156.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 123.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 150.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 178.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 1223.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.06462183869288274, 0.533883707341511, 0.0, 0.0, 0.7526002529416542, 0.0, 0.0, 0.0, 0.9856690941329987, 0.47833548167055584, 0.021021106726217154, 0.0, 0.8248537674871036, 0.0, 0.7166359311088818, 0.0, 0.0, 0.37380810886700244, 0.625329959704233, 0.987658953939626, 0.0, 0.0, 0.755838391283847, 0.0, 0.0, 0.0, 0.04758469400335641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9027637879645087, 0.47510001327416174, 0.5488068085492763, 0.0, 0.0, 0.0, 0.5484344133944249, 0.0, 0.0, 1.0, 0.0, 0.31944183822089856, 0.8339251476664863, 0.0, 0.0, 0.728786222256576, 0.0, 0.0, 0.0, 0.0, 0.32761018720129553, 0.16987259440447633, 0.0, 0.3311464891641498, 0.0, 0.41367867898526034, 0.0, 0.42038090277186335, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11475359941383545, 0.0, 0.0, 0.0, 0.0, 0.7922165790383086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6277454148973364, 0.0, 0.8437550439872936, 0.0, 0.0, 0.03838419295383433, 0.0, 0.5101295232822555, 0.0, 1.0, 0.0, 0.9833241865101608, 0.0, 0.810468217215466, 0.0, 0.26843788043886607, 0.6278797847583013, 0.47811567184205683, 0.0, 0.8187744389502905, 0.9571969635192346, 0.890138053446914, 0.3477248891009498, 0.5403554026142626, 0.3242387071047762, 0.381389710906061, 1.0, 0.0, 0.0, 0.0, 0.9940816546455755, 0.0, 0.2698265466893234, 0.0, 0.0, 0.8724298254286291, 0.5909148513651238, 0.0, 0.0, 0.0, 0.2992744787157362, 0.41097990901908843, 0.06133518670662774, 0.0, 0.24380193771017955, 0.0, 0.0, 0.0, 0.0, 0.06915356771850123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3305610023062908, 0.0, 0.0, 0.0, 0.0, 0.1305045596374398, 0.0, 0.31730547742048654, 0.0, 0.0, 0.305982585894258, 1.0, 0.0, 0.0, 0.9080150893749742, 0.7574217339261748, 0.0, 0.3186896039905236, 0.0, 0.0, 1.0, 0.9390980669005067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.642086507352399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2557437015483004, 0.0, 0.0, 0.18117185085002008, 0.0, 0.615267423492555, 0.0, 0.0, 0.41034650484845236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2851004659086863, 0.5789776465541452, 0.0, 1.0, 1.0, 0.3874512959225387, 1.0, 0.6911977246503846, 0.0, 0.734002306907342, 0.0, 0.0, 0.0, 0.0, 0.8077178199814796, 0.0, 0.0, 0.0, 0.0, 0.7916004263816684, 0.13292804270798264, 0.0, 0.0, 0.0, 0.0, 9.294168699610639E-4, 0.0, 0.0, 0.0, 0.0, 0.6434286740491809, 0.0, 0.0, 1.0, 0.0, 0.0683020263188312, 0.0, 0.0, 0.9162750621546516, 0.0, 0.37394713447906747, 0.11371178354428235, 0.0, 1.0, 0.0, 0.05446604736683758, 0.81754195934751, 0.03479036145426484, 0.0, 0.3679807915775636, 0.7261112593446369, 0.0, 0.14722707441051697, 0.0, 0.0, 0.6360684203522257, 1.0, 0.0, 0.0, 0.0, 0.812077611008679, 0.0, 0.7950580176061312, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9744302009102653, 0.0, 0.09675189490486946, 0.7325847215278923, 0.0, 0.9175940281380518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9024923075361247, 0.1466707834412122, 0.3281600723536078, 0.9462276883380166, 0.0, 0.0, 1.0, 0.0, 0.0, 0.822872855801746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9435741440351771, 0.8712516273986526, 0.0, 0.21678454534332126, 0.19675509533519375, 0.0, 0.0, 0.0, 0.646837228926381, 0.0, 0.0, 0.0, 0.14032041491966707, 0.0, 0.7822874870218485, 0.9118478418633555, 0.0, 0.0, 0.6766446348198475, 0.0, 0.4017931351094245, 0.4221720284885643, 0.0, 1.0, 0.7930630283706559, 1.0, 0.0, 0.0, 0.4022237348471124, 0.0, 1.0, 0.9221919280512842, 0.0, 0.6957581361728042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34979606180759193, 0.0, 0.0, 0.0, 0.37037165506140735, 0.8634846083691153, 0.0, 0.0, 0.41737135395963443, 0.0, 0.0884852741341492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4625935471051531, 0.0, 0.8781119174677295, 0.0, 0.0, 0.0, 0.0, 0.5487333859268856, 0.0, 0.0, 0.0, 0.5892907546083338, 0.8176233783044862, 0.8950566039998331, 0.0, 0.0, 0.0, 0.7231300305079877, 0.046063063681977434, 0.0, 0.33920147030908965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5538234406337256, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7254933264929218, 0.0, 0.0, 0.0, 0.7390914219929531, 0.6865139430432525, 0.0, 0.0, 0.0, 0.0, 0.9682775081839688, 0.46503332659055596, 0.0, 0.8080678171160226, 0.0, 0.43757062588207907, 0.0, 0.7825001443802936, 0.0, 0.0, 0.0, 1.0, 0.5346609230755238, 0.0, 0.3258813426157904, 0.9540422650780858, 0.0, 0.0, 0.0, 0.9313513338521278, 0.0, 0.0, 0.8629790899636793, 0.4624153743074342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5370413147419743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6740175348839673, 0.0, 0.08419241664932775, 0.0, 0.0, 0.0, 0.0, 0.7608859776715097, 0.9572603939380486, 0.0, 0.0, 0.8281234878640757, 0.0, 0.0, 0.0, 1.0, 0.5171487255898952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19701869869089617, 0.0, 0.3940738045857527, 0.5037083870840707, 0.8784158630449617, 0.0, 0.24546308409753947, 0.44545292973428785, 0.5922213993314405, 0.29906463498200075, 0.0, 0.0, 0.0, 0.654725348498443, 0.4112040672118541, 0.33663746598531863, 0.8817775879275401, 0.4014976105648763, 0.0, 0.0, 0.1859615075574177, 0.0, 0.7901023704137693, 0.26091857965016807, 0.0, 1.0, 0.3004034669764718, 0.1470736161454187, 0.0, 0.29404376341999283, 0.4963113906717611, 0.8291506402841399, 0.0, 0.0, 1.0, 0.5218410764441559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2542823337952127, 0.0, 0.0, 0.0, 0.17967591185279908, 1.0, 1.0, 0.926308276921196, 0.3808319557569416, 0.0, 1.0, 0.5519363610604665, 0.0, 0.5740024805315719, 0.0, 0.34223461672739997, 0.0, 0.0, 0.0, 0.0, 0.7593108551502052, 0.0, 0.0, 0.47130827457412117, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5439731112849675, 1.0, 0.0, 0.3972714728404597, 0.7544493740555089, 0.8123261802470616, 0.34283896480545073, 0.11148768783878193, 0.5704094914036416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12338617298410837, 0.0, 0.6985369405411993, 0.5993729928719863, 0.7987362118655276, 0.0, 0.0, 0.0, 0.49799180226081785, 0.4168721765471307, 0.4210346797041956, 0.0, 0.3140438069184325, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.37575926300248186, 0.0, 0.8096630249049525, 0.0, 0.0, 0.0, 0.43085827538227073, 0.0, 0.7251111599333161, 0.20369933658486783, 0.0, 0.014231750414258837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.38746646382175665, 0.4165784809815649, 0.4642039489521267, 0.38079568270784514, 0.4802942587913558, 0.33829615451865325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10612558549099549, 0.0, 0.39577767966043076, 0.0, 0.1943977812297617, 0.0, 0.037897895834972495, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4287642911146835, 0.0, 0.0, 1.0, 0.0, 0.0, 0.13836820088819002, 0.26183172946315636, 0.856964414776239, 0.0, 0.0, 0.0, 0.8555511234358725, 0.41829111109348593, 0.0, 0.0, 0.5156765510770731, 0.0, 0.17841609656349577, 0.8918449854266433, 0.15789313751648837, 0.0, 0.6741754159805513, 0.0, 0.5554972801696314, 0.0, 0.20699360124505817, 0.0, 0.0, 0.0, 0.0, 0.2741203638192007, 0.0, 0.2601321733995965, 0.7890228445481342, 0.0, 0.14054712799554292, 0.7135262622554164, 0.0, 0.0, 0.0, 0.7043353159571805, 1.0, 0.0, 0.0, 0.0, 0.6961924503010899, 0.0, 0.9072851891897301, 0.0, 0.0, 0.10137984246986353, 0.20810867620427076, 0.8115720043515481, 0.0, 0.0, 0.0, 0.0, 0.7117779449909495, 0.0, 0.0, 0.0, 0.8785850944950279, 0.2788676426431763, 0.0, 0.6716145003833947, 0.0, 0.0, 0.0, 0.5921103914927199, 0.7203636815067938, 0.8636296725324342, 0.0, 0.18685234483201507, 0.0, 0.0, 0.6144464355986862, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8839955658189744E-4, 5.337517843693185E-4, 0.0038770503605588535, 0.006663062641371509, 0.010243586590665377, 0.011031614262465794, 0.012907227980991975, 0.013753328048598523, 0.01794567856849183, 0.02449844826765235, 0.025141958277272725, 0.027974743503408894, 0.029504055145205932, 0.030937644731341973, 0.031778484357324444, 0.034939246405988444, 0.03798156328985347, 0.04198542890958823, 0.04459490837296154, 0.04596687241495945, 0.04678584497176852, 0.04753288331215322, 0.04852144033400885, 0.049842027782941556, 0.05439074852231118, 0.057016183183957514, 0.059226700310499036, 0.059716488970889325, 0.06264670578413556, 0.06314029292739132, 0.06461667984408614, 0.06850540662697957, 0.0689900291147002, 0.06935752364804015, 0.07000351213306577, 0.07074260199277072, 0.07547753126810008, 0.07647995549931308, 0.07737694191221034, 0.07970281878059227, 0.0827154615243535, 0.08421176054587287, 0.08439238054454234, 0.08717946783183117, 0.09228479207325724, 0.09261983528715301, 0.09292914437938993, 0.0934079719752956, 0.09639215565320491, 0.09670198562428944, 0.0969062721234617, 0.09954651280877513, 0.10094119997752149, 0.10411581880734044, 0.10418540262811804, 0.10554744317576781, 0.11042338166950783, 0.1156234529770287, 0.1170117248579462, 0.1176439881593252, 0.11995369302388992, 0.12149539108776541, 0.12264438779473996, 0.12448877344738385, 0.12523357043282712, 0.12582931784297402, 0.1263864224056671, 0.12793692451178318, 0.1299299245357013, 0.13158921205861795, 0.133650581410518, 0.1411075940213511, 0.1426910976391591, 0.1451965128846603, 0.14577809365913197, 0.14741504506165726, 0.14840568069578097, 0.14960144952695253, 0.1519841147505986, 0.15298380082856267, 0.1555714368693023, 0.15767449525006594, 0.15802962850329128, 0.1603403442912097, 0.1617346404542951, 0.1652420504426032, 0.16562834702826534, 0.1673195306529568, 0.1706675948587163, 0.17264344517385444, 0.17328534006898166, 0.17408167531142926, 0.1748678040712962, 0.1775053507097729, 0.17844596522777212, 0.18020219501527246, 0.18173919070946298, 0.18214369434497046, 0.18301544423472715, 0.18345240115022932, 0.18672329577304148, 0.18974141330046868, 0.19121001543646154, 0.19230989603362747, 0.193410657673723, 0.19648189156506568, 0.20366713777268486, 0.20601028363199392, 0.20858836774105072, 0.21056780580480883, 0.2140747237910866, 0.21534438138255263, 0.21622761098275078, 0.21720909769121055, 0.21782873690875382, 0.21900410638500856, 0.22306206154275687, 0.22398254586508115, 0.22504187617087212, 0.22543875546369385, 0.22572772383912743, 0.22609377822933485, 0.2264611084654361, 0.22691095830253383, 0.232645538562681, 0.2350372148038251, 0.23642093113342744, 0.24064897424738696, 0.24365671606386663, 0.24690742666758558, 0.24787335872842364, 0.25057399401919134, 0.2533571700596614, 0.2537927425181614, 0.254139961372988, 0.2581732541911692, 0.2600136133143882, 0.26193087666148285, 0.2628197749927569, 0.26542207687858677, 0.26616801251553746, 0.2666751966619776, 0.2676007988617075, 0.26896803159538596, 0.27028809350257776, 0.270765257086357, 0.27437279972558415, 0.27782207278173443, 0.27843940825043456, 0.279415884176072, 0.28450909290072557, 0.2849612811493162, 0.28676413191666317, 0.2886855955306381, 0.2900291936489059, 0.291144247785179, 0.29231167366938127, 0.29316214421945885, 0.29672764110409, 0.29807565052482277, 0.30048938560043237, 0.30206050183479505, 0.30301750698203, 0.3061373408795932, 0.31100249473268027, 0.31654966526787, 0.3171957167653986, 0.31902517276175546, 0.3200273165623919, 0.3221080042291855, 0.3238917685855889, 0.3289447161400856, 0.3303973838660381, 0.3334073221591105, 0.33463479158109566, 0.33684050186110326, 0.34037063360525777, 0.34109002447422054, 0.3417824047367617, 0.34356047477570395, 0.34562499357640153, 0.34904266488192737, 0.3504132500101974, 0.35346074054678245, 0.3542594899043877, 0.3548608307461478, 0.35597103248839435, 0.3581400411446446, 0.36204573731526124, 0.36226808709859115, 0.36290916291909503, 0.36350934895084597, 0.3653607435126195, 0.36588580955688044, 0.36882935404329364, 0.3707011939892638, 0.3715659525810011, 0.37497081391479425, 0.3765221694807036, 0.3773136614063236, 0.3795029033747186, 0.3814729412818144, 0.3835002731049165, 0.38559999256867616, 0.3870998391380508, 0.38962250468167237, 0.39312265842307004, 0.39570796357379256, 0.3967805897866278, 0.3999052068041562, 0.4013060242197122, 0.4014\u001b[0m\n",
      "\u001b[34m4563091319363, 0.40244663743366893, 0.4060118017061106, 0.40763285797965576, 0.4091325587289585, 0.4148151193889472, 0.4161453676406067, 0.41701557383539756, 0.4252204457355848, 0.426070977626097, 0.4275018313281117, 0.4281908363928463, 0.4293503761190651, 0.431112405097005, 0.4351803992553568, 0.4355076254721907, 0.43874432192507595, 0.43981774162508813, 0.44059457427264304, 0.44164768493588635, 0.4427169667795271, 0.4433065095171753, 0.4443653492415144, 0.448813645746606, 0.4495282228970595, 0.4501233611819322, 0.45047857147059533, 0.45086966372282733, 0.4531240341239554, 0.45330367170366015, 0.45441787820793356, 0.4561942721337626, 0.4592654328668958, 0.46116690125391, 0.46660778469721587, 0.4677424688510239, 0.4686834794319409, 0.47273481908474346, 0.47449537803136, 0.47643642047014423, 0.47685697930283477, 0.4775189594838817, 0.4791832294435999, 0.48534241342648843, 0.48709758385280244, 0.4883642821049229, 0.4941476706378827, 0.49943176986683535, 0.5007109258366713, 0.5011529991820097, 0.501763999500727, 0.5021536099619869, 0.5026875538310276, 0.5074009947781859, 0.5097242467516981, 0.51096422469238, 0.5129221647747657, 0.5183651534651377, 0.520296576918654, 0.5221215519777576, 0.5224441454054645, 0.5245933921499263, 0.5258125988733238, 0.5270286539044898, 0.5287244190984357, 0.5296809458982144, 0.5304813346543663, 0.531661023764483, 0.5332513992791025, 0.5359333105954953, 0.5368272832486582, 0.5406685591994572, 0.5415335754307422, 0.5419777883317413, 0.5430214308667641, 0.5440165791827516, 0.5440207242400631, 0.5448276575451868, 0.5455851826691478, 0.5460531518916429, 0.5477846943833194, 0.5483031807683173, 0.5491303362771727, 0.5536131097368052, 0.5546877097800863, 0.5569406376695789, 0.558042325148967, 0.5588494477693676, 0.559578854465342, 0.5616150199692387, 0.5625552012730474, 0.5627116990223392, 0.5656385018587823, 0.5662150157526166, 0.5686193512259253, 0.5703914078676366, 0.5732231944495915, 0.5764724375577539, 0.5771852367117482, 0.5802215187850294, 0.5832574924561156, 0.585264173032529, 0.586479092188707, 0.5899478828018088, 0.5941418627564575, 0.5970469168956917, 0.5975533625663311, 0.598112629369018, 0.5990582375269533, 0.599771314970498, 0.600899811926277, 0.6021169853547795, 0.6032031529136835, 0.6057553031390567, 0.6061465649334797, 0.6081760367165, 0.6113366022166469, 0.6167157603577986, 0.6172490208487257, 0.6192390320535817, 0.6196994401994157, 0.6226863385936764, 0.6296030137246935, 0.630700471158785, 0.6322663491948901, 0.6334117402421271, 0.6354436456595226, 0.6363546410805504, 0.6370947008244425, 0.6382897451404194, 0.6444702771210337, 0.6457637595552255, 0.6475164648433631, 0.6511099249581764, 0.6536782314109965, 0.6588250701400705, 0.6617368946676516, 0.6642017130717857, 0.6651461942384054, 0.6697572206635947, 0.6728471334885447, 0.6741768824355502, 0.6751400611496681, 0.6774734148234729, 0.6789189029129499, 0.6816694824016201, 0.6817486440901612, 0.6820174486596651, 0.6853953434460057, 0.6878036317823963, 0.6890710699924458, 0.6900965582378434, 0.6938055569674118, 0.6948823736759592, 0.6972754190538569, 0.6991468916467449, 0.7026449517631611, 0.7043454583875147, 0.7066755336776999, 0.7101147663372793, 0.712777676216831, 0.7166952375750694, 0.7202964615285208, 0.7206322860652836, 0.7215605917495654, 0.7217215527171793, 0.7231494864646295, 0.7249811699240525, 0.7268388310482375, 0.7288525634998152, 0.7308180287118088, 0.7318609799044866, 0.7330511898599934, 0.7340297625893063, 0.7355056064875376, 0.74056472325951, 0.7406261488943705, 0.7431161523542852, 0.7443550021907277, 0.7451177510851177, 0.7460622280763038, 0.7489198963348322, 0.7524277626155725, 0.7530925733324144, 0.7548378199408478, 0.7565220315951328, 0.7582672920560591, 0.7586763901110049, 0.7628555340222888, 0.7653465582241507, 0.7685193645237912, 0.7691708108459879, 0.7713055905996352, 0.7767366144948037, 0.7792545115472183, 0.780189268482995, 0.7835000808452567, 0.7850977140957076, 0.7863018584296716, 0.7876660257131087, 0.7891608465887314, 0.7925213919629192, 0.7927270209323324, 0.7939293858599648, 0.7983441882243283, 0.7992290252433214, 0.7994470221547335, 0.8003548790234066, 0.800754045591686, 0.8013479918738086, 0.8019044832797104, 0.8031121282243164, 0.805525913576057, 0.8067575637891261, 0.808809298535211, 0.8096751371809322, 0.812713619893062, 0.8146272209174885, 0.8157694046351072, 0.8182767067718435, 0.8186807200744948, 0.820012629119356, 0.8228074989888089, 0.8233094298207179, 0.8239045286694053, 0.826814973796419, 0.8281515186729055, 0.829017732545491, 0.8309382215602837, 0.83136770622197, 0.831863113251422, 0.8324171834102527, 0.8339474785184636, 0.8346977138620387, 0.8364984906180335, 0.8375308340760557, 0.8383801887141286, 0.8398203522034884, 0.841375855473622, 0.8420744373985792, 0.8476704105354645, 0.8525577819015535, 0.855034927620183, 0.8561324990137434, 0.8582256064728981, 0.8590403724782307, 0.8608841511089125, 0.8615645066706057, 0.8628805029124124, 0.863135537735739, 0.863641421296616, 0.8668549958219031, 0.8680346803760383, 0.8686505918550933, 0.8689442522791451, 0.8701735510482824, 0.8726358025468353, 0.8737288628922681, 0.8746435242076144, 0.8756171687586757, 0.8772617628261795, 0.879341020176528, 0.8816156398779976, 0.8835221503266629, 0.8842623933212946, 0.8870567915888264, 0.8870683573139887, 0.889192037820193, 0.8913182063602987, 0.8950652888512458, 0.8951919350024279, 0.8972517475475766, 0.8987400853848411, 0.9012960107746488, 0.9037575717751422, 0.9047663416801179, 0.9062430793544434, 0.9065722106721628, 0.9079012458004102, 0.909278297765069, 0.910187845717226, 0.9111597549124356, 0.9128924447365754, 0.9179763147885291, 0.9183327241399037, 0.920034605640698, 0.923431741566461, 0.9245610553768049, 0.929426694473114, 0.9306716696122352, 0.9309704591121504, 0.9327307404762548, 0.9389964220859776, 0.9399035896218298, 0.940220805571285, 0.9422970715841011, 0.9425459396769053, 0.9429838168160425, 0.9439282834764579, 0.9464855370869567, 0.948099056412691, 0.9492006931808914, 0.949899668246076, 0.9527975276012943, 0.9556122278291456, 0.9569475972843314, 0.9602340350114305, 0.963822275482351, 0.9663308217861273, 0.9673543224543314, 0.9686746055743571, 0.9692099503395522, 0.9703317769352602, 0.9715330423905887, 0.9741646286280156, 0.9755015517323476, 0.9761869749880837, 0.9812363743443039, 0.9819056980765392, 0.9823121903867428, 0.9841768280031792, 0.9858053208502058, 0.9900863760674821, 0.9905460327701334, 0.992442289374779, 0.9943341854704327, 0.9969092185893553, 0.9974159851550176, 0.9995572185627921, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005145170754714767, 0.041183495279271676, 0.1162903303392474, 0.14354236203939286, 0.15987849725878123, 0.17855927199013355, 0.2239997929645705, 0.2346740382615511, 0.2526490939608851, 0.31195199049513045, 0.3323146253551089, 0.3524263565980924, 0.3921512114451966, 0.396659776343562, 0.4119416219099208, 0.4574320977737073, 0.4766768283303684, 0.49327684678379957, 0.5335119252996956, 0.5613927835104616, 0.6009540538628889, 0.6532630192373301, 0.6779052977806647, 0.7085720046026294, 0.7339099189537017, 0.7474912503116178, 0.7600940784380972, 0.7996408564512874, 0.8404524062769335, 0.8521935333470078, 0.8755624427031437, 0.8949214412278399, 0.9275837278536585, 0.9730977480703464, 0.9891849098133589, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_fire\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.02422629894375482,\n",
      "      \"sum\" : 198.87368802928333,\n",
      "      \"std_dev\" : 0.14328712896328036,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7951.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 18.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 136.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.466116292658489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5248999867258383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41367867898526034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35254205925445403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.890138053446914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8172488340125641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1684592136623344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3603754923631707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9462276883380166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30424186382719576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03172249181603115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14123857016129604, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49753435023723447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47774212639953595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7381682705368436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5554972801696314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07140311846936165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01582109176558244, 0.04697997882110083, 0.06982903456157541, 0.0827154615243535, 0.1150356918194122, 0.13686446226426097, 0.14882573914722919, 0.16333664808905723, 0.193410657673723, 0.20106515204994513, 0.21308500868480817, 0.24952436683824863, 0.2697538529098541, 0.3061373408795932, 0.3321097833081246, 0.3714859436594342, 0.39788301464522047, 0.43054020950718996, 0.44042114553465805, 0.44984220797255925, 0.4759677310116559, 0.4920544893824006, 0.5085792894475785, 0.5183651534651377, 0.5245933921499263, 0.5313165205680591, 0.5460531518916429, 0.5843961040926645, 0.597672875313444, 0.599771314970498, 0.6126074143313407, 0.6288383852142582, 0.6451391692538522, 0.6784911686505812, 0.6995106143995676, 0.7074849089292582, 0.7256272002744159, 0.7298603088484784, 0.7375657490928268, 0.7478385744120718, 0.766656135200406, 0.7917202592613465, 0.8306885105200769, 0.8343716529717347, 0.8437373264067243, 0.851594319304219, 0.870399348804558, 0.895814597371882, 0.9287197299448361, 0.9430618974069715, 0.9554361765513208, 0.969062355268658, 0.9727499880491849, 0.9884159894120765, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03787802740795021, 0.14263990790750136, 0.4600941604977875, 0.5233231716696316, 0.608369859459644, 0.7677238880667803, 0.9572702629833256, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_liability\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.9890364234376904,\n",
      "      \"sum\" : 8119.0,\n",
      "      \"std_dev\" : 0.9068581350999193,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 3.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 2890.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 3054.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.5,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.1,\n",
      "            \"count\" : 1734.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.1,\n",
      "            \"upper_bound\" : 2.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.4,\n",
      "            \"upper_bound\" : 2.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.7,\n",
      "            \"upper_bound\" : 3.0,\n",
      "            \"count\" : 531.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0 ], [ 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3\u001b[0m\n",
      "\u001b[34m.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"collision_type_front\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.4049016001997199,\n",
      "      \"sum\" : 3323.8372360395006,\n",
      "      \"std_dev\" : 0.4468075516835439,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 4072.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 190.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 216.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 190.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 222.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 207.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 205.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 201.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 190.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 2516.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.49645301848811385, 0.0, 0.0, 0.9353781613071173, 0.466116292658489, 0.5546134740221278, 0.9854328452487211, 0.0, 0.1337075640178187, 1.0, 0.5848750604652789, 0.014330905867001253, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2833640688911182, 0.0, 0.0, 0.0, 0.374670040295767, 0.012341046060374006, 0.14296087760075216, 1.0, 0.0, 0.4019908826712504, 0.0, 0.0, 0.9524153059966436, 0.0, 0.0, 0.19416286904608226, 0.525565106379265, 0.0, 0.0, 0.0, 0.520449404165286, 0.005418010964740039, 0.0, 1.0, 0.0, 0.0, 0.7778112444584507, 1.0, 0.09723621203549127, 0.5248999867258383, 0.0, 0.0, 0.4107853856521445, 0.5457216032101775, 0.0, 0.9369278637311389, 0.01596848572086984, 0.0, 0.2432419097530717, 0.0, 0.1660748523335137, 0.059105820875654524, 0.0, 0.0, 0.9530270089018602, 0.07194824977115188, 0.09114063944467754, 0.7140994662287976, 0.0, 0.0, 0.9445841115577556, 0.0, 0.0, 0.5863213210147397, 0.3470270780920607, 0.0, 0.0, 0.01146001295429333, 0.9585719111806122, 0.03219726235151499, 1.0, 0.0, 0.0, 0.0, 0.8304959081339414, 1.0, 0.6175291150623116, 0.20778342096169145, 0.41230298171245405, 1.0, 1.0, 0.21836744194675284, 0.43705152184218765, 0.0, 1.0, 0.15624495601270638, 0.0, 1.0, 0.0, 0.0, 0.48987047671774453, 1.0, 0.0, 0.0, 0.016675813489839153, 1.0, 0.0, 0.2726506473124847, 0.0, 0.3721202152416987, 0.0, 0.9320267001805963, 0.18122556104970955, 0.042803036480765444, 0.10986194655308601, 0.0, 0.4596445973857374, 0.6757612928952238, 0.618610289093939, 0.0, 0.05917707186354182, 0.3671973893384931, 0.7689200445711684, 0.005918345354424481, 0.0, 0.0, 0.4282106840640195, 0.5659478239190433, 0.0, 0.0, 0.3543771829861353, 1.0, 0.0, 0.0, 0.5890200909809116, 0.9386648132933723, 0.6501456158191455, 0.0, 1.0, 1.0, 0.3150105071834246, 1.0, 0.9308464322814988, 0.8274987416356734, 1.0, 0.4730275033430207, 0.956684726745688, 0.6993394662526431, 0.6694389976937092, 0.0, 0.4124030604678661, 0.0, 0.0, 0.0, 0.44053915987299475, 0.0, 0.9119595841996332, 0.0, 0.694017414105742, 0.0, 0.31904507433223983, 0.584485936937934, 0.09198491062502578, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.06090193309949332, 0.0, 0.2855858985295022, 0.3616470948410445, 0.8746246507661267, 0.0, 0.357913492647601, 1.0, 0.5054788748795921, 0.12169530672667228, 0.588093637605447, 0.0, 1.0, 0.1916051176959771, 1.0, 0.7042524374049793, 0.7442562984516996, 0.672579041266552, 0.0, 0.0, 0.2093088980998321, 0.0, 0.0, 0.0, 0.0, 0.9326231284780743, 1.0, 0.0, 0.27692836395033116, 0.0, 0.7148995340913137, 0.0, 0.0, 0.0, 0.0, 0.6125487040774613, 0.0, 0.30880227534961535, 0.0, 0.0, 0.0, 0.5574049643141872, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9990705831300389, 0.0, 0.9753820161587614, 0.7905442304904889, 0.0, 0.3565713259508191, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8037552360117627, 0.0, 0.38593951093692735, 0.6260528655209325, 0.8862882164557176, 0.15137117126327493, 0.0, 0.6714418501142015, 0.0, 0.0, 0.0, 0.5718160601328272, 0.6320192084224364, 0.27388874065536306, 0.3669614070072005, 0.0, 0.0, 0.0, 0.36393157964777434, 0.0, 0.006814697900128119, 0.5234071850674719, 0.0, 0.0, 0.0, 0.20494198239386885, 0.0, 0.0, 0.0, 0.0, 0.3584314333150056, 0.0, 0.2120298664090684, 0.9032481050951305, 0.26741527847210766, 0.0, 0.0, 0.599967858261066, 0.5143531346657229, 1.0, 0.0, 1.0, 0.0, 0.726301542321629, 0.9118186286860916, 0.0, 0.8533292165587878, 0.6718399276463922, 0.053772311661983374, 0.0, 0.7687200716840445, 0.0, 0.6939528337712285, 0.06368476750251673, 0.0, 0.0, 1.0, 0.0, 0.317347394955801, 1.0, 0.0, 0.12874837260134742, 0.0, 0.7832154546566787, 0.8032449046648062, 1.0, 1.0, 1.0, 0.35316277107361904, 0.3750202516239648, 1.0, 0.0, 0.8596795850803329, 1.0, 0.21771251297815153, 0.08815215813664445, 0.0, 1.0, 0.0, 0.36395265766087337, 0.0, 0.0, 0.0, 0.0, 0.2069369716293441, 0.0, 0.06751107641019816, 0.0, 0.0, 0.5312101194932091, 0.0, 0.07780807194871575, 0.8580057406479153, 0.30424186382719576, 0.8607531554058905, 0.0, 1.0, 0.32610785251257346, 0.0, 0.6502039381924081, 0.0, 0.0, 0.30481253378993434, 0.0, 0.13651539163088466, 0.0, 0.0, 0.0, 0.0, 0.9115147258658508, 0.7784827278868942, 0.9438379900966869, 0.7443609062046385, 1.0, 1.0, 0.8325402554820115, 0.5374064528948469, 0.0, 0.12188808253227046, 0.0, 0.06312990920796646, 0.6032449435444707, 0.5259937340515549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14675753080288245, 0.6735465781313908, 0.13736174596867423, 0.27686996949201226, 0.0, 0.9308240749901141, 0.6607985296909104, 0.2536371156867585, 0.31157173958222895, 1.0, 0.7403967162915215, 0.0, 0.623585037479306, 0.0, 0.0, 1.0, 0.10540528595616694, 0.44617655936627443, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2944372883503089, 1.0, 0.7578253496525295, 0.9269964071003727, 0.0, 0.2889990380501888, 0.7655005223259063, 0.25062098327584403, 0.08215911690644695, 0.10802895749157926, 0.0, 1.0, 0.27450667350707825, 0.6246639742837168, 1.0, 0.5477975208964613, 0.0, 0.0, 0.0, 0.12254787339683115, 0.22681649874124177, 0.328412257061074, 0.03172249181603115, 0.0, 0.9623022750851472, 0.0, 0.3207245244599576, 0.5624293741179209, 0.0, 0.21749985561970642, 0.0, 0.0, 0.862922393510989, 0.0, 0.4653390769244762, 1.0, 0.6741186573842096, 0.04595773492191424, 0.0, 0.018275069723506232, 1.0, 0.0, 0.0, 0.9513968619791061, 0.13702091003632066, 0.0, 0.8150797025328557, 0.0, 0.9385748707401673, 0.22392458779658952, 1.0, 0.0, 1.0, 0.19213435431601877, 0.7374099443119462, 0.46295868525802575, 0.0, 1.0, 0.2911008872266839, 1.0, 0.0, 0.0, 0.0, 0.9158075833506722, 0.2820673090598982, 0.28360792341713625, 0.0, 0.9792419678760358, 0.0, 0.0, 0.1353476453972543, 0.0, 0.17187651213592425, 1.0, 0.0, 1.0, 0.0, 0.4828512744101048, 0.0, 0.11555837668063174, 0.16357907701436047, 0.49753435023723447, 0.985618764015847, 0.8029813013091038, 1.0, 0.0, 0.0, 0.0, 0.9525167896845986, 0.0, 0.0, 0.40777860066855953, 0.7009353650179992, 1.0, 0.44720103221643803, 0.829821264717285, 0.345274651501557, 0.5887959327881459, 0.6633625340146814, 0.0, 0.0, 0.0, 0.220508787136648, 0.0, 0.9508186599164314, 0.2098976295862307, 0.7390814203498319, 0.03038406109566205, 0.0, 0.0, 0.8529263838545813, 0.8841769177632057, 0.7059562365800072, 0.0, 0.0, 0.0, 0.37975864573108786, 0.0, 0.4781589235558441, 0.0, 0.0, 0.3667367983905896, 0.0, 1.0, 0.7457176662047873, 0.0, 0.30343859785595384, 0.9240729888456831, 0.0, 0.0, 0.0, 0.073691723078804, 0.6191680442430584, 0.0, 0.0, 0.4480636389395335, 0.0, 0.0, 1.0, 0.0, 0.5643953803389896, 0.06704337447177267, 1.0, 0.526082518417403, 0.0, 0.28733438101345554, 0.0, 0.0, 0.0, 0.37822451524334477, 0.0, 0.4131073977271442, 0.19934548947118313, 0.5876335127253189, 0.0722769475731766, 0.0, 0.8536545489411119, 0.27471291564544476, 0.0, 0.9129287944226918, 0.0, 0.5454903404948357, 0.0, 0.0, 0.0, 0.1510761305239272, 0.0, 0.0, 0.0, 0.6571610351945493, 0.0, 0.4295905085963584, 0.41843579556201127, 1.0, 0.24021943320838557, 0.4437713390922451, 0.28236791904265623, 0.9190462638843119, 0.8766138270158916, 0.0, 0.3014630594588007, 0.4006270071280137, 0.20126378813447243, 0.0, 0.0, 0.9961628544921991, 0.5020081977391821, 0.5831278234528693, 0.0, 0.05451192743782629, 0.0, 0.0, 0.7834208143727591, 0.12737411451410363, 1.0, 0.0, 0.691416057513152, 1.0, 0.6242407369975181, 0.0, 0.19033697509504754, 0.08277940817513718, 0.0, 1.0, 0.0, 0.687808116213612, 0.0, 0.7963006634151322, 0.832937392318661, 0.0, 0.0, 0.0, 0.0, 0.5445954487107494, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6192043172921549, 0.0, 0.0, 0.0, 1.0, 0.40356604537434004, 0.5153104830636925, 0.0, 0.38048188549303585, 0.0, 0.5313568317526952, 0.0, 1.0, 0.8056022187702383, 0.0, 0.9621021041650275, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.053781964177377906, 0.0, 0.0, 0.0, 0.38769515483900674, 0.0, 0.7381682705368436, 0.14303558522376103, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.497253886590878, 0.0, 0.0, 0.8421068624835116, 0.0, 0.0, 1.0, 0.4445027198303686, 0.5839192892611353, 0.0, 0.0, 0.9157356338441489, 1.0, 0.3196155862374779, 0.0, 0.0, 0.7398678266004035, 0.0, 0.0, 0.8594528720044571, 0.0, 0.0, 0.0, 0.16346910923909652, 0.29566468404281954, 0.0, 0.7387435096159303, 0.6937321129953853, 0.0, 0.3038075496989101, 0.8071294313103857, 0.0, 1.0, 1.0, 0.0, 0.7918913237957292, 0.18842799564845192, 0.0, 0.0, 0.1745898512471864, 0.0, 0.0, 0.10164472483233467, 0.5826861465545828, 0.0, 0.12141490550497214, 0.0, 0.18378466510790115, 0.0, 1.0, 1.0, 0.0, 0.40788960850728007, 0.0, 0.13637032746756583, 0.2719877422038026, 0.0, 0.7425210238562752, 0.22558050539369667, 0.38555356440131383, 0.5066857908540028, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.427814372078842E-4, 0.0013462709565636999, 0.002584014844982385, 0.005315834803512831, 0.00566581452956727, 0.006710390304059954, 0.008546432157207962, 0.008736773266366793, 0.009913623932517934, 0.011480659749377842, 0.01230970301607559, 0.01419467914979422, 0.01768780961325722, 0.018094301923460843, 0.020353284966116547, 0.021602721199404096, 0.024110193408666825, 0.024684157224584613, 0.027175016090844162, 0.028466957609411314, 0.0297646555851232, 0.030549457093379973, 0.03132539442564286, 0.03338360178638122, 0.0337565892932018, 0.038334264045186806, 0.03983221527125458, 0.041656818382682426, 0.04417551627924776, 0.045319278960894605, 0.046500586440065494, 0.047202472398705675, 0.049496853493666615, 0.05048894441240792, 0.0507993068191086, 0.051895299518410876, 0.05280396046852809, 0.05488581124399128, 0.055334267828904826, 0.057016183183957514, 0.0576129808977669, 0.05768461032680716, 0.057741051869173776, 0.05846708971555892, 0.05958079269925309, 0.06009641037817015, 0.06262156183567924, 0.06482791327350668, 0.06687276559169164, 0.06767724177112244, 0.06902954088784963, 0.07057330552688601, 0.07267087161001629, 0.07436266997466423, 0.07543894462319511, 0.07638494499145598, 0.07680744106928128, 0.07714516853958187, 0.07996539435930194, 0.08126528939362265, 0.08179200037722478, 0.0822475108286227, 0.08474281508217696, 0.08710755526342462, 0.08764983619465327, 0.08893129723261639, 0.089812154282774, 0.09072170223493103, 0.0927510556435942, 0.09375692064555663, 0.09432742629104363, 0.09608666973962532, 0.10054478745389839, 0.10440412974808144, 0.10536753395280596, 0.10633729734822717, 0.10889331398103907, 0.11034796698243365, 0.11097752458514809, 0.1129316426860113, 0.11573760667870536, 0.11619095652544598, 0.11838436012200237, 0.11849235876840059, 0.12013732263884003, 0.12065897982347196, 0.12237675732517794, 0.12286155848859603, 0.12389480740195746, 0.12459437487816571, 0.12573752938976224, 0.12786429997752347, 0.1300477825111387, 0.1313494081449067, 0.13169343847203852, 0.13345201825091313, 0.1350801462257607, 0.13533960785958232, 0.13603841926498983, 0.13659923314299816, 0.13711949708758764, 0.1384354933293943, 0.13911584889108752, 0.14058420671941085, 0.14430920072160303, 0.1458640023494957, 0.1474422180984465, 0.14882573914722919, 0.14931973939515375, 0.15380702464160778, 0.15607538738827598, 0.15792556260142077, 0.1593040206189803, 0.16003601971781745, 0.1605390904992331, 0.16253798746870785, 0.16368380146530148, 0.16668292852698752, 0.16906177843971626, 0.17208603245262644, 0.17334305297528085, 0.17521214372221328, 0.17639357920181054, 0.17683916929114074, 0.17760658118294192, 0.18019575412814792, 0.18280723665690046, 0.18331782454928192, 0.18691444060846163, 0.1903248628190678, 0.19081682886096896, 0.191190701464789, 0.1917245604440624, 0.19197737009344706, 0.19395386726777486, 0.1950362696007455, 0.19560927304451503, 0.1984910746053491, 0.19924595440831405, 0.20028208638128042, 0.20106515204994513, 0.2034914802762916, 0.2040246657385787, 0.2044608860547118, 0.20621740508413988, 0.2072422997688783, 0.20730900318755796, 0.20795635928938994, 0.20984199485640942, 0.21111247116613618, 0.21189433044010908, 0.21302986508233368, 0.2132916592926909, 0.21462807325880284, 0.2152044797331928, 0.21552986879133185, 0.21649991915474331, 0.21790870825201347, 0.21865115938559376, 0.21911747946993843, 0.21927396192387572, 0.21980534882319003, 0.22001167308945568, 0.2204836934733041, 0.22074548845278175, 0.22254453281761444, 0.2232633855051963, 0.22614705158994075, 0.2262791082142318, 0.22869440940036478, 0.23024616842786993, 0.23082918915401207, 0.23148009591298824, 0.23154843596504882, 0.232541331620855, 0.23417096076509014, 0.23915877778224304, 0.24075126693915716, 0.24373534210854741, 0.2453787784014082, 0.2462441609706001, 0.24690742666758558, 0.25278041225796233, 0.254139961372988, 0.25482050463038564, 0.25530907650393164, 0.2556449978092723, 0.256743496309758, 0.25823101966616, 0.2593738511056295, 0.2602696679144594, 0.2623429667809457, 0.2633157837532001, 0.26400434995946587, 0.2645158039888382, 0.2660946229981306, 0.2665132535078961, 0.26758613518733143, 0.26804193241436547, 0.26868348029670375, 0.2691819712881912, 0.27156876475103986, 0.27325077583180335, 0.2756123386789454, 0.2768505135353705, 0.2782784472828207, 0.2786065488937117, 0.2793677139347164, 0.2799919603368869, 0.28330476242493063, 0.28703999214119424, 0.28783129885160585, 0.2906170329126091, 0.29151030250720267, 0.2933657365324036, 0.2967866820198506, 0.2973550482368389, 0.2986167144403099, 0.29944351049188667, 0.3027245809461431, 0.30458435167194675, 0.3061373408795932, 0.3072389618477205, 0.30895599006815266, 0.30990344176215656, 0.31092893000755417, 0.31189908000428046, 0.31219636821760366, 0.31372769119409605, 0.31491958861296765, 0.31784683843836503, 0.31833051759837994, 0.3198680688965486, 0.32080084879883064, 0.3210810970870501, 0.32284758754232634, 0.3258231175644498, 0.3275521651801324, 0.3285753304693856, 0.33209936539313645, 0.3330348718\u001b[0m\n",
      "\u001b[34m0539837, 0.3347078980219448, 0.3356232729779117, 0.33600705899010874, 0.3373028364674864, 0.3382631053323484, 0.3404058433495647, 0.34194501613877926, 0.34460408444755963, 0.3460059076601988, 0.347062368499395, 0.34828935208903167, 0.3485736672419705, 0.3494883522082842, 0.3533995560513381, 0.35552972287896634, 0.3598016884403762, 0.36037781993034756, 0.36201479420670235, 0.36290529917555747, 0.3646706762343366, 0.36681037398653593, 0.36776184913213905, 0.36791017049375774, 0.369299528841215, 0.3699601215200178, 0.3712070938899983, 0.3718804687564282, 0.3738238284068618, 0.37479523046955776, 0.37557455352827196, 0.3786555027464704, 0.38050224859241233, 0.3810084353014118, 0.3827509791512743, 0.38423962013738133, 0.3853758830473618, 0.38587450289511593, 0.3865268613608237, 0.3876735947503942, 0.3892292693149614, 0.3923937215284745, 0.3942446968609433, 0.3961490174597221, 0.39717877742921104, 0.39753016929654494, 0.39788301464522047, 0.3993904574537639, 0.40063103433706615, 0.401887370630982, 0.4027075796465307, 0.40464033874139593, 0.405751168615061, 0.4065567838081042, 0.4071880083465773, 0.4085932405775119, 0.41005211719819123, 0.4113394664991439, 0.41293829229884904, 0.413520907811293, 0.4141502243282268, 0.41451606481679226, 0.4161214280710923, 0.4195249932833254, 0.4223845221843059, 0.42281476328825185, 0.4235275624422461, 0.4254126176822334, 0.42677680555040853, 0.43037474969079326, 0.43138064877407467, 0.4328292200806144, 0.4338005122547718, 0.4343614981412177, 0.4355589093211175, 0.4372883009776608, 0.4380071525331932, 0.4383849800307613, 0.44042114553465805, 0.4411505522306324, 0.441957674851033, 0.4426894246856915, 0.4434558363819041, 0.44441945275120154, 0.44564331878363095, 0.44635235119764216, 0.4468880289416285, 0.4474681413224578, 0.4488530716747082, 0.4504163432778564, 0.45069022851989604, 0.45161796380434605, 0.45221530561668055, 0.45440315447995283, 0.4548944717393003, 0.4559792757599369, 0.45697856913323587, 0.4593314408005428, 0.4613043326569609, 0.46311471383751146, 0.4632936532727968, 0.46464189815733914, 0.46672809376795044, 0.4667820772311879, 0.46751880744057384, 0.46811092099248586, 0.47031905410178565, 0.4714218902778029, 0.4727738191601998, 0.47289713281090484, 0.4742437804408651, 0.47476024247983983, 0.4754066078500737, 0.4759677310116559, 0.4764833837782927, 0.47755585459453553, 0.4780469965214361, 0.4792600899145375, 0.47970342308134595, 0.4800473773100856, 0.4816348465348623, 0.4818674792746166, 0.4827606182856681, 0.48531638287856105, 0.48638895345567545, 0.48785119719240644, 0.48937644897067023, 0.49255363388025786, 0.49294889613455894, 0.4933273510172542, 0.4946751895912833, 0.49604783867988655, 0.498040393056869, 0.49897111691376594, 0.5004453091307415, 0.5006661650213817, 0.504003763596326, 0.5064990078455918, 0.5085818224714432, 0.5116253710170613, 0.5131830837567788, 0.516424388218611, 0.5215993960113582, 0.5224810405161183, 0.5232130549708749, 0.5235635795298558, 0.5236005471526117, 0.5250490347362518, 0.5262784603382027, 0.5272261808398002, 0.5279395658030017, 0.5315773967749932, 0.5322575311489761, 0.5350255045989328, 0.536009868535575, 0.5370074883513584, 0.5381565187248897, 0.53883309874609, 0.5403491803404276, 0.5410028989276625, 0.5417653496071662, 0.5425343685322515, 0.5447722269827888, 0.5456868884954734, 0.5467005205567683, 0.5468759658760446, 0.5488386567200587, 0.5495214285294047, 0.550091940458156, 0.5519903021207211, 0.5546573480350956, 0.5558847535036677, 0.5563280072570793, 0.5566370579367172, 0.5567269125563817, 0.5576334668975812, 0.5579807387826399, 0.558980634099774, 0.5596884448379399, 0.5601822583749119, 0.561255678074924, 0.5632889309538147, 0.5633246420330467, 0.5636599710287622, 0.5655499649214404, 0.569016098079178, 0.5706496238809349, 0.5711131211389614, 0.5718091636071537, 0.5724981686718883, 0.5757031141151119, 0.5770406644619108, 0.5801513023136824, 0.5822087597682312, 0.5829844261646024, 0.5835569673248185, 0.5838546323593933, 0.5850395639203195, 0.5891429081595035, 0.5905221469947961, 0.5914067594224881, 0.5927709408701848, 0.5933259300014169, 0.5942907505617747, 0.5954313435959826, 0.5959888421834818, 0.5967764199616896, 0.5985543690868064, 0.598845400079439, 0.5996275684599214, 0.6006312516053091, 0.6023524204079639, 0.6032194102133722, 0.6045657320070856, 0.6063709444333756, 0.6092448476703629, 0.6098797653116608, 0.6103774953183276, 0.6133798273661658, 0.6144000074313238, 0.6148798800974999, 0.6159573616088996, 0.6174737197559917, 0.617931559846298, 0.6185270587181856, 0.6189481930077215, 0.6204970966252814, 0.6209728737809026, 0.6225196957297452, 0.6234778305192964, 0.6264451989523181, 0.6267588436207662, 0.6288304839804686, 0.6302087483291442, 0.6320154860204185, 0.6325441099658279, 0.6329063306784342, 0.6341141904431196, 0.6344042989960332, 0.6358872249895006, 0.6368992633659896, 0.6377319129014088, 0.6379018745529615, 0.6379607933159701, 0.6390321589149208, 0.6418599588553554, 0.6445911747423436, 0.6457405100956123, 0.646096175005063, 0.6466059134228601, 0.6481050345341234, 0.6504252488238643, 0.6509573351180726, 0.6534412401834524, 0.6541601542860984, 0.656336807390897, 0.6575603127780231, 0.6580825847491903, 0.6589099755257795, 0.6594551645201031, 0.6596293663947422, 0.6623506980007654, 0.6630073461417759, 0.6630420045004922, 0.6643261669609404, 0.6662678614790385, 0.6665926778408895, 0.6666170848793723, 0.6669715169909073, 0.6695919961242262, 0.6710552838599144, 0.674746094075448, 0.6761082314144111, 0.6764263623383923, 0.6769888016137862, 0.6795499271339084, 0.6808765101795374, 0.6818955530965279, 0.6828042832346014, 0.6869498549368531, 0.6880880944632948, 0.6938626591204068, 0.6944504561307088, 0.695624652354058, 0.69698249301797, 0.697716307553293, 0.6983111572275728, 0.6996899090587084, 0.7004317991565039, 0.7024883415884688, 0.7037923109905077, 0.7045320753732407, 0.7061931829633586, 0.707483574523748, 0.7099708063510941, 0.7101354317980658, 0.7108847166823191, 0.7132358680833368, 0.7150387188506838, 0.7150919784690392, 0.7154909070992744, 0.7189619186189717, 0.7197914533546861, 0.720584115823928, 0.7218708445133876, 0.7221779272182656, 0.7234047656122863, 0.7245168513986181, 0.7257164632199491, 0.7285012458181321, 0.7286340364609895, 0.7297119064974222, 0.7302461470901459, 0.731031968404614, 0.7311532575471567, 0.7338319874844625, 0.7340297625893063, 0.7345779231214132, 0.7362398101338331, 0.7373243574013483, 0.7380691233385172, 0.7399863866856118, 0.7418267458088308, 0.746776639533718, 0.7473539693787133, 0.7495454844688882, 0.7504756331617514, 0.7531873359134028, 0.7538297005692186, 0.754107680316164, 0.7577687821754331, 0.7581850110765374, 0.7596114286997965, 0.7599292595124335, 0.762482884475553, 0.7651908645557847, 0.7665885239716433, 0.76821640971065, 0.7718577261816213, 0.7730353056346358, 0.7733093479250763, 0.7735721017307203, 0.7745612445363061, 0.7751097831840875, 0.7763855655036888, 0.7789366285462715, 0.7805560268872138, 0.7809958936149914, 0.7820153349329673, 0.7823883294600873, 0.7830437541361205, 0.7839873586893554, 0.7846556186174474, 0.7852688115160151, 0.7859252762089134, 0.7867695033571274, 0.7888875288338638, 0.7894321941951912, 0.7899706504837184, 0.7914097505069756, 0.792690996812442, 0.7944808178535061, 0.7955594260504532, 0.8001587287180605, 0.805441676814699, 0.8076901039663725, 0.809183171139031, 0.8102585866995313, 0.8109604752724683, 0.815414870462967, 0.8165475988497707, 0.8169845557652728, 0.8178563056550295, 0.8182066687482475, 0.8196920645772219, 0.8228290747281345, 0.8231128548561456, 0.8251321959287038, 0.8267146599310183, 0.826814973796419, 0.828488133895241, 0.8287050421783296, 0.82941808844291, 0.8316630440808698, 0.8328319018690757, 0.8343033659547675, 0.8347579495573968, 0.8353725302842461, 0.8391518260422538, 0.841375855473622, 0.8422307463439479, 0.843618195596552, 0.8444285631306977, 0.848224590148898, 0.84841570713012, 0.849391896781726, 0.8495342154879013, 0.8514486375512653, 0.8516396627104832, 0.8529381494334116, 0.85520698501837, 0.8578295532961044, 0.8581203942511035, 0.8598238353912759, 0.8619869084042723, 0.8621771008407646, 0.8630009369463286, 0.8651933473978111, 0.8661962637205113, 0.8665479817490869, 0.8673554223990468, 0.868410787941382, 0.8689442522791451, 0.8697631766817108, 0.8720630754882168, 0.872546040577131, 0.8736135775943329, 0.8742757310077738, 0.8747794404831686, 0.8755112265526162, 0.87735561220526, 0.8782380888747252, 0.8794965707281264, 0.8822585560948476, 0.882734380673422, 0.8839773186518307, 0.8852030727487199, 0.8884641099229207, 0.8888874240036297, 0.8895766183304922, 0.8918931032565626, 0.8929428214458139, 0.8936562737442254, 0.8944525568242322, 0.8956979631993723, 0.8958841811926596, 0.8963214192657235, 0.8990588000224785, 0.9003212680742715, 0.9013830966419349, 0.9027055104453562, 0.9036078443467951, 0.9050915587326538, 0.9065920280247044, 0.9071998215606223, 0.907380164712847, 0.9077152079267428, 0.9081291122899553, 0.9093901920083962, 0.910187845717226, 0.9111682851800791, 0.9132326804214563, 0.9156722322616498, 0.9172659603763292, 0.9223592240112187, 0.9233641935247512, 0.9242542746031159, 0.9245224687318999, 0.925957782087652, 0.928317532848577, 0.9292573980072293, 0.9306424763519598, 0.9314945933730204, 0.9325445893524509, 0.9341882393094235, 0.9363211539691568, 0.9373532942158644, 0.9388953323803677, 0.9396515112935082, 0.941048260038377, 0.9425313075201167, 0.943174822961285, 0.9467560351737032, 0.948744395149711, 0.9491121430894405, 0.9503127529305917, 0.9514785596659912, 0.9524671166878468, 0.9539432658100436, 0.9550385584084489, 0.9562221906489483, 0.9569930481330605, 0.9573667907129673, 0.9577082507773188, 0.9580145710904118, 0.9619781517625451, 0.9623102029877842, 0.9650607535940116, 0.9672635875263655, 0.969062355268658, 0.9699786678509281, 0.9707499576706702, 0.9721560924225866, 0.9734573899761731, 0.9750337778799428, 0.9755015517323476, 0.9795508403817569, 0.9801089924137669, 0.980516822001106, 0.9832436955076176, 0.9844916693734078, 0.9862466719514015, 0.9867291015008487, 0.9884159894120765, 0.9890283583501739, 0.9897564134093346, 0.9917728809792494, 0.9933369373586285, 0.9937425289735298, 0.9944152675588734, 0.9948579730593216, 0.995480490704257, 0.9963982936790554, 0.9981201164750894, 0.9995439187190943, 0.9998116004434181, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013307019642838425, 0.026902251929653564, 0.055696365042170126, 0.06913278618661944, 0.09218134701535985, 0.1050785587721601, 0.12574151180664883, 0.14579022553843402, 0.1537547079809507, 0.1794973234238334, 0.21119301812925573, 0.230569195805019, 0.25530652472843185, 0.2660900810462983, 0.283854528608645, 0.3121480566964471, 0.3340088787452379, 0.34499066116789145, 0.39381128643882846, 0.40672135168982126, 0.41988777030453195, 0.44699854740804157, 0.4673107665376526, 0.49118634086862656, 0.5190961685510151, 0.5250315008602682, 0.551222426168597, 0.5677592161074877, 0.5946898169142566, 0.603340223656438, 0.6078487885548034, 0.6297779229961531, 0.6636295361715779, 0.6740745360479251, 0.7011641136626862, 0.7536988340505192, 0.7629721428916638, 0.7688690875723534, 0.7896504200811314, 0.7991409101377058, 0.8401215027412188, 0.8528218216919013, 0.8644928803073485, 0.8796612379650041, 0.9103391020575343, 0.9588165047207283, 0.9843514074029039, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1\u001b[0m\n",
      "\u001b[34m.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_education\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.324521866244366,\n",
      "      \"sum\" : 19082.0,\n",
      "      \"std_dev\" : 1.0514521771710255,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 4.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 156.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 2256.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.6,\n",
      "            \"upper_bound\" : 2.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.0,\n",
      "            \"upper_bound\" : 2.4,\n",
      "            \"count\" : 1481.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.4,\n",
      "            \"upper_bound\" : 2.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.8,\n",
      "            \"upper_bound\" : 3.2,\n",
      "            \"count\" : 3404.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.2,\n",
      "            \"upper_bound\" : 3.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6,\n",
      "            \"upper_bound\" : 4.0,\n",
      "            \"count\" : 912.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 0.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 4.0, 1.0, 3.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0 ], [ 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4\u001b[0m\n",
      "\u001b[34m.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_nv\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.05158481722478171,\n",
      "      \"sum\" : 423.45976459823305,\n",
      "      \"std_dev\" : 0.20068785125094382,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7611.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 53.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 40.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 41.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 48.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 44.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 45.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 30.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 35.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 262.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.987658953939626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007334150836180275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11354064232628669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0630721362688611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05541588844224443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45013582163560184, 0.0, 0.0, 0.4904085191855132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7396828977631081, 0.38772423430612757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5685522556046121, 0.0, 0.0, 0.0, 0.9940816546455755, 0.9889214474056903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06915356771850123, 0.0, 0.0, 0.0, 0.0, 0.3006605337473569, 0.0, 0.25526327217079003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6813103960094764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7244634328591488, 0.0, 0.0, 0.411906362394553, 0.31607768384326407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5896534951515476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4425950356858128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6802568045923051, 0.0, 0.0, 0.0, 0.09677637265529271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31952053747562603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9455339526331624, 0.0, 0.0, 0.42818393986717285, 0.0, 0.0, 0.0, 0.852772925589483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18792238899132097, 0.0, 0.0, 0.32373082561042366, 0.0, 0.0, 0.0, 0.6415685666849944, 0.0, 0.7879701335909316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23127992831595545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5982068648905755, 0.5778279715114357, 0.0, 0.5227999205820387, 0.0, 0.9812415974554621, 0.0, 0.0, 0.4022237348471124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9290840405120208, 0.6502039381924081, 0.13750349259841466, 0.0, 0.0, 0.0, 0.0, 0.13228794765103824, 0.0, 0.0, 0.0, 0.0884852741341492, 0.0, 0.0, 0.0, 0.4724363510005801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4512666140731144, 0.8691748574030873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13736174596867423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2596032837084785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5538234406337256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3753360257162832, 0.9188357755362855, 0.0, 0.0, 0.31348605695674747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9041353525781907, 0.0, 0.008110804052508302, 0.9513968619791061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15568513584761756, 0.9158075833506722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8364209229856395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.345274651501557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26091857965016807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5081417186651943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6965614021440462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8006545105288169, 0.0, 0.0, 0.42421413722558843, 0.0, 0.0, 0.0, 0.9129287944226918, 0.7978506007747292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1876738197529384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9172205918248628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6013840706885634, 0.3392202983917838, 0.0, 0.0, 0.25517492447008694, 0.0, 0.9799767702678124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8871568128163786, 0.0, 0.0, 0.0, 0.38048188549303585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.618290798754788, 0.0, 0.0, 0.48902925695493793, 0.5712357088853165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13836820088819002, 0.0, 0.0, 0.0, 0.49236230351962584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4843234489229269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9157356338441489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2650812843385726, 0.0, 0.0, 0.0, 0.0, 0.8216415697789553, 0.0, 0.0, 0.18842799564845192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.32838549961660535, 0.0, 0.0, 0.24881902701993186, 0.0, 0.27963631849320625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8560010748931528 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.865281706631139E-4, 0.009913623932517934, 0.01234040765874822, 0.016756304492382412, 0.02104249295889593, 0.027843907577413396, 0.031115599917357684, 0.034461259425, 0.03768979701221575, 0.048557971274318934, 0.05607171652354215, 0.07039412257801081, 0.074042217912348, 0.07737694191221034, 0.08706899522531009, 0.09060980799160379, 0.09501169899230466, 0.10640541354986843, 0.10794371464646435, 0.11074844531895811, 0.11428576999797946, 0.12793692451178318, 0.13237237903497245, 0.13788526935601042, 0.14017616460872406, 0.1438143503148137, 0.15862414452637796, 0.1603403442912097, 0.16540904740472795, 0.16758281658974727, 0.1706647585499984, 0.17396094833342812, 0.1768871451438544, 0.1817232932281565, 0.18331782454928192, 0.18981530297215599, 0.19519716457188252, 0.20021890457597835, 0.21228698447229133, 0.2136422669385185, 0.23024616842786993, 0.23178359028935003, 0.23418444681548567, 0.24075126693915716, 0.2478713004564288, 0.2593738511056295, 0.2603286992732363, 0.2669488101400066, 0.2675512681619102, 0.2714385776342002, 0.27843940825043456, 0.2803344607915209, 0.29524180248964216, 0.3002947939005238, 0.31259363586376243, 0.3182620413857259, 0.3256848020639532, 0.33314557898573216, 0.33581208549458264, 0.34361414061523277, 0.3452909246437009, 0.35176410261790303, 0.3649108940902812, 0.3784764234858691, 0.38559999256867616, 0.3870998391380508, 0.3952059263099702, 0.39717877742921104, 0.4011879140389827, 0.4091325587289585, 0.4113745714125894, 0.41550020446920977, 0.42265603378895833, 0.4353936461757356, 0.4434558363819041, 0.45011652647481104, 0.45150027834852324, 0.4580099251102341, 0.46118699096038096, 0.4677424688510239, 0.47086735622317677, 0.4775189594838817, 0.4898902875011748, 0.49857079950570915, 0.5272326607539126, 0.5343174582377205, 0.5407345671331042, 0.549309771480104, 0.554356681216369, 0.5579274451507007, 0.5599419534906013, 0.5614615114625645, 0.5632889309538147, 0.5671707799193856, 0.5747795542644152, 0.5791752553747221, 0.5821832300925898, 0.5850287845999218, 0.5940827805697124, 0.5948032146777896, 0.6042920364262074, 0.6065521534364084, 0.6199254910627947, 0.6263223516561951, 0.6330439207951993, 0.6406355928025865, 0.6517106479109683, 0.6520930618816506, 0.6536782314109965, 0.6602297577011562, 0.6642017130717857, 0.6728471334885447, 0.6746078529162162, 0.6791991512011694, 0.6852980161158734, 0.690405721911072, 0.6981984306764998, 0.7318609799044866, 0.7333248033380224, 0.7355056064875376, 0.7463644444859617, 0.7537139811894684, 0.7584250178691111, 0.7604243116824717, 0.7685193645237912, 0.7735527418648872, 0.7816154791963991, 0.7960074024272833, 0.8040956696335928, 0.8082754395559376, 0.8231740155956603, 0.8316630440808698, 0.8372630071385088, 0.8385492149028282, 0.8409749962597387, 0.8456784347169206, 0.8700586277320588, 0.8729037597815608, 0.8742267241383516, 0.8815849608240681, 0.8951919350024279, 0.8960751117945733, 0.9036078443467951, 0.9072489443564058, 0.909278297765069, 0.9231925589307187, 0.9242870707946612, 0.9301709654384246, 0.9326154452144775, 0.9422970715841011, 0.9521691796058945, 0.9548469930384681, 0.9571624448808868, 0.9670526814260348, 0.9728249839091558, 0.9794791852706748, 0.99328960969594, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\u001b[0m\n",
      "\u001b[34m.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06498640948289403, 0.1812143566429063, 0.4633807482156199, 0.5579756262171425, 0.6161528481322037, 0.7834227259416147, 0.9473504626310387, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"auto_year\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2015.6727981483737,\n",
      "      \"sum\" : 1.6546658E7,\n",
      "      \"std_dev\" : 3.0692486020095284,\n",
      "      \"min\" : 2001.0,\n",
      "      \"max\" : 2020.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 2001.0,\n",
      "            \"upper_bound\" : 2002.9,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2002.9,\n",
      "            \"upper_bound\" : 2004.8,\n",
      "            \"count\" : 58.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2004.8,\n",
      "            \"upper_bound\" : 2006.7,\n",
      "            \"count\" : 67.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2006.7,\n",
      "            \"upper_bound\" : 2008.6,\n",
      "            \"count\" : 117.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2008.6,\n",
      "            \"upper_bound\" : 2010.5,\n",
      "            \"count\" : 240.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2010.5,\n",
      "            \"upper_bound\" : 2012.4,\n",
      "            \"count\" : 557.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2012.4,\n",
      "            \"upper_bound\" : 2014.3,\n",
      "            \"count\" : 1335.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2014.3,\n",
      "            \"upper_bound\" : 2016.2,\n",
      "            \"count\" : 2102.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2016.2,\n",
      "            \"upper_bound\" : 2018.1,\n",
      "            \"count\" : 2382.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2018.1,\n",
      "            \"upper_bound\" : 2020.0,\n",
      "            \"count\" : 1339.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2016.0, 2019.0, 2016.0, 2019.0, 2013.0, 2014.0, 2003.0, 2016.0, 2018.0, 2018.0, 2018.0, 2019.0, 2013.0, 2012.0, 2020.0, 2015.0, 2017.0, 2016.0, 2018.0, 2018.0, 2011.0, 2014.0, 2018.0, 2017.0, 2016.0, 2016.0, 2016.0, 2016.0, 2012.0, 2016.0, 2013.0, 2016.0, 2015.0, 2016.0, 2012.0, 2016.0, 2015.0, 2016.0, 2013.0, 2015.0, 2018.0, 2018.0, 2017.0, 2017.0, 2020.0, 2019.0, 2014.0, 2016.0, 2013.0, 2015.0, 2004.0, 2016.0, 2017.0, 2016.0, 2013.0, 2017.0, 2016.0, 2016.0, 2014.0, 2016.0, 2019.0, 2016.0, 2016.0, 2019.0, 2019.0, 2019.0, 2013.0, 2017.0, 2018.0, 2020.0, 2019.0, 2013.0, 2018.0, 2013.0, 2017.0, 2017.0, 2016.0, 2015.0, 2014.0, 2013.0, 2016.0, 2017.0, 2015.0, 2018.0, 2017.0, 2012.0, 2013.0, 2013.0, 2015.0, 2013.0, 2011.0, 2012.0, 2013.0, 2019.0, 2015.0, 2009.0, 2010.0, 2016.0, 2014.0, 2018.0, 2012.0, 2015.0, 2020.0, 2018.0, 2015.0, 2013.0, 2016.0, 2019.0, 2018.0, 2018.0, 2019.0, 2019.0, 2015.0, 2015.0, 2019.0, 2019.0, 2017.0, 2018.0, 2011.0, 2019.0, 2018.0, 2014.0, 2018.0, 2005.0, 2013.0, 2014.0, 2018.0, 2017.0, 2018.0, 2012.0, 2019.0, 2018.0, 2012.0, 2017.0, 2013.0, 2020.0, 2018.0, 2015.0, 2016.0, 2019.0, 2018.0, 2016.0, 2016.0, 2014.0, 2015.0, 2017.0, 2017.0, 2015.0, 2016.0, 2014.0, 2013.0, 2017.0, 2012.0, 2017.0, 2019.0, 2016.0, 2017.0, 2017.0, 2016.0, 2019.0, 2017.0, 2015.0, 2020.0, 2016.0, 2012.0, 2010.0, 2017.0, 2019.0, 2016.0, 2019.0, 2017.0, 2015.0, 2004.0, 2017.0, 2018.0, 2014.0, 2016.0, 2013.0, 2014.0, 2017.0, 2014.0, 2018.0, 2014.0, 2014.0, 2010.0, 2016.0, 2016.0, 2015.0, 2017.0, 2015.0, 2016.0, 2019.0, 2012.0, 2012.0, 2014.0, 2018.0, 2014.0, 2012.0, 2019.0, 2015.0, 2010.0, 2014.0, 2014.0, 2017.0, 2014.0, 2015.0, 2018.0, 2016.0, 2017.0, 2020.0, 2017.0, 2020.0, 2016.0, 2012.0, 2020.0, 2018.0, 2017.0, 2018.0, 2016.0, 2019.0, 2015.0, 2018.0, 2009.0, 2012.0, 2012.0, 2012.0, 2015.0, 2017.0, 2017.0, 2018.0, 2013.0, 2013.0, 2011.0, 2012.0, 2014.0, 2017.0, 2018.0, 2020.0, 2017.0, 2016.0, 2019.0, 2016.0, 2018.0, 2017.0, 2018.0, 2019.0, 2018.0, 2016.0, 2016.0, 2017.0, 2012.0, 2019.0, 2018.0, 2018.0, 2017.0, 2020.0, 2019.0, 2017.0, 2018.0, 2018.0, 2017.0, 2014.0, 2017.0, 2015.0, 2012.0, 2014.0, 2017.0, 2020.0, 2020.0, 2016.0, 2004.0, 2015.0, 2016.0, 2014.0, 2014.0, 2017.0, 2012.0, 2014.0, 2019.0, 2019.0, 2019.0, 2019.0, 2018.0, 2017.0, 2017.0, 2014.0, 2019.0, 2012.0, 2019.0, 2018.0, 2015.0, 2015.0, 2015.0, 2018.0, 2013.0, 2012.0, 2018.0, 2018.0, 2015.0, 2016.0, 2019.0, 2013.0, 2017.0, 2014.0, 2015.0, 2018.0, 2013.0, 2019.0, 2016.0, 2016.0, 2018.0, 2007.0, 2016.0, 2020.0, 2016.0, 2016.0, 2018.0, 2016.0, 2018.0, 2016.0, 2017.0, 2018.0, 2017.0, 2013.0, 2019.0, 2012.0, 2015.0, 2016.0, 2012.0, 2018.0, 2015.0, 2013.0, 2017.0, 2015.0, 2009.0, 2017.0, 2013.0, 2016.0, 2015.0, 2019.0, 2016.0, 2011.0, 2019.0, 2018.0, 2014.0, 2004.0, 2015.0, 2015.0, 2015.0, 2019.0, 2017.0, 2016.0, 2016.0, 2016.0, 2013.0, 2015.0, 2014.0, 2014.0, 2017.0, 2010.0, 2014.0, 2012.0, 2016.0, 2018.0, 2014.0, 2015.0, 2016.0, 2019.0, 2020.0, 2017.0, 2011.0, 2015.0, 2013.0, 2016.0, 2016.0, 2015.0, 2018.0, 2014.0, 2020.0, 2010.0, 2018.0, 2017.0, 2020.0, 2014.0, 2013.0, 2014.0, 2017.0, 2017.0, 2017.0, 2014.0, 2013.0, 2015.0, 2016.0, 2017.0, 2017.0, 2014.0, 2015.0, 2016.0, 2010.0, 2016.0, 2013.0, 2019.0, 2016.0, 2017.0, 2013.0, 2015.0, 2019.0, 2014.0, 2015.0, 2015.0, 2015.0, 2016.0, 2018.0, 2017.0, 2016.0, 2016.0, 2019.0, 2016.0, 2019.0, 2016.0, 2018.0, 2017.0, 2015.0, 2016.0, 2012.0, 2013.0, 2018.0, 2015.0, 2015.0, 2016.0, 2017.0, 2012.0, 2016.0, 2017.0, 2011.0, 2017.0, 2012.0, 2014.0, 2014.0, 2015.0, 2012.0, 2014.0, 2014.0, 2016.0, 2017.0, 2009.0, 2016.0, 2014.0, 2018.0, 2017.0, 2016.0, 2016.0, 2017.0, 2015.0, 2017.0, 2014.0, 2016.0, 2005.0, 2018.0, 2015.0, 2018.0, 2018.0, 2020.0, 2011.0, 2016.0, 2014.0, 2017.0, 2010.0, 2015.0, 2019.0, 2015.0, 2016.0, 2016.0, 2019.0, 2009.0, 2017.0, 2016.0, 2016.0, 2010.0, 2013.0, 2004.0, 2015.0, 2013.0, 2014.0, 2019.0, 2018.0, 2018.0, 2018.0, 2012.0, 2019.0, 2016.0, 2015.0, 2012.0, 2014.0, 2018.0, 2019.0, 2016.0, 2015.0, 2016.0, 2016.0, 2018.0, 2015.0, 2015.0, 2016.0, 2012.0, 2015.0, 2017.0, 2017.0, 2010.0, 2013.0, 2016.0, 2015.0, 2015.0, 2003.0, 2015.0, 2018.0, 2018.0, 2018.0, 2013.0, 2016.0, 2017.0, 2016.0, 2012.0, 2018.0, 2016.0, 2017.0, 2016.0, 2014.0, 2019.0, 2016.0, 2017.0, 2014.0, 2017.0, 2013.0, 2017.0, 2017.0, 2013.0, 2017.0, 2014.0, 2014.0, 2017.0, 2019.0, 2017.0, 2010.0, 2012.0, 2015.0, 2011.0, 2014.0, 2016.0, 2019.0, 2017.0, 2014.0, 2012.0, 2015.0, 2015.0, 2018.0, 2018.0, 2016.0, 2016.0, 2013.0, 2016.0, 2017.0, 2017.0, 2018.0, 2017.0, 2019.0, 2017.0, 2015.0, 2017.0, 2018.0, 2017.0, 2019.0, 2018.0, 2016.0, 2018.0, 2016.0, 2015.0, 2013.0, 2015.0, 2006.0, 2008.0, 2017.0, 2016.0, 2020.0, 2015.0, 2015.0, 2020.0, 2016.0, 2009.0, 2013.0, 2019.0, 2013.0, 2015.0, 2016.0, 2014.0, 2006.0, 2016.0, 2018.0, 2018.0, 2014.0, 2014.0, 2014.0, 2017.0, 2014.0, 2011.0, 2015.0, 2016.0, 2016.0, 2013.0, 2014.0, 2015.0, 2015.0, 2017.0, 2016.0, 2012.0, 2017.0, 2015.0, 2015.0, 2014.0, 2015.0, 2013.0, 2020.0, 2018.0, 2014.0, 2013.0, 2014.0, 2016.0, 2013.0, 2017.0, 2019.0, 2014.0, 2015.0, 2016.0, 2015.0, 2020.0, 2015.0, 2017.0, 2016.0, 2018.0, 2014.0, 2016.0, 2020.0, 2015.0, 2015.0, 2016.0, 2017.0, 2016.0, 2017.0, 2019.0, 2015.0, 2012.0, 2017.0, 2015.0, 2016.0, 2007.0, 2018.0, 2019.0, 2017.0, 2009.0, 2013.0, 2016.0, 2014.0, 2007.0, 2016.0, 2017.0, 2013.0, 2006.0, 2007.0, 2019.0, 2015.0, 2017.0, 2012.0, 2011.0, 2015.0, 2017.0, 2015.0, 2012.0, 2011.0, 2014.0, 2004.0, 2016.0, 2013.0, 2017.0, 2019.0, 2019.0, 2018.0, 2017.0, 2014.0, 2017.0, 2009.0, 2016.0, 2015.0, 2018.0, 2014.0, 2017.0, 2016.0, 2011.0, 2015.0, 2018.0, 2020.0, 2014.0, 2017.0, 2015.0, 2018.0, 2016.0, 2010.0, 2017.0, 2014.0, 2017.0, 2013.0, 2018.0 ], [ 2020.0, 2003.0, 2003.0, 2003.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2004.0, 2005.0, 2005.0, 2005.0, 2005.0, 2005.0, 2006.0, 2006.0, 2006.0, 2006.0, 2006.0, 2006.0, 2006.0, 2006.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 201\u001b[0m\n",
      "\u001b[34m8.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0 ], [ 2001.0, 2002.0, 2002.0, 2003.0, 2003.0, 2003.0, 2003.0, 2004.0, 2004.0, 2004.0, 2004.0, 2005.0, 2005.0, 2005.0, 2005.0, 2005.0, 2005.0, 2006.0, 2006.0, 2006.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2007.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2008.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2009.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2010.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2011.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2012.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2013.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2014.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2015.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2016.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2017.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2018.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2019.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0, 2020.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_police\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.6714946346453773,\n",
      "      \"sum\" : 5512.299455803902,\n",
      "      \"std_dev\" : 0.4278720328871626,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 1954.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 204.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 175.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 166.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 189.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 195.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 184.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 191.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 187.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 4764.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.49645301848811385, 0.06810902472352254, 1.0, 0.06462183869288274, 0.0, 0.4453865259778722, 0.0, 0.0, 0.1337075640178187, 0.0, 0.5848750604652789, 0.014330905867001253, 0.5216645183294442, 1.0, 0.18039044693420014, 0.0, 0.0, 0.0, 1.0, 0.4570018673947307, 0.37380810886700244, 1.0, 0.0, 0.0, 1.0, 0.244161608716153, 1.0, 0.38510260282302966, 1.0, 1.0, 1.0, 1.0, 0.0, 0.474434893620735, 1.0, 0.025809392863181735, 0.5532906396230001, 0.47955059583471404, 0.99458198903526, 1.0, 1.0, 0.8864593576737133, 1.0, 0.22218875554154927, 0.17766088854315254, 0.9027637879645087, 0.47510001327416174, 0.4511931914507237, 1.0, 0.0, 0.0, 0.4515655866055751, 0.0, 0.0, 0.20351561067041923, 0.7567580902469283, 0.6805581617791014, 1.0, 0.9408941791243455, 1.0, 0.27121377774342403, 0.046972991098139794, 0.07194824977115188, 1.0, 0.2859005337712024, 1.0, 0.8301274055955237, 0.0, 0.6688535108358502, 0.23402842514482092, 0.5863213210147397, 1.0, 1.0, 0.02221848202558041, 1.0, 1.0, 0.967802737648485, 0.45013582163560184, 0.9631590270650665, 0.8852464005861646, 1.0, 0.16950409186605864, 0.05097487702244241, 1.0, 0.20778342096169145, 0.587697018287546, 1.0, 1.0, 0.7816325580532472, 0.5629484781578123, 0.3722545851026636, 0.647457940745546, 1.0, 0.3249227944066413, 0.6872955625825176, 0.9616158070461657, 1.0, 1.0, 1.0, 0.26031710223689186, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5218843281579432, 0.0679732998194037, 0.18122556104970955, 0.042803036480765444, 0.10986194655308601, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6328026106615069, 0.23107995542883164, 0.0, 0.011078552594309676, 1.0, 0.0, 1.0, 0.12757017457137088, 1.0, 1.0, 0.3028298889787422, 1.0, 0.2992744787157362, 1.0, 0.0, 0.34985438418085446, 0.0, 0.34409668690160045, 0.19881406093740295, 0.6849894928165754, 1.0, 0.0, 0.17250125836432662, 0.7454594570783388, 0.5269724966569793, 0.04331527325431195, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6826945225795135, 0.08804041580036681, 1.0, 1.0, 0.1827511659874359, 0.0, 1.0, 0.09198491062502578, 0.24257826607382516, 0.9086911974553298, 0.6813103960094764, 0.0, 0.0, 0.4261494020249733, 0.06090193309949332, 0.030930881393566034, 0.7144141014704978, 0.6383529051589555, 0.12537534923387328, 1.0, 0.0, 0.7244634328591488, 1.0, 0.8783046932733277, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2557437015483004, 0.327420958733448, 0.8353794867634952, 0.8188281491499799, 1.0, 0.38473257650744497, 1.0, 0.40595053443318885, 0.5896534951515476, 1.0, 0.8315407863376656, 0.17732655322393942, 1.0, 1.0, 0.0, 0.0, 0.9853910028911171, 0.6396245076368293, 0.39516057063741883, 0.3874512959225387, 0.0, 0.30880227534961535, 0.7064652075413396, 0.0, 0.6672191310392045, 0.0, 1.0, 0.0, 0.19228218001852038, 0.8859139954974249, 0.8160790423433513, 0.0, 0.26408204644801125, 1.0, 0.8670719572920174, 0.6384887847991355, 1.0, 0.05711716337044326, 1.0, 0.0, 1.0, 1.0, 1.0, 0.41626278068790734, 0.0, 1.0, 0.040288945734542114, 1.0, 1.0, 0.9316979736811688, 0.0, 1.0, 0.0837249378453484, 0.6140604890630726, 0.0, 0.0, 0.8486288287367251, 0.8481138276633697, 0.32855814988579846, 0.9455339526331624, 0.18245804065249005, 0.9652096385457352, 0.42818393986717285, 1.0, 0.27388874065536306, 1.0, 0.852772925589483, 0.7934189837782192, 1.0, 1.0, 1.0, 0.9931853020998719, 0.0, 0.9215133919074179, 0.18792238899132097, 0.17478862874036893, 0.7950580176061312, 0.6762691743895763, 1.0, 1.0, 1.0, 0.0, 0.02556979908973467, 0.0, 1.0, 0.0, 0.8123907241861509, 0.0824059718619482, 0.0, 0.0, 0.0, 1.0, 0.8713152472468535, 0.785083657239757, 1.0, 0.08818137131390835, 0.09750769246387525, 0.0, 0.3281600723536078, 0.053772311661983374, 0.6693569842407483, 0.23127992831595545, 1.0, 0.3060471662287715, 0.0, 0.17712714419825404, 0.005139627585560302, 0.0, 0.08425537741797129, 0.682652605044199, 0.7643771488083516, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.597839986845685, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8596795850803329, 0.04052781704458808, 0.21771251297815153, 0.9118478418633555, 0.19453503316848408, 0.1794478607442812, 0.0, 0.6360473423391266, 0.5982068648905755, 0.5778279715114357, 0.6921258747256326, 0.4772000794179613, 0.0, 0.018758402544537867, 0.9324889235898018, 1.0, 0.5977762651528876, 1.0, 0.7056353963689815, 0.0, 0.0, 0.6957581361728042, 0.13924684459410952, 0.3879914700405447, 1.0, 0.6738921474874265, 0.07091595948797924, 0.6502039381924081, 0.8624965074015853, 1.0, 1.0, 0.6296283449385927, 1.0, 0.13228794765103824, 0.022410039654956804, 0.5826286460403656, 1.0, 0.0, 0.7784827278868942, 0.056162009903313104, 0.0, 0.4724363510005801, 1.0, 0.1674597445179885, 1.0, 1.0, 1.0, 0.41586133940794756, 0.9368700907920335, 1.0, 0.4740062659484451, 0.4512666140731144, 0.1308251425969127, 1.0, 0.0, 1.0, 0.18237662169551383, 0.10494339600016689, 0.14675753080288245, 1.0, 1.0, 1.0, 0.9539369363180226, 0.0691759250098859, 1.0, 1.0, 1.0, 0.8456535222773424, 0.0, 1.0, 0.623585037479306, 1.0, 1.0, 0.0, 0.8945947140438331, 0.44617655936627443, 1.0, 0.0, 0.8222281125770106, 1.0, 0.0, 1.0, 1.0, 0.7681587082852736, 0.7055627116496911, 0.30770281338984384, 0.24217465034747054, 0.07300359289962732, 0.7440285803476767, 1.0, 0.23449947767409374, 1.0, 1.0, 1.0, 1.0, 0.7502607940873155, 0.7254933264929218, 0.0, 0.9188357755362855, 0.4522024791035387, 0.0, 0.31348605695674747, 1.0, 0.8774521266031688, 0.7731835012587582, 1.0, 0.9682775081839688, 0.534966673409444, 0.03769772491485279, 0.1919321828839774, 0.6792754755400424, 0.43757062588207907, 1.0, 1.0, 1.0, 0.39864249421306397, 0.13707760648901102, 1.0, 1.0, 0.858761429838704, 1.0, 0.0, 0.8781204982186164, 0.9817249302764938, 0.9041353525781907, 0.06864866614787224, 1.0, 1.0, 0.0, 0.5375846256925658, 1.0, 0.5718448269698801, 1.0, 0.7760754122034105, 0.0, 0.5613524997539452, 0.9774962582088932, 0.8078656456839812, 0.0, 0.46295868525802575, 1.0, 1.0, 1.0, 0.0, 0.6853710910648012, 0.3259824651160327, 1.0, 0.9158075833506722, 0.7179326909401018, 1.0, 0.6737178484310535, 0.0, 0.0, 1.0, 0.8646523546027457, 1.0, 1.0, 0.4765264708322373, 1.0, 0.8609977948009223, 0.0, 1.0, 0.7877143583314087, 0.0, 0.8364209229856395, 0.5024656497627655, 1.0, 1.0, 1.0, 0.6059261954142473, 1.0, 0.12158413695503834, 0.04748321031540137, 0.7545369159024605, 0.0, 0.0, 0.29906463498200075, 0.8057264289981986, 1.0, 1.0, 0.345274651501557, 0.0, 0.0, 0.11822241207245987, 1.0, 1.0, 0.779491212863352, 0.0, 0.04918134008356856, 0.0, 0.7390814203498319, 1.0, 0.7347085702650257, 1.0, 1.0, 0.11582308223679427, 0.29404376341999283, 0.5036886093282389, 0.17084935971586013, 0.4918582813348057, 1.0, 0.522257873600464, 0.0, 1.0, 1.0, 0.6332632016094104, 1.0, 1.0, 0.0, 0.8259409191119182, 1.0, 1.0, 1.0, 0.0, 0.6714060726437369, 0.926308276921196, 0.3808319557569416, 0.0, 0.6888105035899871, 1.0, 1.0, 0.4259975194684281, 0.9677428248337157, 1.0, 0.4356046196610104, 0.06704337447177267, 0.0, 0.47391748158259706, 1.0, 0.7126656189865445, 1.0, 0.5286917254258788, 1.0, 1.0, 0.0, 1.0, 0.8006545105288169, 0.41236648727468106, 0.9277230524268234, 0.5757858627744116, 0.14634545105888808, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4560268887150325, 0.0, 0.8489238694760728, 1.0, 1.0, 0.1876738197529384, 0.6571610351945493, 0.8885123121612181, 0.0, 1.0, 1.0, 1.0, 0.5562286609077549, 1.0, 1.0, 0.0, 1.0, 0.6985369405411993, 0.4006270071280137, 0.20126378813447243, 0.8902366217957709, 1.0, 1.0, 0.5020081977391821, 0.4168721765471307, 0.0, 0.9454880725621737, 0.0, 0.4991989468413318, 1.0, 1.0, 0.912890710538566, 0.48738444167204287, 0.30858394248684795, 0.0, 1.0, 1.0, 0.8096630249049525, 1.0, 0.446441467337642, 0.0, 0.5691417246177293, 0.687808116213612, 0.2748888400666839, 0.20369933658486783, 1.0, 1.0, 1.0, 0.39861592931143663, 0.6607797016082162, 0.4554045512892506, 0.0, 1.0, 0.4459555450921018, 0.9799767702678124, 1.0, 0.6125335361782434, 0.5834215190184351, 0.0, 0.38079568270784514, 0.5197057412086442, 0.6617038454813468, 0.21912606467080087, 0.8871568128163786, 1.0, 0.48468951693630746, 0.0, 1.0, 0.0, 0.4686431682473048, 0.6042223203395692, 0.0, 1.0, 0.2996686838414908, 1.0, 1.0, 0.0, 0.680672373225737, 1.0, 0.5109707430450621, 0.5712357088853165, 0.9462180358226221, 0.9779141546988203, 1.0, 1.0, 0.6123048451609933, 0.86163179911181, 0.26183172946315636, 0.856964414776239, 0.938714635374035, 0.5076376964803742, 0.0, 0.14444887656412753, 1.0, 1.0, 0.06327544414650987, 0.4843234489229269, 0.502746113409122, 0.8215839034365042, 0.10815501457335674, 1.0, 1.0, 0.3258245840194487, 0.19173621739026647, 0.4445027198303686, 0.41608071073886466, 0.20699360124505817, 0.8514057478914739, 1.0, 1.0, 0.6803844137625221, 0.0, 0.8276751947812718, 0.0, 0.2109771554518658, 0.0, 0.14054712799554292, 0.2864737377445836, 1.0, 1.0, 0.8365308907609035, 1.0, 0.9285968815306384, 0.26125649038406973, 0.3062678870046147, 0.7349187156614274, 0.0, 0.19287056868961427, 0.09271481081026989, 0.5322228748561939, 0.8216415697789553, 1.0, 0.20810867620427076, 0.18842799564845192, 1.0, 0.9426896899895132, 0.8254101487528136, 0.7074262751619323, 1.0, 0.8983552751676653, 1.0, 0.1241073677137774, 0.12141490550497214, 0.7211323573568237, 0.8162153348920989, 0.32838549961660535, 1.0, 0.0247648775761512, 0.7511809729800681, 0.0, 0.27963631849320625, 0.8636296725324342, 1.0, 0.8131476551679849, 0.25747897614372484, 0.7744194946063033, 0.0, 1.0, 1.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.865281706631139E-4, 4.5608128090568467E-4, 0.0018798835249106416, 0.0029210326213620075, 0.004519509295742963, 0.005026552609803114, 0.007557710625221037, 0.008257382832161153, 0.011584010587923466, 0.013029567757083749, 0.017149781915198115, 0.018346676147552143, 0.019483177998893986, 0.02002635592582447, 0.021938182026471464, 0.022895766948426655, 0.02353249441409877, 0.025408188664670317, 0.027420309972657653, 0.029155186022088997, 0.030021332149071878, 0.030549457093379973, 0.03273641247363446, 0.03557086703554835, 0.03593867492155334, 0.03798156328985347, 0.038840584289834834, 0.04300695186693948, 0.04367990661247245, 0.04456382344867915, 0.04496144159155113, 0.04545250043579596, 0.049496853493666615, 0.05021443169045525, 0.050559187959538954, 0.05174846220992069, 0.05239129559486122, 0.053243964826296786, 0.056017694636790405, 0.05607171652354215, 0.05693810259302845, 0.05770292841589886, 0.05895173996162295, 0.06034848870649179, 0.06158625614185598, 0.06254222689736844, 0.06581176069057648, 0.06745541064754912, 0.06850540662697957, 0.0703830771243158, 0.07168246715142301, 0.07424087298838644, 0.07597312957426716, 0.07996539435930194, 0.0827154615243535, 0.08305795179908415, 0.08676731957854367, 0.08717946783183117, 0.08883171481992092, 0.08991624485970229, 0.0918708877100447, 0.09280017843937771, 0.0941519101256979, 0.09464012572212965, 0.09608666973962532, 0.09729448955464381, 0.09861690335806506, 0.09986682113617817, 0.10094119997752149, 0.10173837270729402, 0.10232532732204336, 0.10418540262811804, 0.10440412974808144, 0.10585323587790885, 0.10810689674343743, 0.10891834184673144, 0.11196093563988219, 0.1129316426860113, 0.11438023575822676, 0.1147969272512801, 0.11557572449802289, 0.11726561932657797, 0.11956199775205645, 0.12211151592428793, 0.12276054283779958, 0.12523357043282712, 0.12627707981777492, 0.12736419745316474, 0.12960065119544195, 0.1299299245357013, 0.1305012641171842, 0.13144849367971123, 0.1324046134964546, 0.13356133247235458, 0.13699906305367138, 0.1370894580787565, 0.1378228991592354, 0.138871326396517, 0.13911584889108752, 0.14217044670389556, 0.14386750098625656, 0.14479301498163, 0.14798414736583476, 0.1504657845120987, 0.15158429286987996, 0.15232958946453545, 0.15598086369893316, 0.1577692536560521, 0.157984338493256, 0.16003601971781745, 0.1614507850971718, 0.1617346404542951, 0.16246916592394434, 0.1652420504426032, 0.16562834702826534, 0.16605252148153637, 0.1663568658560416, 0.16716809813092426, 0.16833695591913023, 0.1690810703559925, 0.1702771336783756, 0.1706647585499984, 0.17129495782167037, 0.17208922929525938, 0.173185026203581, 0.1733479425393596, 0.17424340164537955, 0.17567310812073078, 0.1771709252718655, 0.17807336406007035, 0.18126499592572987, 0.1816304335186627, 0.181973250861307, 0.18472366890944003, 0.18602300000566563, 0.1896948481746772, 0.19081682886096896, 0.19197737009344706, 0.19281068120881195, 0.19395386726777486, 0.19688787177568357, 0.19865200812619144, 0.19964512097659337, 0.20021890457597835, 0.2055191821464939, 0.20730900318755796, 0.2079063662394568, 0.20853645911048102, 0.20984199485640942, 0.21059057808641435, 0.21088622768078813, 0.21111247116613618, 0.21323049664287264, 0.21523031817501204, 0.2160904531853075, 0.21798466506703273, 0.2197067903914004, 0.22190046078437287, 0.22327636952830732, 0.22642789826927967, 0.22735730009609878, 0.22769898483465711, 0.22848793800151235, 0.22917195121416212, 0.23148009591298824, 0.23199456468679036, 0.23276314710128876, 0.23341147602835666, 0.2358575991436871, 0.2370847085173401, 0.237517115524447, 0.2403823886994838, 0.2415749821308889, 0.2422312178245669, 0.24606965879799825, 0.24640536925424705, 0.24690742666758558, 0.24751007314041196, 0.24787335872842364, 0.24854705554065637, 0.2507162873042236, 0.2517671686681041, 0.2521614255879282, 0.2584316202918181, 0.25938840074319625, 0.2624342509071732, 0.2628197749927569, 0.2644943935124624, 0.2665132535078961, 0.2673647652991672, 0.2691819712881912, 0.2695075225177006, 0.27247076977490503, 0.2750188300759475, 0.2756825303233388, 0.27809951506635644, 0.2782784472828207, 0.279745967769071, 0.28084010305543106, 0.28191904290472913, 0.2828011306704997, 0.2849612811493162, 0.2882515771673685, 0.28988994357829334, 0.2925150910707418, 0.2939809923359754, 0.2956946740416042, 0.29639200687528344, 0.2970565590213232, 0.2984349123618767, 0.3002947939005238, 0.30048938560043237, 0.30168884277242725, 0.30247902916792657, 0.3040302724479996, 0.3046023557741905, 0.30666484626529333, 0.30883442400734085, 0.31092893000755417, 0.3130501450631469, 0.31370651205206523, 0.31514703913255326, 0.31755457986950175, 0.31830409469234733, 0.3204500728660916, 0.32162117714485816, 0.3225265851765271, 0.32387460241170973, 0.3240177244136446, 0.32415225353566357, 0.3256961935909516, 0.32582346077048474, 0.3322055709473216, 0.33579828692821434, 0.3369926538582241, 0.3375324658838189, 0.3403800926666749, 0.34180370549218253, 0.3485736672419705, 0.3495747511761357, 0.3524835351566369, 0.3542677648410466, 0.35574327634918845, 0.35618564711759415, 0.36037781993034756, 0.36167776020817344, 0.36346135324664564, 0.3639292362701749, 0.3674558900341721, 0.36791017049375774, 0.3683564849171084, 0.37116161478574183, 0.3720499472273642, 0.3773136614063236, 0.3802654285669108, 0.3803840730550777, 0.3806565458630886, 0.382068440153702, 0.3828442166043532, 0.38512011990250006, 0.38551422248836875, 0.3865268613608237, 0.388059494662669, 0.3898997462910806, 0.3906821109859392, 0.39297422534529125, 0.39344784656359155, 0.39385343506652026, 0.39451874947405463, 0.39679684708631646, 0.39883602970372944, 0.40022868502950204, 0.4009417624730467, 0.4014048925953292, 0.40276439846225187, 0.4042492718110433, 0.4051967853222104, 0.4061975191903845, 0.4076986289379043, 0.40877726122913205, 0.4097392364429391, 0.41085709184049646, 0.41516136831111794, 0.41533190983417523, 0.41701557383539756, 0.4185806216239353, 0.42011872784772497, 0.4229593355380892, 0.423944812913302, 0.4273571468844154, 0.42898493184089\u001b[0m\n",
      "\u001b[34m05, 0.43098390192082203, 0.43377056601801756, 0.4344500350785596, 0.43564479045650983, 0.43667535796695334, 0.4372883009776608, 0.43845671525057817, 0.44123405537560234, 0.44218677448893007, 0.4436719927429207, 0.44524611228478816, 0.4468880289416285, 0.4474863852172748, 0.45065735509724236, 0.4510195505583582, 0.45150027834852324, 0.45221530561668055, 0.45394684810835706, 0.4544148173308522, 0.4552277730172112, 0.45697856913323587, 0.4589971010723375, 0.4622170652586235, 0.46381424972767993, 0.4644332362255428, 0.4667820772311879, 0.4679783210157482, 0.4695186653456337, 0.46991537203359535, 0.4701187389114738, 0.4709500587725145, 0.4737215396617973, 0.4748865435062186, 0.4754066078500737, 0.4769152754182153, 0.4782598841952235, 0.47892680949161215, 0.4857989599906608, 0.4870778352252343, 0.48985161954367673, 0.49141817752855677, 0.49142071055242154, 0.49350099215440824, 0.4973124461689724, 0.49823600049927297, 0.4992890741633287, 0.5006970539856748, 0.5014292004942908, 0.5042962497681089, 0.5066726489827458, 0.508068899894271, 0.5116058699350604, 0.5122847572434851, 0.5138507345765979, 0.5146410168401129, 0.514683617121439, 0.5182761764476463, 0.5190939992469303, 0.5200740611111504, 0.5212341324853343, 0.5219530034785639, 0.5231430206971652, 0.5240322689883441, 0.5252584187815833, 0.5262784603382027, 0.5271028671890952, 0.5272261808398002, 0.5307373552868359, 0.5324926994371466, 0.5341742467768753, 0.5384770724113932, 0.5407345671331042, 0.5425343685322515, 0.5438057278662374, 0.5451055282606997, 0.5466852550992888, 0.5472375204206431, 0.5491303362771727, 0.549309771480104, 0.5496062685307567, 0.549883473525189, 0.5501577920274408, 0.5509152549890532, 0.5511469283252918, 0.5519903021207211, 0.552397059679783, 0.5536131097368052, 0.5561408115786989, 0.5572830332204729, 0.5587762863446735, 0.5608744633626176, 0.5644945456018406, 0.5656881721410058, 0.5661994877452282, 0.56945979049281, 0.5696628224910788, 0.5704040564239353, 0.5718091636071537, 0.5738412541045134, 0.5740622915330605, 0.5766140071297178, 0.5773439662110417, 0.5799959259185951, 0.5809320532627977, 0.5821832300925898, 0.584056095418145, 0.5844997955307902, 0.5850784422062031, 0.5854839351832077, 0.5861725346792042, 0.5886254285874106, 0.5918809431740769, 0.5923671420203442, 0.5934857629759347, 0.594248831384939, 0.5975533625663311, 0.5985543690868064, 0.6000947931958438, 0.600899811926277, 0.6021169853547795, 0.6024698307034551, 0.603291805714943, 0.6047940736900298, 0.6057553031390567, 0.6089572369418256, 0.6098318054986945, 0.6107707306850386, 0.6129212396643692, 0.614386487134352, 0.6151963827788968, 0.6177477480225416, 0.6189915646985882, 0.6193103188391342, 0.620872341624353, 0.6218992302125492, 0.6241949841539137, 0.6247400955573337, 0.6264903169616124, 0.6279933826040981, 0.6284340474189989, 0.6288304839804686, 0.630700471158785, 0.6320898295062423, 0.6331896260134641, 0.6344042989960332, 0.6352017808554705, 0.6360424687799683, 0.6378237452012717, 0.6379607933159701, 0.6401682238281661, 0.6401983115596238, 0.6425759689471896, 0.646090123462508, 0.6466059134228601, 0.6495867499898026, 0.6500550604703602, 0.6531140236356144, 0.6536782314109965, 0.6541601542860984, 0.656336807390897, 0.6617368946676516, 0.6625196743251018, 0.6627962742097216, 0.6665926778408895, 0.6673503980464284, 0.6706755253823256, 0.6729553558481822, 0.6737017335421565, 0.6743996518139815, 0.6761050258143518, 0.6769888016137862, 0.6791991512011694, 0.6807558929604856, 0.682153161561635, 0.6834132400913489, 0.6837541055770425, 0.6850804113870324, 0.685939205007268, 0.6883101714849585, 0.6897788492481212, 0.6921136179837506, 0.6938626591204068, 0.6954156483280532, 0.69698249301797, 0.6980832999224982, 0.7000342727721044, 0.7011428647409692, 0.7015650876381233, 0.7031307254397192, 0.7057332633628857, 0.7084896974927973, 0.7090137242870318, 0.710029881056391, 0.712777676216831, 0.7129600078588058, 0.7143004059552355, 0.7146412749087242, 0.7176357859086295, 0.7196655392084791, 0.7197914533546861, 0.7210619239265232, 0.7221548367934345, 0.7242425955587187, 0.7256153947974125, 0.7279471767307432, 0.7297119064974222, 0.7310410541735289, 0.7313165197032963, 0.7324138648126686, 0.7338319874844625, 0.7339053770018694, 0.7345779231214132, 0.7376570332190543, 0.7401613687614631, 0.7428249749063163, 0.743256503690242, 0.7439524348950457, 0.745860038627012, 0.7462072574818386, 0.7466428299403386, 0.7473539693787133, 0.7504756331617514, 0.7531873359134028, 0.7537558390293999, 0.7546212215985918, 0.7562705174756582, 0.758111116445854, 0.759344327922866, 0.7608543445144956, 0.7625963946941753, 0.7647644151980152, 0.7658290392349099, 0.767944260298844, 0.7685193645237912, 0.7704472210739898, 0.7732726176700367, 0.7736625648956658, 0.7737247491834002, 0.775911532807306, 0.7762904775159478, 0.7774554671823856, 0.7799883269105443, 0.780731853200901, 0.7813488406144062, 0.7816154791963991, 0.7830166373167329, 0.7837494718134711, 0.7839873586893554, 0.7848618229588802, 0.7853719267411972, 0.7869149913151918, 0.790014841559882, 0.7914116322589493, 0.7933940143053477, 0.7945985915219707, 0.7955594260504532, 0.7963328622273151, 0.7985932723827512, 0.7989348479500549, 0.801684293191305, 0.8041591874130811, 0.8059789008675837, 0.8067505847658318, 0.8082754395559376, 0.8087899845635385, 0.809183171139031, 0.810184697027844, 0.8167569301195281, 0.818260809290537, 0.8216274156926702, 0.8219266359399297, 0.8229584462214861, 0.8259183246885707, 0.8266569470247191, 0.8288712762529586, 0.8293916269585125, 0.8297631202876449, 0.8347058890298255, 0.8363161985346985, 0.8371849503231362, 0.839816162145531, 0.8461929753583922, 0.8471673613725742, 0.8484306284123264, 0.8502960320430423, 0.8504716147608377, 0.8514486375512653, 0.8518412368739476, 0.8527280198757112, 0.855034927620183, 0.8564934027625736, 0.8587219507244942, 0.8615137072268936, 0.8628805029124124, 0.8634657303414633, 0.8646603921404177, 0.8676276209650275, 0.8689442522791451, 0.8720483384470077, 0.8728002373125504, 0.8738749555210183, 0.8754056251218343, 0.8767674242836752, 0.87735561220526, 0.8779844969848348, 0.8782380888747252, 0.8794965707281264, 0.881125608822928, 0.8815849608240681, 0.8824594404560998, 0.8839773186518307, 0.8857142300020205, 0.8876956555887808, 0.8893909161288442, 0.8911066860189609, 0.8923858152401412, 0.8939852050469608, 0.8960751117945733, 0.8988473881802473, 0.9014170729775877, 0.9024856743591025, 0.9069428088348339, 0.9110687027673836, 0.9129610374123414, 0.9147311149565036, 0.916603301642411, 0.9172845384756465, 0.9187347106063773, 0.9226230580877897, 0.9243388960958892, 0.925178794805027, 0.9256373300253358, 0.9269163463311081, 0.9292884022620594, 0.9301709654384246, 0.9309704591121504, 0.9312871674817322, 0.933571083457648, 0.9363211539691568, 0.938894960041275, 0.9402835110291107, 0.9415453858914461, 0.9425459396769053, 0.9446657321710952, 0.9456092514776888, 0.9476611242134917, 0.9492086268705122, 0.9503127529305917, 0.9530200211788992, 0.9535350978515088, 0.9545967185313075, 0.9558244837207522, 0.9571624448808868, 0.959826518075929, 0.9622614466091567, 0.9663308217861273, 0.9673820516584335, 0.9685781784887271, 0.9696077268480954, 0.9707421536772481, 0.9724808148595847, 0.9753158427754154, 0.9771061750238798, 0.9789575070411041, 0.9820543214315082, 0.9838403128554378, 0.9841789082344176, 0.9858099506042328, 0.9863659760941785, 0.9867489664960895, 0.9876595923412518, 0.9888355313891645, 0.9897564134093346, 0.991588408870274, 0.9939112517601609, 0.9943341854704327, 0.9946538391456355, 0.9968321514192983, 0.9979814822517661, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009851627249352957, 0.036763346559868126, 0.09627603282472952, 0.11584385678025766, 0.1604001053300721, 0.18132057950015823, 0.23227611193321973, 0.25252778207541926, 0.31179213413340456, 0.32313065707027855, 0.3478767544695621, 0.3911697660803798, 0.40167273487757305, 0.4386072164895384, 0.4673974805992379, 0.4792789285762873, 0.5217300466362131, 0.5342422059764451, 0.5505661647862623, 0.5840926338530592, 0.597274072430341, 0.616604581862474, 0.6621120101065646, 0.7248265598740583, 0.7654387066651713, 0.7817903298450294, 0.8145411253233457, 0.8259207657998966, 0.8463419618388873, 0.8573600920924986, 0.8949214412278399, 0.9420795394412017, 0.9621219725920498, 0.9706055542434927, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \u001b[0m\n",
      "\u001b[34m1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_state_az\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.12673300557050346,\n",
      "      \"sum\" : 1040.3512427282628,\n",
      "      \"std_dev\" : 0.3034326100251395,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 6802.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 89.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 93.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 82.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 94.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 97.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 92.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 98.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 96.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 666.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014567154751278899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47833548167055584, 0.021021106726217154, 0.0, 1.0, 0.21225781169763014, 0.0, 0.8372372182218181, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7422935381702628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27061999469359665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7981581646362419, 0.7418960708395316, 0.8864593576737133, 0.0, 0.0, 0.0, 0.9027637879645087, 0.0, 0.0, 0.0, 0.0, 0.4542783967898225, 0.0, 0.0, 0.01596848572086984, 0.20351561067041923, 0.0, 0.0, 0.0, 0.0, 0.3092736848867369, 0.27121377774342403, 0.0, 0.0, 0.0, 0.2859005337712024, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6529729219079393, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.03684097293493349, 0.11475359941383545, 0.0, 0.0, 0.0, 0.0, 0.7922165790383086, 0.587697018287546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15624495601270638, 0.0, 0.0, 0.0, 0.0, 0.48987047671774453, 0.0, 0.26031710223689186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26843788043886607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6522751108990502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5717893159359805, 0.4340521760809567, 0.0, 0.0, 0.3543771829861353, 0.0, 0.2691203766777923, 0.0, 0.0, 0.9386648132933723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19575560640562462, 0.4868249177179641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8714035140394475, 1.0, 0.0, 0.0, 0.0, 0.6383529051589555, 0.0, 0.0, 0.642086507352399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1916051176959771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.43599518057058584, 0.0, 0.41034650484845236, 0.0, 0.0, 0.8226734467760606, 0.0, 0.0, 0.0, 0.0, 0.9853910028911171, 0.0, 1.0, 0.0, 0.0, 0.6911977246503846, 0.0, 0.734002306907342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9810545966256454, 0.0, 0.7916004263816684, 0.8670719572920174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5837372193120927, 0.0, 0.08827412308722427, 0.040288945734542114, 0.0, 0.0, 0.0, 0.379628747876279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.32855814988579846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.14722707441051697, 0.0, 0.6867335234193896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.400032141738934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3281600723536078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9435741440351771, 0.12874837260134742, 0.0, 0.0, 0.0, 0.013436885885589556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6928543518957885, 0.0, 0.04052781704458808, 0.0, 0.0, 0.19453503316848408, 0.0, 0.6766446348198475, 0.0, 0.0, 0.4221720284885643, 0.0, 0.0, 0.7930630283706559, 0.018758402544537867, 0.0, 0.0, 0.0, 0.46878988050679093, 0.0, 0.0, 0.8580057406479153, 0.0, 0.0, 0.0, 0.6936990031124625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30481253378993434, 0.37037165506140735, 0.0, 0.0, 0.0, 0.0, 0.004525847653185644, 0.0, 0.0, 0.0, 0.25563909379536154, 0.0, 0.82840363293481, 0.0, 0.4625935471051531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5320195375219566, 0.4107092453916662, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7463628843132415, 0.0, 0.0, 0.0, 0.0016437571124496841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5129793498209074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7227846006215212, 0.0, 0.0, 0.30770281338984384, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8919710425084207, 0.0, 0.0, 0.7254933264929218, 0.0, 0.0, 0.5477975208964613, 0.7390914219929531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8080678171160226, 0.0, 0.0, 0.7205546926810974, 0.7825001443802936, 0.11349747335809746, 0.0, 0.0, 0.0, 0.4653390769244762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.18492029746714433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6606771643442889, 0.0, 0.006216024621827909, 0.6853710910648012, 1.0, 0.0, 0.0, 0.0, 0.28360792341713625, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7378804151687424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3940738045857527, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5922213993314405, 0.0, 0.0, 0.552798967783562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20687146203694362, 0.0, 0.1859615075574177, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3004034669764718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4502824838315258, 0.5311094963375276, 0.2542823337952127, 0.0, 0.0, 0.9240729888456831, 0.17967591185279908, 0.0, 0.6714060726437369, 0.926308276921196, 0.0, 0.17519305202016933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06704337447177267, 0.0, 0.0, 0.24068914484979476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5868926022728558, 0.0, 0.0, 0.9277230524268234, 0.0, 0.14634545105888808, 0.7252870843545552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5439731112849675, 0.0, 0.0, 0.3972714728404597, 0.7544493740555089, 0.8123261802470616, 0.0, 0.11148768783878193, 0.0, 0.0, 0.2853043247642658, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5993729928719863, 0.0, 0.0, 0.8850936566380897, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5008010531586682, 0.21657918562724088, 0.0, 0.0, 0.48738444167204287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7251111599333161, 0.0, 0.832937392318661, 0.014231750414258837, 0.0, 0.0, 0.0, 0.0, 0.04106817279040542, 0.0, 0.4459555450921018, 0.0, 0.9374930584895892, 0.38746646382175665, 0.0, 0.4642039489521267, 0.0, 1.0, 0.0, 0.7808739353291991, 0.0, 0.0, 0.0, 0.026867654044935296, 0.0, 0.10612558549099549, 0.0, 0.6042223203395692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.680672373225737, 0.0, 0.0, 0.4287642911146835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.856964414776239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8421068624835116, 0.38586682381248194, 0.6741754159805513, 0.0, 0.0, 0.0, 1.0, 0.14859425210852606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7398678266004035, 0.7890228445481342, 0.8808934641232837, 0.14054712799554292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6937321129953853, 0.0, 0.3038075496989101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20810867620427076, 0.0, 0.0, 0.0, 0.0, 0.29257372483806765, 0.7117779449909495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8162153348920989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7280122577961974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013462709565636999, 0.006257471026470229, 0.006710390304059954, 0.009638218001628118, 0.013270898499151307, 0.015813196232962068, 0.02002635592582447, 0.029155186022088997, 0.032645677545668605, 0.03628762261350216, 0.041656818382682426, 0.04404037938846439, 0.04809231041203543, 0.057016183183957514, 0.057741051869173776, 0.058727551758148366, 0.060942904032812883, 0.06449127124916754, 0.07447779214811912, 0.07547753126810008, 0.0827154615243535, 0.08884024508756438, 0.09680922116557089, 0.09986682113617817, 0.10125991461515893, 0.1036785807342765, 0.11042338166950783, 0.11692353552539148, 0.12017808604830471, 0.12149539108776541, 0.12582931784297402, 0.12689115723577238, 0.12936611851650948, 0.13417983477764484, 0.1350801462257607, 0.1370894580787565, 0.14043476835305424, 0.14350659723742643, 0.1474422180984465, 0.15158429286987996, 0.15628370954977622, 0.15862414452637796, 0.1614507850971718, 0.1645921691578741, 0.16590102437078624, 0.1690810703559925, 0.17213162467782717, 0.1762219098988348, 0.1777663878512482, 0.1805182283924236, 0.1842513564957191, 0.19121001543646154, 0.1950089804386158, 0.1978694418724125, 0.20551436635150933, 0.20607061414003525, 0.21088622768078813, 0.21198249090223853, 0.21513817704111982, 0.21557914199658235, 0.21849435225781788, 0.2217819781923186, 0.22320951659277288, 0.22569731705540486, 0.22691095830253383, 0.23250116940929455, 0.23519902754072275, 0.23769096797806133, 0.23891169397612444, 0.24736170592816398, 0.24950307968274177, 0.2531242838641773, 0.2554933446556047, 0.25717502509368373, 0.26616801251553746, 0.2666751966619776, 0.26777667548833417, 0.2681390200955134, 0.27149875418186786, 0.2750188300759475, 0.27571985309555225, 0.28103808138102826, 0.2853587250912758, 0.29332446632230014, 0.2952782892203101, 0.2984349123618767, 0.304375347645942, 0.30690451319457, 0.3119840203264185, 0.3148258293516488, 0.31654966526787, 0.31755457986950175, 0.31912348982046257, 0.3198680688965486, 0.32387460241170973, 0.3256510209765311, 0.32854506510535675, 0.3326496019535716, 0.33314557898573216, 0.33748032567489816, 0.3376493019992346, 0.3397688271511179, 0.3403800926666749, 0.3417824047367617, 0.347507082425181, 0.34833208129357407, 0.3522868289370785, 0.35513164775381256, 0.35618564711759415, 0.3621229073363661, 0.36290916291909503, 0.36882935404329364, 0.3715659525810011, 0.3773136614063236, 0.37922653718044896, 0.3826482425870258, 0.3936290555666244, 0.39458824249241276, 0.39694797293429285, 0.39936874839469094, 0.40146842431563434, 0.4042397296442092, 0.40472506382965867, 0.4065142370240653, 0.4149604360796805, 0.4167334821869546, 0.4167425075438844, 0.41977848121497063, 0.4273571468844154, 0.4345800323922576, 0.4351803992553568, 0.43550545439815935, 0.4385384885374355, 0.4420725548492993, 0.4443653492415144, 0.44812286357881437, 0.44908474501094675, 0.4503839562810755, 0.4548944717393003, 0.46464189815733914, 0.4679783210157482, 0.46952554204386265, 0.47746028326794676, 0.4793544401378518, 0.4843405941435466, 0.4857989599906608, 0.4876996531129194, 0.49027575324830186, 0.4953809753923044, 0.4995226841332818, 0.5014292004942908, 0.5021536099619869, 0.5026875538310276, 0.5070824240602667, 0.508068899894271, 0.5121488028075936, 0.516424388218611, 0.5172393817143319, 0.5174995797646393, 0.5217401158047765, 0.5235635795298558, 0.5245933921499263, 0.5287244190984357, 0.5304813346543663, 0.5324926994371466, 0.5332513992791025, 0.5349447516993556, 0.5393301701665109, 0.5419900748897659, 0.5446168645193924, 0.5448477590845157, 0.5466963282963399, 0.5469632513713881, 0.5480323566642401, 0.549322479403174, 0.5498755675802404, 0.551186354253394, 0.5525136147827252, 0.5554954241058602, 0.5578132255110699, 0.5625552012730474, 0.5646757785447638, 0.5661994877452282, 0.5745873823177666, 0.5776154778156941, 0.5843578133140943, 0.5920168427890629, 0.5953596612586041, 0.5986939757802878, 0.5993689656629339, 0.600899811926277, 0.6017722060419883, 0.6070257746547087, 0.6092448476703629, 0.6099415585960517, 0.6107707306850386, 0.6127627288219041, 0.6133798273661658, 0.6197345714330892, 0.6243277481182735, 0.6267401855372411, 0.6300398784799822, 0.6329063306784342, 0.6353293237656634, 0.6361903588590665, 0.637246399600848, 0.6377319129014088, 0.6433290258582353, 0.6463033134192661, 0.6539940923398012, 0.6581962945078175, 0.6643261669609404, 0.6665926778408895, 0.6693086091618792, 0.6729553558481822, 0.6743996518139815, \u001b[0m\n",
      "\u001b[34m0.6764263623383923, 0.6818955530965279, 0.6853953434460057, 0.6880444438360138, 0.6906797711480066, 0.6927610381522795, 0.6946537728101754, 0.6972754190538569, 0.7019243494751772, 0.7026449517631611, 0.7062240938256092, 0.710029881056391, 0.712777676216831, 0.7171988693295003, 0.7231282738825542, 0.7231494864646295, 0.7262086924858935, 0.7306687016979749, 0.7313165197032963, 0.7371802250072431, 0.7375657490928268, 0.7439524348950457, 0.7460622280763038, 0.754107680316164, 0.7574644454507177, 0.7599292595124335, 0.7631083636013083, 0.7651603288167663, 0.7704472210739898, 0.7732726176700367, 0.7774554671823856, 0.7791973702143609, 0.780189268482995, 0.7817401273062705, 0.7837494718134711, 0.7850977140957076, 0.7882446493345217, 0.790014841559882, 0.7920436407106101, 0.7927577002311217, 0.7955391139452882, 0.7994470221547335, 0.8023607794088699, 0.810184697027844, 0.8106859279862663, 0.8171927633430995, 0.8219266359399297, 0.8231608307088593, 0.8251306676661152, 0.8260390516665719, 0.8273565548261456, 0.8288712762529586, 0.82941808844291, 0.8306885105200769, 0.8315556148572804, 0.8339656865838045, 0.8361189762195178, 0.8375308340760557, 0.8420744373985792, 0.8442487024058184, 0.8493125129991662, 0.8518220717700545, 0.855690799278397, 0.8587219507244942, 0.8689442522791451, 0.8708255547568896, 0.872546040577131, 0.8737288628922681, 0.8746435242076144, 0.8752859430886095, 0.8765991847944036, 0.8804380022479436, 0.8816156398779976, 0.8823560118406748, 0.8843765470229713, 0.8870683573139887, 0.8899367157988848, 0.8920562853535356, 0.8955958702519186, 0.8982380639532351, 0.900697797246307, 0.9015830052870676, 0.9077354331775127, 0.9103736608450579, 0.9128924447365754, 0.9160804641785706, 0.9183327241399037, 0.9253615689205712, 0.9291084241087146, 0.9303188848378237, 0.9314945933730204, 0.9349944318387654, 0.9381142983195248, 0.9404485057361726, 0.9409061099217467, 0.9423834540022769, 0.9444749671908494, 0.9476087044051388, 0.954547499564204, 0.9552215494953318, 0.9577082507773188, 0.9686746055743571, 0.9696077268480954, 0.9715330423905887, 0.9724808148595847, 0.9751799759755083, 0.9758898065913332, 0.9778585245273705, 0.980516822001106, 0.9819691904461453, 0.984257087004323, 0.9865973735678344, 0.9903131172590323, 0.9933369373586285, 0.9970781570816617, 0.9996674938795106, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009072404652724964, 0.03665316717960099, 0.06913278618661944, 0.09218134701535985, 0.12816722102687883, 0.15616384479217393, 0.1623818946623209, 0.21632402303655351, 0.2541629879690357, 0.2844466847657581, 0.40167273487757305, 0.42058510065649923, 0.45369363460528267, 0.4677550111737009, 0.5399058395022125, 0.608369859459644, 0.6709825621853378, 0.7353502986657526, 0.7713748384750765, 0.8145411253233457, 0.9412375042323865, 0.9826202098145204, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"total_claim_amount\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 20860.98331100012,\n",
      "      \"sum\" : 1.71247812E8,\n",
      "      \"std_dev\" : 15979.639779234016,\n",
      "      \"min\" : 1000.0,\n",
      "      \"max\" : 173000.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1000.0,\n",
      "            \"upper_bound\" : 18200.0,\n",
      "            \"count\" : 5126.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 18200.0,\n",
      "            \"upper_bound\" : 35400.0,\n",
      "            \"count\" : 1680.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 35400.0,\n",
      "            \"upper_bound\" : 52600.0,\n",
      "            \"count\" : 948.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 52600.0,\n",
      "            \"upper_bound\" : 69800.0,\n",
      "            \"count\" : 355.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 69800.0,\n",
      "            \"upper_bound\" : 87000.0,\n",
      "            \"count\" : 76.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 87000.0,\n",
      "            \"upper_bound\" : 104200.0,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 104200.0,\n",
      "            \"upper_bound\" : 121400.0,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 121400.0,\n",
      "            \"upper_bound\" : 138600.0,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 138600.0,\n",
      "            \"upper_bound\" : 155800.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 155800.0,\n",
      "            \"upper_bound\" : 173000.0,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 4248.0, 16000.0, 17890.0, 11000.0, 41292.0, 10000.0, 2492.0, 5623.0, 17933.0, 7000.0, 17707.0, 13000.0, 8739.0, 4000.0, 11000.0, 9087.0, 6787.0, 5925.0, 16918.0, 16771.0, 2747.0, 25686.0, 11000.0, 6142.0, 22257.0, 10377.0, 18200.0, 17807.0, 12572.0, 18523.0, 12500.0, 14000.0, 8402.0, 12500.0, 8500.0, 6025.0, 17723.0, 16260.0, 12500.0, 14000.0, 27080.0, 11443.0, 26200.0, 14000.0, 11000.0, 11548.0, 66553.0, 10274.0, 12500.0, 10000.0, 2272.0, 12774.0, 14000.0, 6000.0, 4398.0, 18243.0, 28534.0, 33086.0, 10000.0, 18000.0, 21220.0, 18000.0, 6071.0, 17954.0, 8142.0, 10663.0, 12415.0, 14000.0, 17000.0, 16000.0, 54843.0, 17826.0, 16000.0, 35199.0, 24545.0, 17834.0, 14000.0, 15000.0, 9981.0, 17442.0, 12745.0, 12084.0, 27550.0, 11191.0, 17103.0, 18000.0, 27612.0, 27831.0, 10000.0, 7281.0, 7813.0, 43644.0, 23687.0, 16000.0, 28187.0, 7519.0, 7365.0, 19000.0, 28130.0, 11130.0, 13000.0, 8000.0, 11000.0, 16000.0, 34453.0, 4000.0, 10313.0, 18956.0, 12033.0, 13000.0, 13000.0, 59846.0, 24326.0, 23540.0, 12337.0, 48211.0, 10784.0, 25292.0, 7316.0, 12500.0, 11000.0, 14000.0, 16000.0, 2214.0, 18282.0, 34872.0, 16000.0, 32050.0, 12651.0, 14000.0, 16000.0, 65295.0, 5969.0, 18000.0, 4121.0, 11000.0, 7000.0, 7000.0, 27264.0, 11000.0, 12500.0, 18372.0, 16500.0, 9978.0, 13000.0, 8000.0, 14127.0, 17500.0, 16597.0, 18000.0, 4065.0, 8279.0, 8341.0, 14000.0, 16000.0, 30182.0, 57893.0, 6319.0, 23038.0, 13000.0, 10500.0, 15545.0, 13000.0, 16500.0, 6128.0, 3713.0, 10530.0, 16984.0, 16500.0, 8319.0, 16437.0, 14000.0, 3142.0, 15000.0, 11247.0, 15439.0, 14000.0, 8500.0, 16500.0, 31329.0, 16500.0, 11147.0, 19000.0, 10000.0, 1493.0, 12409.0, 23976.0, 12192.0, 28730.0, 17797.0, 8705.0, 11033.0, 42263.0, 9588.0, 7000.0, 16000.0, 19285.0, 4289.0, 17000.0, 50126.0, 3697.0, 19000.0, 8000.0, 17154.0, 17646.0, 8867.0, 18000.0, 14000.0, 32585.0, 11000.0, 13000.0, 11000.0, 16591.0, 9509.0, 11000.0, 11500.0, 23901.0, 16000.0, 13000.0, 16000.0, 14000.0, 12000.0, 13000.0, 40778.0, 13000.0, 9708.0, 8000.0, 22911.0, 18000.0, 36048.0, 8500.0, 12534.0, 3240.0, 13000.0, 7958.0, 16192.0, 8000.0, 12556.0, 16075.0, 3924.0, 8164.0, 8472.0, 15000.0, 25830.0, 14500.0, 11000.0, 13000.0, 23582.0, 8573.0, 16000.0, 18000.0, 46683.0, 37928.0, 11503.0, 16738.0, 16000.0, 14906.0, 17912.0, 11000.0, 11000.0, 27495.0, 7071.0, 31090.0, 14000.0, 7987.0, 14000.0, 23483.0, 12866.0, 16000.0, 11958.0, 2299.0, 10000.0, 15000.0, 10000.0, 7000.0, 18000.0, 7136.0, 15044.0, 12951.0, 12426.0, 11835.0, 60435.0, 18000.0, 14500.0, 32538.0, 16500.0, 16968.0, 8088.0, 16997.0, 7000.0, 10000.0, 16500.0, 12882.0, 11500.0, 24579.0, 9855.0, 6674.0, 8000.0, 18506.0, 24809.0, 17500.0, 25236.0, 18000.0, 27861.0, 14000.0, 4640.0, 19000.0, 19673.0, 33427.0, 18000.0, 7000.0, 3661.0, 7000.0, 13000.0, 8711.0, 15653.0, 11000.0, 16896.0, 11009.0, 12500.0, 31570.0, 11298.0, 23703.0, 41350.0, 15000.0, 6000.0, 74938.0, 7000.0, 2836.0, 26509.0, 15336.0, 14000.0, 15000.0, 14000.0, 12883.0, 30933.0, 8685.0, 28068.0, 8500.0, 15988.0, 15000.0, 14000.0, 11000.0, 17610.0, 10000.0, 2372.0, 15000.0, 18914.0, 14416.0, 4268.0, 16000.0, 28060.0, 6415.0, 18000.0, 37429.0, 15000.0, 8225.0, 14000.0, 16000.0, 2935.0, 24205.0, 8091.0, 8947.0, 17926.0, 12836.0, 15000.0, 28138.0, 10500.0, 10965.0, 33927.0, 18126.0, 30597.0, 27500.0, 14000.0, 16500.0, 6623.0, 35082.0, 12500.0, 11000.0, 7552.0, 11000.0, 16756.0, 11000.0, 7000.0, 24988.0, 8000.0, 30042.0, 8500.0, 18000.0, 15000.0, 19000.0, 16500.0, 18000.0, 18000.0, 25655.0, 10000.0, 34255.0, 34575.0, 17945.0, 11500.0, 27500.0, 11637.0, 14000.0, 15000.0, 6452.0, 8869.0, 14843.0, 10000.0, 10000.0, 16500.0, 34955.0, 85294.0, 17000.0, 14000.0, 17095.0, 14000.0, 11000.0, 14000.0, 4108.0, 16556.0, 16800.0, 16431.0, 75149.0, 19000.0, 42059.0, 26359.0, 60425.0, 15560.0, 14000.0, 15000.0, 17000.0, 8500.0, 15000.0, 12000.0, 7731.0, 22462.0, 4000.0, 7000.0, 10000.0, 16500.0, 4000.0, 7000.0, 10000.0, 16631.0, 13000.0, 9580.0, 22339.0, 17500.0, 6993.0, 8500.0, 8837.0, 12577.0, 15000.0, 14000.0, 32440.0, 10000.0, 18000.0, 3141.0, 10978.0, 16500.0, 16000.0, 11000.0, 11000.0, 18000.0, 18430.0, 5059.0, 25585.0, 1636.0, 10000.0, 14500.0, 41214.0, 18492.0, 18598.0, 17500.0, 3802.0, 16000.0, 11939.0, 18000.0, 13000.0, 9277.0, 3092.0, 16350.0, 27500.0, 17776.0, 17585.0, 15000.0, 12294.0, 12331.0, 4440.0, 16000.0, 14000.0, 15389.0, 3907.0, 16500.0, 15000.0, 11000.0, 34212.0, 3867.0, 11500.0, 28426.0, 15000.0, 29411.0, 34496.0, 12085.0, 14000.0, 12689.0, 74317.0, 12000.0, 9616.0, 14000.0, 15000.0, 14000.0, 34361.0, 2754.0, 6825.0, 13000.0, 28272.0, 11500.0, 4938.0, 4164.0, 3889.0, 18380.0, 3649.0, 19311.0, 28224.0, 33516.0, 10287.0, 7000.0, 10671.0, 16282.0, 18067.0, 16500.0, 15000.0, 24120.0, 18287.0, 33613.0, 13000.0, 31164.0, 4189.0, 8000.0, 23880.0, 14500.0, 12500.0, 18000.0, 14000.0, 18000.0, 18137.0, 12500.0, 15000.0, 14398.0, 8227.0, 10000.0, 9228.0, 5268.0, 16500.0, 11500.0, 11500.0, 8906.0, 13000.0, 17444.0, 8000.0, 17790.0, 22000.0, 23698.0, 18000.0, 14641.0, 28176.0, 10061.0, 30237.0, 11000.0, 17200.0, 19698.0, 16000.0, 14000.0, 17500.0, 13000.0, 30209.0, 4210.0, 16500.0, 2471.0, 1500.0, 22541.0, 14509.0, 11000.0, 4256.0, 10000.0, 11000.0, 28312.0, 9585.0, 24666.0, 13000.0, 8500.0, 15000.0, 15000.0, 6687.0, 2812.0, 18203.0, 27998.0, 11500.0, 14000.0, 14000.0, 14000.0, 7000.0, 9979.0, 13000.0, 4277.0, 15000.0, 14000.0, 8693.0, 12291.0, 8732.0, 27690.0, 8740.0, 28713.0, 9609.0, 15000.0, 17500.0, 18515.0, 9986.0, 15000.0, 3946.0, 10765.0, 22719.0, 15000.0, 41680.0, 10000.0, 28481.0, 14000.0, 10809.0, 17000.0, 44166.0, 14000.0, 8714.0, 16500.0, 16000.0, 71286.0, 31163.0, 16193.0, 11430.0, 58449.0, 3785.0, 11000.0, 14000.0, 14850.0, 11927.0, 16000.0, 26798.0, 17968.0, 14757.0, 15000.0, 4089.0, 17000.0, 19000.0, 14000.0, 3662.0, 7000.0, 56332.0, 16291.0, 2413.0, 9925.0, 15000.0, 25897.0, 1479.0, 5862.0, 18000.0, 5869.0, 3605.0, 2238.0, 11929.0, 12143.0, 10259.0, 14000.0, 14081.0, 36069.0, 84679.0, 16500.0, 6306.0, 14000.0, 5651.0, 2210.0, 12046.0, 27500.0, 15000.0, 10550.0, 11895.0, 15000.0, 28634.0, 10000.0, 16087.0, 1292.0, 3135.0, 14949.0, 14791.0, 8500.0, 10560.0, 28149.0, 18000.0, 8164.0, 22512.0, 11000.0, 14000.0, 8000.0, 8139.0, 11000.0, 15087.0, 7593.0, 15000.0, 12500.0, 12000.0, 12753.0, 13000.0 ], [ 173000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1135.0, 1461.0, 1467.0, 1500.0, 1500.0, 1521.0, 1557.0, 1635.0, 1717.0, 1763.0, 1844.0, 2000.0, 2000.0, 2000.0, 2240.0, 2293.0, 2342.0, 2362.0, 2414.0, 2428.0, 2504.0, 2649.0, 2826.0, 2843.0, 2925.0, 3000.0, 3000.0, 3137.0, 3196.0, 3279.0, 3374.0, 3475.0, 3500.0, 3500.0, 3500.0, 3515.0, 3587.0, 3600.0, 3601.0, 3618.0, 3674.0, 3693.0, 3707.0, 3752.0, 3806.0, 3857.0, 3904.0, 3926.0, 3944.0, 3969.0, 3983.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4003.0, 4025.0, 4087.0, 4102.0, 4147.0, 4152.0, 4231.0, 4246.0, 4256.0, 4285.0, 4316.0, 4343.0, 4397.0, 4433.0, 4450.0, 4470.0, 4487.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4702.0, 4889.0, 5000.0, 5000.0, 5000.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5529.0, 5551.0, 5603.0, 5677.0, 5707.0, 5768.0, 5801.0, 5868.0, 5937.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6052.0, 6159.0, 6240.0, 6293.0, 6324.0, 6456.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6512.0, 6515.0, 6634.0, 6706.0, 6761.0, 6766.0, 6808.0, 6874.0, 6924.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7005.0, 7132.0, 7156.0, 7210.0, 7261.0, 7292.0, 7312.0, 7363.0, 7383.0, 7390.0, 7430.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7529.0, 7611.0, 7675.0, 7691.0, 7704.0, 7778.0, 7809.0, 7849.0, 7935.0, 7956.0, 7996.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8053.0, 8098.0, 8161.0, 8245.0, 8278.0, 8316.0, 8317.0, 8361.0, 8398.0, 8448.0, 8465.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8597.0, 8652.0, 8685.0, 8751.0, 8776.0, 8822.0, 8837.0, 8840.0, 8879.0, 8934.0, 8941.0, 8965.0, 8988.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9047.0, 9107.0, 9182.0, 9341.0, 9439.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9509.0, 9530.0, 9542.0, 9571.0, 9575.0, 9598.0, 9609.0, 9612.0, 9633.0, 9654.0, 9707.0, 9755.0, 9765.0, 9790.0, 9801.0, 9810.0, 9822.0, 9836.0, 9840.0, 9846.0, 9864.0, 9892.0, 9901.0, 9914.0, 9924.0, 9941.0, 9975.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10023.0, 10074.0, 10186.0, 10199.0, 10243.0, 10279.0, 10385.0, 10396.0, 10411.0, 10421.0, 10431.0, 10451.0, 10455.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10608.0, 10647.0, 10676.0, 10729.0, 10761.0, 10781.0, 10859.0, 10904.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11066.0, 11136.0, 11162.0, 11208.0, 11221.0, 11258.0, 11272.0, 11277.0, 11299.0, 11354.0, 11390.0, 11414.0, 11495.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11531.0, 11559.0, 11604.0, 11637.0, 11648.0, 11672.0, 11740.0, 11799.0, 11825.0, 11900.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12010.0, 12033.0, 12048.0, 12099.0, 12205.0, 12229.0, 12261.0, 12357.0, 12422.0, 12463.0, 12482.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12509.0, 12511.0, 12517.0, 12535.0, 12588.0, 12615.0, 12633.0, 12674.0, 12683.0, 12767.0, 12774.0, 12789.0, 12811.0, 12826.0, 12833.0, 12844.0, 12860.0, 12883.0, 12916.0, 12935.0, 12947.0, 12969.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13147.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13665.0, 13965.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14011.0, 14019.0, 14117.0, 14168.0, 14238.0, 14259.0, 14436.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14520.0, 14538.0, 14623.0, 14685.0, 14700.0, 14707.0, 14764.0, 14795.0, 14889.0, 14897.0, 14946.0, 14974.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15008.0, 15058.0, 15257.0, 15304.0, 15378.0, 15460.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15587.0, 15672.0, 15726.0, 15903.0, 15974.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16005.0, 16025.0, 16086.0, 16108.0, 16131.0, 16160.0, 16205.0, 16243.0, 16260.0, 16284.0, 16344.0, 16360.0, 16380.0, 16450.0, 16491.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16518.0, 16549.0, 16589.0, 16591.0, 16634.0, 16642.0, 16655.0, 16713.0, 16726.0, 16742.0, 16766.0, 16789.0, 16842.0, 16861.0, 16890.0, 16937.0, 16962.0, 16965.0, 16970.0, 16985.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17043.0, 17109.0, 17151.0, 17184.0, 17195.0, 17230.0, 17237.0, 17248.0, 17265.0, 17277.0, 17333.0, 17366.0, 17373.0, 17388.0, 17393.0, 17448.0, 17465.0, 17497.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17503.0, 17640.0, 17647.0, 17659.0, 17729.0, 17738.0, 17827.0, 17840.0, 17850.0, 17925.0, 17936.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18145.0, 18172.0, 18225.0, 18267.0, 18298.0, 18360.0, 18498.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18564.0, 18574.0, 18595.0, 18613.0, 18649.0, 18688.0, 18716.0, 18749.0, 18783.0, 18821.0, 18862.0, 18873.0, 18891.0, 18925.0, 18938.0, 18945.0, 18997.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19088.0, 19196.0, 19219.0, 19453.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19533.0, 19559.0, 19700.0, 19745.0, 19838.0, 19861.0, 19910.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20121.0, 20253.0, 20442.0, 20500.0, 20500.0, 20500.0, 20500.0, 20556.0, 20660.0, 20847.0, 20874.0, 21000.0, 21000.0, 21000.0, 21002.0, 21197.0, 21237.0, 21375.0, 21500.0, 21660.0, 21747.0, 21912.0, 21979.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0,\n",
      " 22015.0, 22090.0, 22156.0, 22189.0, 22232.0, 22263.0, 22301.0, 22343.0, 22450.0, 22465.0, 22551.0, 22577.0, 22664.0, 22671.0, 22724.0, 22778.0, 22810.0, 22897.0, 22923.0, 22933.0, 22952.0, 22990.0, 23022.0, 23028.0, 23214.0, 23234.0, 23320.0, 23421.0, 23438.0, 23464.0, 23500.0, 23500.0, 23510.0, 23591.0, 23659.0, 23766.0, 23839.0, 23916.0, 23969.0, 24000.0, 24049.0, 24187.0, 24198.0, 24228.0, 24263.0, 24282.0, 24299.0, 24337.0, 24355.0, 24372.0, 24426.0, 24458.0, 24486.0, 24663.0, 24879.0, 24987.0, 25016.0, 25113.0, 25151.0, 25181.0, 25285.0, 25292.0, 25360.0, 25394.0, 25450.0, 25469.0, 25480.0, 25500.0, 25500.0, 25500.0, 25500.0, 25564.0, 25652.0, 25737.0, 25749.0, 25782.0, 25867.0, 25902.0, 25906.0, 25963.0, 26021.0, 26321.0, 26424.0, 26500.0, 26500.0, 26500.0, 26602.0, 26732.0, 26798.0, 26998.0, 27114.0, 27167.0, 27257.0, 27394.0, 27487.0, 27500.0, 27529.0, 27570.0, 27574.0, 27591.0, 27648.0, 27738.0, 27747.0, 27777.0, 27817.0, 27882.0, 27906.0, 27973.0, 28000.0, 28003.0, 28069.0, 28105.0, 28117.0, 28136.0, 28175.0, 28248.0, 28260.0, 28279.0, 28312.0, 28326.0, 28381.0, 28401.0, 28430.0, 28782.0, 28963.0, 29007.0, 29562.0, 29634.0, 29735.0, 29762.0, 29798.0, 29859.0, 29927.0, 29976.0, 30087.0, 30108.0, 30163.0, 30266.0, 30404.0, 30508.0, 30583.0, 30606.0, 30754.0, 30821.0, 31000.0, 31000.0, 31000.0, 31052.0, 31120.0, 31162.0, 31215.0, 31316.0, 31368.0, 31391.0, 31500.0, 31532.0, 31657.0, 31795.0, 31940.0, 31972.0, 32244.0, 32551.0, 32556.0, 32589.0, 32694.0, 32714.0, 32872.0, 32905.0, 32957.0, 33052.0, 33169.0, 33206.0, 33343.0, 33408.0, 33471.0, 33500.0, 33594.0, 33797.0, 33992.0, 34000.0, 34187.0, 34306.0, 34406.0, 34508.0, 34524.0, 34568.0, 34720.0, 34750.0, 34762.0, 34895.0, 34947.0, 34997.0, 35279.0, 35401.0, 35469.0, 35556.0, 35703.0, 35730.0, 35911.0, 35931.0, 36185.0, 36328.0, 36500.0, 36675.0, 36875.0, 37156.0, 37427.0, 37437.0, 37486.0, 37571.0, 37588.0, 37626.0, 37678.0, 37789.0, 37815.0, 37896.0, 37967.0, 38000.0, 38308.0, 38391.0, 38436.0, 38544.0, 38563.0, 38735.0, 38767.0, 38883.0, 38917.0, 39100.0, 39263.0, 39479.0, 39511.0, 39520.0, 39644.0, 39975.0, 40015.0, 40040.0, 40133.0, 40197.0, 40415.0, 40598.0, 40680.0, 40823.0, 40945.0, 40993.0, 41084.0, 41161.0, 41260.0, 41500.0, 41543.0, 41657.0, 41795.0, 41865.0, 41939.0, 41996.0, 42170.0, 42291.0, 42418.0, 42500.0, 42730.0, 42888.0, 43000.0, 43161.0, 43242.0, 43667.0, 43709.0, 43801.0, 43879.0, 44000.0, 44052.0, 44108.0, 44212.0, 44364.0, 44615.0, 44733.0, 44781.0, 44904.0, 44958.0, 45202.0, 45382.0, 45790.0, 45937.0, 46000.0, 46014.0, 46115.0, 46353.0, 46567.0, 46651.0, 47019.0, 47142.0, 47277.0, 47377.0, 47500.0, 47520.0, 47613.0, 47693.0, 47840.0, 47923.0, 48000.0, 48132.0, 48243.0, 48274.0, 48360.0, 48449.0, 48599.0, 48678.0, 49029.0, 49138.0, 49143.0, 49447.0, 49528.0, 49607.0, 49821.0, 49932.0, 50150.0, 50262.0, 50377.0, 50691.0, 50753.0, 51357.0, 51529.0, 52000.0, 52081.0, 52364.0, 52667.0, 52761.0, 52942.0, 53122.0, 53500.0, 53562.0, 53701.0, 53893.0, 54082.0, 54246.0, 54323.0, 54455.0, 54508.0, 54613.0, 54690.0, 54833.0, 55227.0, 55333.0, 55442.0, 56027.0, 56128.0, 56233.0, 56323.0, 56554.0, 56617.0, 56713.0, 57095.0, 57109.0, 57873.0, 58174.0, 58455.0, 58586.0, 58626.0, 59798.0, 59949.0, 60285.0, 60422.0, 60679.0, 61121.0, 62462.0, 63562.0, 63743.0, 64346.0, 64711.0, 65182.0, 66857.0, 67000.0, 67659.0, 67782.0, 68000.0, 68293.0, 68662.0, 69629.0, 71013.0, 74503.0, 77803.0, 80341.0, 82309.0, 82771.0, 83328.0, 84206.0, 84506.0, 84947.0, 86454.0, 87424.0, 90023.0, 112172.0 ], [ 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1500.0, 1500.0, 2000.0, 2000.0, 2000.0, 2000.0, 2000.0, 2500.0, 2500.0, 2500.0, 2500.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3081.0, 3500.0, 3500.0, 3500.0, 3500.0, 3500.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 5500.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6000.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7000.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7500.0, 7712.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 8500.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 9500.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 10500.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11000.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 11500.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 12500.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14000.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 14500.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 15500.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 16500.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17000.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18000.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 18500.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19000.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19500.0, 19734.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 20500.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21000.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 21500.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22000.0, 22005.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22588.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23000.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 23500.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24350.0, 24500.0, 24500.0, 24500.0, 24500.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25000.0, 25432.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25798.0, 26000.0, 26000.0, 26000.0, 26000.0, 26149.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 27000.0, 27000.0, 27000.0, 27000.0, 27275.0, 27500.0, 27500.0, 27500.0, 27500.0, 27704.0, 28000.0, 28000.0, 28000.0, 28205.0, 28500.0, 28500.0, 28500.0, 28500.0, 29000.0, 29000.0, 29000.0, 29000.0, 29223.0, 29500.0, 29500.0, 29500.0, 29500.0, 29692.0, 30000.0, 30000.0, 30000.0, 30000.0, 30500.0, 30500.0, 30500.0, 30500.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31191.0, 31500.0, 31500.0, 31500.0, 31500.0, 31500.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33000.0, 33500.0, 33500.0, 33500.0, 33500.0, 33500.0, 33500.0, 33767.0, 34000.0, 34000.0, 34000.0, 34000.0, 34054.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 35000.0, 35000.0, 35000.0, 35000.0, 35329.0, 35500.0, 35500.0, 35500.0, 35500.0, 35500.0, 35702.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36500.0, 36500.0, 36500.0, 36500.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37500.0, 37500.0, 37500.0, 37500.0, 37500.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38218.0, 38500.0, 38500.0, 38500.0, 38500.0, 38523.0, 39000.0, 39000.0, 39000.0, 39000.0, 39000.0, 39012.0, 39500.0, 39500.0, 39500.0, 39500.0, 39500.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40500.0, 40500.0, 40500.0, 40500.0, 40500.0, 41000.0, 41000.0, 41000.0, 41000.0, 41000.0, 41000.0, 41000.0, 41500.0, 41500.0, 41500.0, 41500.0, 41500.0, 41500.0, 41500.0, 41821.0, 42000.0, 42000.0, 42000.0, 42000.0, 42000.0, 42000.0, 42022.0, 42500.0, 42500.0, 42500.0, 42500.0, 42500.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 43500.0, 43500.0, 43500.0, 43500.0, 44000.0, 44000.0, 44000.0, 44000.0, 44500.0, 44500.0, 44500.0, 44500.0, 44500.0, 45000.0, 45000.0, 45000.0, 45000.0, 45000.0, 45500.0, 45500.0, 45500.0, 46000.0, 46000.0, 46000.0, 46500.0, 46500.0, 46500.0, 46500.0, 47000.0, 47000.0, 47000.0, 47000.0, 47000.0, 47198.0, 47500.0, 47500.0, 47500.0, 47500.0, 47500.0, 47850.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48500.0, 48500.0, 48500.0, 48500.0, 48612.0, 49000.0, 49000.0, 49000.0, 49500.0, 49500.0, 49500.0, 49500.0, 49500.0, 49500.0, 50000.0, 50000.0, 50000.0, 50500.0, 50500.0, 50500.0, 50500.0, 51000.0, 51000.0, 51500.0, 51500.0, 51982.0, 52000.0, 52000.0, 52000.0, 52500.0, 53000.0, 53000.0, 53500.0, 53500.0, 53500.0, 53500.0, 54000.0, 54000.0, 54000.0, 54500.0, 54500.0, 54500.0, 55000.0, 55197.0, 55500.0, 55500.0, 56000.0, 56000.0, 56500.0, 56500.0, 56500.0, 57000.0, 57000.0, 57500.0, 57500.0, 58000.0, 58500.0, 58500.0, 58500.0, 59000.0, 59000.0, 59500.0, 59500.0, 60000.0, 60500.0, 61000.0, 61000.0, 61000.0, 61838.0, 62000.0, 62000.0, 62500.0, 63000.0, 63500.0, 64000.0, 64365.0, 64500.0, 65500.0, 65500.0, 65500.0, 66000.0, 66500.0, 66500.0, 67000.0, 67000.0, 68000.0, 68000.0, 68000.0, 68500.0, 69056.0, 70000.0, 71000.0, 72000.0, 74000.0, 75000.0, 76000.0, 77500.0, 78500.0, 80000.0, 82500.0, 84000.0, 85000.0, 90500.0, 95500.0, 98500.0, 127500.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"customer_gender_male\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.6079017599917611,\n",
      "      \"sum\" : 4990.2655477723665,\n",
      "      \"std_dev\" : 0.4726012094280717,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 2932.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 58.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 69.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 74.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 66.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 88.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 81.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 80.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 66.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 4695.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7526002529416542, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9789788932737828, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4570018673947307, 0.6261918911329976, 1.0, 1.0, 0.14296087760075216, 1.0, 1.0, 1.0, 1.0, 0.14519422120073855, 1.0, 0.1164352716298096, 1.0, 1.0, 0.525565106379265, 1.0, 0.025809392863181735, 1.0, 1.0, 0.005418010964740039, 0.7981581646362419, 1.0, 1.0, 0.0, 0.7778112444584507, 1.0, 0.9027637879645087, 1.0, 1.0, 0.3303914736656165, 1.0, 1.0, 0.5484344133944249, 1.0, 0.01596848572086984, 0.7964843893295808, 0.7567580902469283, 0.31944183822089856, 1.0, 1.0, 1.0, 1.0, 0.046972991098139794, 0.07194824977115188, 1.0, 1.0, 1.0, 0.16987259440447633, 1.0, 1.0, 1.0, 0.41367867898526034, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.45013582163560184, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.587697018287546, 1.0, 1.0, 1.0, 0.43705152184218765, 0.6277454148973364, 1.0, 1.0, 1.0, 1.0, 0.03838419295383433, 0.26975666564213197, 1.0, 1.0, 1.0, 0.6122757656938724, 1.0, 1.0, 1.0, 0.2726506473124847, 0.7315621195611339, 1.0, 1.0, 0.0, 1.0, 1.0, 0.890138053446914, 1.0, 1.0, 1.0, 0.0, 1.0, 0.05917707186354182, 0.3671973893384931, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8724298254286291, 1.0, 0.3543771829861353, 1.0, 1.0, 1.0, 0.41097990901908843, 1.0, 0.34985438418085446, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8274987416356734, 0.7454594570783388, 1.0, 1.0, 0.6993394662526431, 1.0, 0.74473672782921, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9119595841996332, 0.93907127827928, 1.0, 1.0, 0.31904507433223983, 1.0, 1.0, 1.0, 1.0, 0.3186896039905236, 1.0, 1.0, 0.5738505979750267, 1.0, 0.030930881393566034, 1.0, 1.0, 0.8746246507661267, 0.7463872291402918, 1.0, 1.0, 1.0, 0.8783046932733277, 1.0, 1.0, 1.0, 0.1916051176959771, 1.0, 1.0, 0.2557437015483004, 1.0, 1.0, 1.0, 1.0, 0.615267423492555, 0.43599518057058584, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2851004659086863, 1.0, 0.9853910028911171, 1.0, 0.6048394293625812, 0.3874512959225387, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8160790423433513, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3197431954076949, 1.0, 0.13762973439836135, 9.294168699610639E-4, 0.9032236273447073, 0.9753820161587614, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5122147076770516, 1.0, 0.0683020263188312, 1.0, 1.0, 0.9162750621546516, 0.38593951093692735, 1.0, 1.0, 1.0, 0.15188617233663027, 1.0, 1.0, 1.0, 0.03479036145426484, 0.5718160601328272, 1.0, 1.0, 1.0, 1.0, 0.20658101622178082, 1.0, 0.0, 0.3982805490890544, 0.9931853020998719, 0.5234071850674719, 1.0, 0.812077611008679, 1.0, 1.0, 1.0, 0.0, 0.856838642188807, 0.0, 1.0, 0.9744302009102653, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.545923533309, 1.0, 1.0, 1.0, 0.726301542321629, 0.08818137131390835, 0.9024923075361247, 1.0, 0.3281600723536078, 0.9462276883380166, 1.0, 0.7687200716840445, 1.0, 1.0, 0.06368476750251673, 1.0, 0.005139627585560302, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6249797483760352, 1.0, 0.6928543518957885, 1.0, 0.04052781704458808, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4017931351094245, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8580057406479153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.766927188109165, 0.30481253378993434, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5374064528948469, 0.9667320288306416, 1.0, 0.41586133940794756, 0.9368700907920335, 0.6032449435444707, 1.0, 1.0, 0.8691748574030873, 0.5300624550517324, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6607985296909104, 1.0, 0.31157173958222895, 1.0, 1.0, 1.0, 0.623585037479306, 0.5707614809590734, 0.47870485796552253, 1.0, 0.10540528595616694, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.876192478269556, 1.0, 1.0, 0.7055627116496911, 0.30770281338984384, 1.0, 0.07300359289962732, 1.0, 1.0, 1.0, 0.25062098327584403, 0.08215911690644695, 1.0, 1.0, 1.0, 0.7254933264929218, 1.0, 1.0, 1.0, 1.0, 0.6865139430432525, 1.0, 1.0, 1.0, 0.328412257061074, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21749985561970642, 1.0, 0.39864249421306397, 0.862922393510989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.018275069723506232, 0.9041353525781907, 1.0, 1.0, 1.0, 0.8629790899636793, 0.4624153743074342, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7374099443119462, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8443148641523824, 1.0, 0.2820673090598982, 0.28360792341713625, 1.0, 0.02075803212396421, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8609977948009223, 1.0, 1.0, 1.0, 1.0, 0.16357907701436047, 0.49753435023723447, 1.0, 1.0, 1.0, 1.0, 0.5037083870840707, 1.0, 0.04748321031540137, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03038406109566205, 0.2652914297349743, 1.0, 1.0, 1.0, 1.0, 0.4963113906717611, 1.0, 1.0, 1.0, 1.0, 0.5218410764441559, 1.0, 0.3714335993527168, 1.0, 0.4502824838315258, 1.0, 1.0, 0.8259409191119182, 0.30343859785595384, 0.9240729888456831, 1.0, 1.0, 0.32859392735626314, 0.073691723078804, 0.3808319557569416, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7126656189865445, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19934548947118313, 0.5876335127253189, 0.9277230524268234, 1.0, 0.14634545105888808, 1.0, 0.6396059599458888, 1.0, 0.20214939922527075, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5562286609077549, 0.28236791904265623, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8726258854858964, 1.0, 0.5126155583279571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08277940817513718, 1.0, 0.29923200430106056, 1.0, 0.687808116213612, 1.0, 0.20369933658486783, 0.832937392318661, 1.0, 0.20871570750331647, 1.0, 0.3392202983917838, 1.0, 1.0, 0.7448250755299131, 0.5540444549078982, 0.9799767702678124, 1.0, 1.0, 0.4165784809815649, 1.0, 1.0, 1.0, 0.33829615451865325, 1.0, 1.0, 1.0, 0.48468951693630746, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3868480888969821, 0.8056022187702383, 1.0, 1.0, 1.0, 1.0, 0.680672373225737, 0.6667315298575898, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.14303558522376103, 1.0, 1.0, 1.0, 1.0, 0.41829111109348593, 1.0, 1.0, 0.5156765510770731, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5554972801696314, 0.5839192892611353, 0.7930063987549418, 1.0, 1.0, 1.0, 1.0, 0.2741203638192007, 1.0, 1.0, 1.0, 1.0, 0.14054712799554292, 0.7135262622554164, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.20810867620427076, 1.0, 0.0, 1.0, 0.1745898512471864, 1.0, 0.2882220550090505, 1.0, 0.5826861465545828, 1.0, 1.0, 0.2788676426431763, 0.8162153348920989, 1.0, 1.0, 1.0, 0.24881902701993186, 1.0, 1.0, 1.0, 0.7280122577961974, 0.18685234483201507, 1.0, 0.22558050539369667, 0.6144464355986862, 0.5066857908540028, 0.1439989251068472 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0023771777486145673, 0.005018630674907043, 0.005346160854364457, 0.00968688274096774, 0.011492473298115313, 0.013753328048598523, 0.016756304492382412, 0.01956442972962824, 0.025237345848264203, 0.029504055145205932, 0.03132539442564286, 0.03366917821387272, 0.041499167183079444, 0.05846708971555892, 0.06110503995872496, 0.06919270268351019, 0.074042217912348, 0.07680744106928128, 0.08126528939362265, 0.0884787066746835, 0.0913741048604092, 0.09393411431363474, 0.1082891347972541, 0.11443151861235856, 0.11726561932657797, 0.12211151592428793, 0.1274856801402462, 0.1291744452431104, 0.1350801462257607, 0.13788526935601042, 0.14931973939515375, 0.15272833227814064, 0.15962490143216723, 0.1645921691578741, 0.16931148947992314, 0.173185026203581, 0.17334305297528085, 0.17788812404902343, 0.1805182283924236, 0.18913910002298462, 0.1917245604440624, 0.199411597758535, 0.19992656792313201, 0.20375940443714569, 0.20498120952681642, 0.21078144935468823, 0.2140747237910866, 0.21903613635556474, 0.21944397311278618, 0.22319666786011205, 0.22572772383912743, 0.22633743510433424, 0.232055739701156, 0.23519902754072275, 0.24038857130020352, 0.2461702994307814, 0.24626592957199545, 0.24952436683824863, 0.250609547198841, 0.254139961372988, 0.25482050463038564, 0.2637711174714499, 0.2690196467983105, 0.2768717261174458, 0.2828794315278065, 0.2956545416124853, 0.29639200687528344, 0.3040302724479996, 0.30666484626529333, 0.31100249473268027, 0.31514703913255326, 0.31924410703951445, 0.3216081144969869, 0.3275521651801324, 0.33303487180539837, 0.3375324658838189, 0.3465587598165476, 0.34889007504182357, 0.3504132500101974, 0.35574327634918845, 0.3567687116232726, 0.35979409354529945, 0.3638096411409335, 0.3645563543404774, 0.3677336508051099, 0.37448039996801696, 0.37544110966791266, 0.3814410414133115, 0.38561351286564804, 0.39159106411998224, 0.39458824249241276, 0.39666580378796523, 0.4003724315400786, 0.4032235800383104, 0.405751168615061, 0.4076986289379043, 0.4113394664991439, 0.4148151193889472, 0.41524097233404045, 0.41579750068745014, 0.42026883386580793, 0.42265603378895833, 0.4255632441277942, 0.4281908363928463, 0.45039373146924333, 0.45252851013768136, 0.4531240341239554, 0.4561942721337626, 0.4600023955807989, 0.4623911769125407, 0.4677424688510239, 0.4756878180109587, 0.4772398584381302, 0.4866317897750845, 0.48903577530762, 0.4953809753923044, 0.4984845385202662, 0.5006970539856748, 0.5066726489827458, 0.5085818224714432, 0.512726394261776, 0.516424388218611, 0.5197042628944842, 0.5210731905083879, 0.5235166162217073, 0.5252584187815833, 0.5320216789842518, 0.5359333105954953, 0.5361857502723201, 0.5403491803404276, 0.5430214308667641, 0.5446168645193924, 0.5450811104924129, 0.5464210000771659, 0.5480323566642401, 0.5546573480350956, 0.5561408115786989, 0.5564562058254564, 0.5594264719876927, 0.5636599710287622, 0.566892796249536, 0.5689131373767106, 0.5696252503092067, 0.5770406644619108, 0.5814171055820205, 0.5837819411546507, 0.5920168427890629, 0.5948032146777896, 0.5985951074046708, 0.599771314970498, 0.6030643061705165, 0.6037969919290961, 0.6054826692144046, 0.6072062241906566, 0.6096310116569019, 0.6172490208487257, 0.6196159269449223, 0.6218992302125492, 0.6226863385936764, 0.6230144580737199, 0.6264570196769271, 0.6320898295062423, 0.6329063306784342, 0.6343397397112043, 0.637090837080905, 0.648235897382097, 0.6541601542860984, 0.6551823922538302, 0.6563858593847672, 0.6585747303957017, 0.6630352742825435, 0.6662678614790385, 0.6677944290526784, 0.6700325378075668, 0.6741765392295153, 0.6743996518139815, 0.6761804250975686, 0.6784911686505812, 0.6817486440901612, 0.6851741706483512, 0.6906797711480066, 0.6955074672510492, 0.7011428647409692, 0.7026402058582288, 0.7061931829633586, 0.7119946540759589, 0.7144912198814884, 0.720254032230929, 0.7219004849336436, 0.7256153947974125, 0.7270500052685122, 0.7286340364609895, 0.7311532575471567, 0.7339053770018694, 0.7385058785105187, 0.7457387685551354, 0.746776639533718, 0.7477943497593724, 0.7505417957067677, 0.7521266412715764, 0.7574644454507177, 0.7629152914826599, 0.7651603288167663, 0.7681281783808822, 0.7704472210739898, 0.7730890416974662, 0.7732726176700367, 0.7774554671823856, 0.7835000808452567, 0.7839873586893554, 0.784769681824988, 0.7866066520243105, 0.8015089253946509, 0.8157694046351072, 0.8172523113668212, 0.8247878562777867, 0.8278893971772223, 0.8316630440808698, 0.8339474785184636, 0.8347579495573968, 0.8364984906180335, 0.8471944390335817, 0.8520158526341652, 0.8561856496851863, 0.8598238353912759, 0.8639615807350102, 0.8689442522791451, 0.8726135839996607, 0.8726550721760554, 0.8748747428582531, 0.8794965707281264, 0.8843551504557535, 0.8887912526617813, 0.8895766183304922, 0.8935945864501316, 0.9001331788638218, 0.9014057697580635, 0.9046283977269414, 0.9078320415275677, 0.910187845717226, 0.9132326804214563, 0.9172845384756465, 0.9273551805862972, 0.9334723917891448, 0.9363211539691568, 0.9404192073007469, 0.9439282834764579, 0.9447774792569715, 0.948099056412691, 0.9488459558311304, 0.9550385584084489, 0.9576577212276162, 0.9615133389830848, 0.9649920851931943, 0.96945054290662, 0.9721560924225866, 0.9753158427754154, 0.9816138578484027, 0.9844916693734078, 0.9867291015008487, 0.9894317657796315, 0.9899093933109753, 0.9933178707761122, 0.9942814186392107, 0.9956378335948083, 0.9968321514192983, 0.9976824520951861, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.\u001b[0m\n",
      "\u001b[34m0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_annual_premium\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2936.696187111707,\n",
      "      \"sum\" : 2.4107339E7,\n",
      "      \"std_dev\" : 126.05155900725325,\n",
      "      \"min\" : 2150.0,\n",
      "      \"max\" : 3000.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 2150.0,\n",
      "            \"upper_bound\" : 2235.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2235.0,\n",
      "            \"upper_bound\" : 2320.0,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2320.0,\n",
      "            \"upper_bound\" : 2405.0,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2405.0,\n",
      "            \"upper_bound\" : 2490.0,\n",
      "            \"count\" : 30.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2490.0,\n",
      "            \"upper_bound\" : 2575.0,\n",
      "            \"count\" : 182.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2575.0,\n",
      "            \"upper_bound\" : 2660.0,\n",
      "            \"count\" : 318.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2660.0,\n",
      "            \"upper_bound\" : 2745.0,\n",
      "            \"count\" : 266.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2745.0,\n",
      "            \"upper_bound\" : 2830.0,\n",
      "            \"count\" : 447.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2830.0,\n",
      "            \"upper_bound\" : 2915.0,\n",
      "            \"count\" : 599.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2915.0,\n",
      "            \"upper_bound\" : 3000.0,\n",
      "            \"count\" : 6335.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 3000.0, 3000.0, 2889.0, 2803.0, 2946.0, 2933.0, 3000.0, 2925.0, 2829.0, 3000.0, 2762.0, 3000.0, 2973.0, 3000.0, 3000.0, 2912.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2742.0, 3000.0, 3000.0, 2940.0, 2850.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2950.0, 2701.0, 2850.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2764.0, 3000.0, 3000.0, 2993.0, 2704.0, 3000.0, 3000.0, 2968.0, 3000.0, 2858.0, 3000.0, 3000.0, 2995.0, 2700.0, 3000.0, 3000.0, 2816.0, 3000.0, 2994.0, 2950.0, 3000.0, 3000.0, 3000.0, 3000.0, 2902.0, 3000.0, 2808.0, 3000.0, 3000.0, 2981.0, 2850.0, 3000.0, 3000.0, 3000.0, 3000.0, 2818.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2994.0, 2932.0, 2755.0, 3000.0, 3000.0, 3000.0, 2852.0, 2961.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2901.0, 3000.0, 3000.0, 3000.0, 2912.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2868.0, 2940.0, 2828.0, 3000.0, 2813.0, 3000.0, 3000.0, 2787.0, 3000.0, 3000.0, 3000.0, 3000.0, 2911.0, 3000.0, 3000.0, 3000.0, 3000.0, 2965.0, 3000.0, 2975.0, 3000.0, 3000.0, 2795.0, 3000.0, 3000.0, 2951.0, 2954.0, 3000.0, 2597.0, 3000.0, 3000.0, 3000.0, 3000.0, 2871.0, 3000.0, 2556.0, 3000.0, 3000.0, 3000.0, 3000.0, 2956.0, 2958.0, 2965.0, 2905.0, 3000.0, 2908.0, 3000.0, 3000.0, 2950.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2850.0, 3000.0, 3000.0, 3000.0, 2588.0, 2736.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2870.0, 2896.0, 2850.0, 3000.0, 2950.0, 2955.0, 3000.0, 2932.0, 3000.0, 3000.0, 3000.0, 2501.0, 2852.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2645.0, 3000.0, 3000.0, 2856.0, 3000.0, 2965.0, 3000.0, 3000.0, 3000.0, 2862.0, 2580.0, 2943.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2996.0, 3000.0, 2944.0, 3000.0, 3000.0, 3000.0, 2682.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2850.0, 2880.0, 2898.0, 3000.0, 2785.0, 3000.0, 2935.0, 3000.0, 2921.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2805.0, 3000.0, 2988.0, 2738.0, 2889.0, 2782.0, 2995.0, 3000.0, 3000.0, 3000.0, 3000.0, 2950.0, 3000.0, 3000.0, 2895.0, 3000.0, 2991.0, 3000.0, 3000.0, 2633.0, 3000.0, 3000.0, 3000.0, 3000.0, 2893.0, 3000.0, 3000.0, 2993.0, 3000.0, 2975.0, 3000.0, 2906.0, 3000.0, 3000.0, 3000.0, 2979.0, 3000.0, 3000.0, 2879.0, 2946.0, 3000.0, 2840.0, 3000.0, 3000.0, 2965.0, 2928.0, 2850.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2970.0, 3000.0, 2957.0, 3000.0, 2965.0, 3000.0, 3000.0, 2966.0, 2907.0, 3000.0, 2986.0, 3000.0, 3000.0, 2968.0, 3000.0, 3000.0, 2998.0, 3000.0, 3000.0, 3000.0, 2733.0, 2991.0, 3000.0, 3000.0, 2585.0, 3000.0, 3000.0, 2986.0, 3000.0, 2720.0, 2906.0, 3000.0, 3000.0, 3000.0, 2913.0, 2812.0, 3000.0, 3000.0, 2990.0, 3000.0, 2827.0, 3000.0, 3000.0, 3000.0, 2809.0, 2800.0, 3000.0, 3000.0, 3000.0, 3000.0, 2974.0, 3000.0, 2700.0, 3000.0, 3000.0, 2827.0, 3000.0, 3000.0, 3000.0, 2856.0, 2753.0, 3000.0, 2890.0, 3000.0, 2986.0, 2888.0, 3000.0, 2846.0, 3000.0, 3000.0, 2887.0, 3000.0, 2964.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2962.0, 3000.0, 2886.0, 3000.0, 3000.0, 2877.0, 3000.0, 3000.0, 3000.0, 3000.0, 2930.0, 3000.0, 2850.0, 3000.0, 2821.0, 3000.0, 3000.0, 3000.0, 3000.0, 2556.0, 3000.0, 2767.0, 3000.0, 3000.0, 3000.0, 2956.0, 3000.0, 3000.0, 2860.0, 2950.0, 3000.0, 3000.0, 2930.0, 3000.0, 3000.0, 2703.0, 2883.0, 2741.0, 3000.0, 2706.0, 2878.0, 3000.0, 3000.0, 3000.0, 3000.0, 2806.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2768.0, 2996.0, 3000.0, 2847.0, 2979.0, 3000.0, 2875.0, 3000.0, 2973.0, 3000.0, 3000.0, 3000.0, 3000.0, 2646.0, 3000.0, 3000.0, 2998.0, 3000.0, 2705.0, 3000.0, 2801.0, 3000.0, 2995.0, 3000.0, 2722.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2961.0, 3000.0, 2857.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2950.0, 3000.0, 2949.0, 3000.0, 3000.0, 3000.0, 2965.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2741.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2709.0, 2817.0, 3000.0, 2826.0, 2912.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2922.0, 3000.0, 3000.0, 3000.0, 3000.0, 2957.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2881.0, 3000.0, 3000.0, 2977.0, 3000.0, 3000.0, 3000.0, 3000.0, 2850.0, 3000.0, 2816.0, 3000.0, 2951.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2895.0, 2789.0, 3000.0, 3000.0, 3000.0, 2700.0, 3000.0, 3000.0, 3000.0, 2991.0, 3000.0, 3000.0, 3000.0, 2974.0, 2982.0, 3000.0, 3000.0, 2852.0, 3000.0, 2974.0, 3000.0, 3000.0, 2977.0, 3000.0, 3000.0, 2700.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2939.0, 2966.0, 2886.0, 2595.0, 3000.0, 3000.0, 3000.0, 3000.0, 2969.0, 3000.0, 3000.0, 3000.0, 3000.0, 2966.0, 2576.0, 3000.0, 2789.0, 3000.0, 2597.0, 3000.0, 3000.0, 2800.0, 3000.0, 3000.0, 3000.0, 2674.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2951.0, 3000.0, 2991.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2987.0, 2950.0, 3000.0, 3000.0, 2767.0, 3000.0, 2850.0, 3000.0, 3000.0, 3000.0, 2866.0, 2578.0, 3000.0, 3000.0, 2942.0, 3000.0, 2570.0, 3000.0, 2797.0, 3000.0, 3000.0, 3000.0, 2782.0, 2891.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2824.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2923.0, 2973.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 2805.0, 3000.0, 3000.0, 3000.0, 2835.0, 2591.0, 3000.0, 3000.0, 3000.0, 3000.0, 2993.0, 3000.0, 2972.0, 3000.0, 2899.0, 3000.0, 3000.0, 2975.0, 2911.0, 2891.0, 2870.0, 2945.0, 2971.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0 ], [ 3000.0, 2410.0, 2507.0, 2507.0, 2513.0, 2515.0, 2523.0, 2529.0, 2530.0, 2531.0, 2533.0, 2541.0, 2550.0, 2551.0, 2553.0, 2554.0, 2555.0, 2558.0, 2559.0, 2559.0, 2562.0, 2563.0, 2564.0, 2568.0, 2569.0, 2571.0, 2574.0, 2576.0, 2579.0, 2580.0, 2582.0, 2586.0, 2588.0, 2591.0, 2591.0, 2595.0, 2595.0, 2600.0, 2600.0, 2600.0, 2601.0, 2602.0, 2603.0, 2606.0, 2607.0, 2613.0, 2613.0, 2615.0, 2621.0, 2625.0, 2626.0, 2627.0, 2630.0, 2633.0, 2635.0, 2640.0, 2644.0, 2646.0, 2647.0, 2649.0, 2651.0, 2651.0, 2653.0, 2655.0, 2656.0, 2656.0, 2661.0, 2662.0, 2664.0, 2668.0, 2669.0, 2672.0, 2675.0, 2675.0, 2677.0, 2678.0, 2681.0, 2682.0, 2683.0, 2687.0, 2690.0, 2691.0, 2692.0, 2694.0, 2697.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2702.0, 2703.0, 2705.0, 2705.0, 2706.0, 2707.0, 2709.0, 2709.0, 2710.0, 2711.0, 2711.0, 2713.0, 2714.0, 2714.0, 2716.0, 2720.0, 2722.0, 2723.0, 2723.0, 2725.0, 2726.0, 2726.0, 2727.0, 2729.0, 2729.0, 2731.0, 2733.0, 2736.0, 2737.0, 2739.0, 2740.0, 2740.0, 2741.0, 2743.0, 2746.0, 2747.0, 2748.0, 2750.0, 2750.0, 2750.0, 2750.0, 2752.0, 2754.0, 2757.0, 2759.0, 2762.0, 2763.0, 2763.0, 2765.0, 2767.0, 2768.0, 2770.0, 2770.0, 2772.0, 2773.0, 2773.0, 2774.0, 2776.0, 2778.0, 2780.0, 2781.0, 2782.0, 2783.0, 2786.0, 2787.0, 2789.0, 2789.0, 2792.0, 2792.0, 2793.0, 2797.0, 2797.0, 2799.0, 2800.0, 2800.0, 2800.0, 2800.0, 2801.0, 2801.0, 2802.0, 2803.0, 2803.0, 2804.0, 2805.0, 2806.0, 2807.0, 2809.0, 2811.0, 2811.0, 2813.0, 2813.0, 2814.0, 2815.0, 2816.0, 2816.0, 2817.0, 2817.0, 2818.0, 2819.0, 2821.0, 2822.0, 2825.0, 2825.0, 2826.0, 2826.0, 2826.0, 2827.0, 2828.0, 2828.0, 2828.0, 2829.0, 2829.0, 2829.0, 2830.0, 2830.0, 2831.0, 2832.0, 2832.0, 2833.0, 2835.0, 2835.0, 2836.0, 2836.0, 2838.0, 2839.0, 2841.0, 2841.0, 2842.0, 2845.0, 2845.0, 2847.0, 2848.0, 2849.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2851.0, 2852.0, 2852.0, 2853.0, 2853.0, 2853.0, 2854.0, 2854.0, 2855.0, 2856.0, 2856.0, 2857.0, 2858.0, 2859.0, 2860.0, 2861.0, 2861.0, 2862.0, 2862.0, 2863.0, 2864.0, 2865.0, 2865.0, 2866.0, 2867.0, 2868.0, 2869.0, 2869.0, 2870.0, 2870.0, 2870.0, 2870.0, 2871.0, 2872.0, 2872.0, 2875.0, 2875.0, 2877.0, 2878.0, 2878.0, 2880.0, 2880.0, 2881.0, 2882.0, 2882.0, 2883.0, 2883.0, 2884.0, 2884.0, 2885.0, 2885.0, 2887.0, 2888.0, 2888.0, 2888.0, 2889.0, 2890.0, 2891.0, 2892.0, 2893.0, 2893.0, 2895.0, 2896.0, 2897.0, 2899.0, 2899.0, 2900.0, 2900.0, 2900.0, 2901.0, 2902.0, 2904.0, 2904.0, 2905.0, 2906.0, 2906.0, 2907.0, 2908.0, 2908.0, 2908.0, 2909.0, 2909.0, 2909.0, 2910.0, 2910.0, 2911.0, 2911.0, 2912.0, 2912.0, 2912.0, 2913.0, 2914.0, 2915.0, 2916.0, 2916.0, 2917.0, 2918.0, 2919.0, 2919.0, 2920.0, 2920.0, 2921.0, 2921.0, 2921.0, 2922.0, 2923.0, 2923.0, 2923.0, 2924.0, 2925.0, 2926.0, 2926.0, 2927.0, 2927.0, 2928.0, 2928.0, 2929.0, 2929.0, 2930.0, 2931.0, 2932.0, 2932.0, 2933.0, 2933.0, 2933.0, 2934.0, 2934.0, 2934.0, 2935.0, 2936.0, 2936.0, 2937.0, 2937.0, 2938.0, 2939.0, 2939.0, 2940.0, 2940.0, 2940.0, 2942.0, 2942.0, 2943.0, 2944.0, 2944.0, 2945.0, 2945.0, 2946.0, 2946.0, 2946.0, 2946.0, 2947.0, 2947.0, 2948.0, 2948.0, 2949.0, 2949.0, 2949.0, 2949.0, 2950.0, 2951.0, 2951.0, 2952.0, 2952.0, 2952.0, 2953.0, 2953.0, 2953.0, 2954.0, 2954.0, 2954.0, 2954.0, 2955.0, 2955.0, 2955.0, 2956.0, 2957.0, 2957.0, 2958.0, 2958.0, 2959.0, 2959.0, 2960.0, 2960.0, 2960.0, 2960.0, 2961.0, 2961.0, 2962.0, 2962.0, 2962.0, 2962.0, 2963.0, 2963.0, 2963.0, 2964.0, 2964.0, 2964.0, 2964.0, 2964.0, 2965.0, 2965.0, 2965.0, 2965.0, 2965.0, 2966.0, 2966.0, 2966.0, 2966.0, 2967.0, 2967.0, 2967.0, 2967.0, 2968.0, 2968.0, 2968.0, 2968.0, 2969.0, 2969.0, 2969.0, 2969.0, 2970.0, 2971.0, 2972.0, 2972.0, 2972.0, 2973.0, 2973.0, 2973.0, 2974.0, 2974.0, 2974.0, 2974.0, 2975.0, 2975.0, 2975.0, 2976.0, 2977.0, 2977.0, 2977.0, 2978.0, 2978.0, 2978.0, 2979.0, 2979.0, 2979.0, 2979.0, 2979.0, 2980.0, 2980.0, 2981.0, 2981.0, 2982.0, 2982.0, 2983.0, 2983.0, 2983.0, 2984.0, 2984.0, 2984.0, 2985.0, 2985.0, 2985.0, 2986.0, 2986.0, 2986.0, 2987.0, 2988.0, 2988.0, 2988.0, 2988.0, 2989.0, 2989.0, 2989.0, 2989.0, 2990.0, 2990.0, 2991.0, 2991.0, 2991.0, 2992.0, 2992.0, 2992.0, 2992.0, 2993.0, 2994.0, 2994.0, 2994.0, 2995.0, 2995.0, 2995.0, 2996.0, 2996.0, 2997.0, 2997.0, 2998.0, 2998.0, 2998.0, 2998.0, 2999.0, 2999.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 300\u001b[0m\n",
      "\u001b[34m0.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0 ], [ 2250.0, 2300.0, 2350.0, 2350.0, 2400.0, 2400.0, 2400.0, 2400.0, 2450.0, 2450.0, 2450.0, 2450.0, 2450.0, 2450.0, 2456.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2500.0, 2532.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2550.0, 2560.0, 2597.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2600.0, 2630.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2650.0, 2665.0, 2697.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2700.0, 2714.0, 2724.0, 2739.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2750.0, 2755.0, 2765.0, 2782.0, 2799.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2800.0, 2803.0, 2817.0, 2829.0, 2845.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2850.0, 2858.0, 2867.0, 2879.0, 2893.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2900.0, 2909.0, 2918.0, 2924.0, 2929.0, 2934.0, 2941.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2950.0, 2953.0, 2958.0, 2966.0, 2970.0, 2973.0, 2981.0, 2987.0, 2998.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"driver_relationship_child\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.04508160040805536,\n",
      "      \"sum\" : 370.07485774972645,\n",
      "      \"std_dev\" : 0.1892613555600827,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7695.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 42.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 33.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 34.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 35.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 37.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 31.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 40.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 33.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 229.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8548057787992615, 0.04758469400335641, 0.8835647283701904, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47510001327416174, 0.0, 0.6696085263343835, 0.0, 0.0, 0.4515655866055751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8301274055955237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5095914808144868, 0.16950409186605864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0679732998194037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6757612928952238, 0.0, 0.0, 0.05917707186354182, 0.0, 0.7689200445711684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6971701110212578, 0.0, 0.0, 0.41097990901908843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2557437015483004, 0.0, 0.0, 0.0, 0.0, 0.38473257650744497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3874512959225387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9316979736811688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8862882164557176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26741527847210766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09750769246387525, 0.8533292165587878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23562285119164839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013436885885589556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04052781704458808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06751107641019816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6957581361728042, 0.0, 0.0, 0.30630099688753754, 0.0, 0.0, 0.0, 0.0, 0.23307281189083495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.82840363293481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5212951420344775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30770281338984384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9682775081839688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7329249925436676, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8150797025328557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19701869869089617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5887959327881459, 0.6633625340146814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.522257873600464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3808319557569416, 0.0, 0.6888105035899871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06704337447177267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.36039404005411124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7146956752357342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7834208143727591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20369933658486783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5834215190184351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6420388054672354, 0.0, 0.0, 0.0, 0.26183172946315636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2864737377445836, 0.0, 0.0, 0.0, 0.0, 0.9285968815306384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4872120069219139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4933142091459972, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0038171341243471435, 0.010568234220368455, 0.02002635592582447, 0.029155186022088997, 0.03798156328985347, 0.05174846220992069, 0.058454614108553904, 0.06581176069057648, 0.06669388140544885, 0.09228479207325724, 0.09537160227305863, 0.09756251023929974, 0.0988736176406354, 0.10554744317576781, 0.10633729734822717, 0.11120874733821873, 0.12448877344738385, 0.12884871200025483, 0.12960065119544195, 0.1318307046734959, 0.14225523977681542, 0.15067610770987738, 0.1617346404542951, 0.16462746971575393, 0.16605252148153637, 0.1706675948587163, 0.17264344517385444, 0.17477344282737717, 0.18059459817530088, 0.184585129537033, 0.19013981263941382, 0.20795635928938994, 0.21228698447229133, 0.22609377822933485, 0.23140019521149158, 0.232541331620855, 0.24858025771494208, 0.25669422831004585, 0.2660192780053807, 0.2678773931570442, 0.2765952343877137, 0.27893807607347676, 0.30048938560043237, 0.3100002626910566, 0.31924410703951445, 0.32539214708378383, 0.3332280902161028, 0.3373354869406445, 0.36039443882231814, 0.366927346500487, 0.3779604376290062, 0.3900584414039483, 0.3950460773094592, 0.39744815689909163, 0.40063103433706615, 0.4035145250145784, 0.41701557383539756, 0.42000407408140494, 0.4235275624422461, 0.43431182785899425, 0.43981774162508813, 0.44441945275120154, 0.4507762838863638, 0.4559792757599369, 0.4640666894045047, 0.4865976622437531, 0.49943176986683535, 0.5053248104087167, 0.5085818224714432, 0.5116253710170613, 0.5209299368966488, 0.5252584187815833, 0.5370074883513584, 0.5480323566642401, 0.5587762863446735, 0.5655499649214404, 0.5704040564239353, 0.5886605335008561, 0.5927709408701848, 0.5976650447626672, 0.5986939757802878, 0.6052656461551719, 0.6092448476703629, 0.6136768269235341, 0.6183880601327999, 0.620773462819551, 0.6321594991864574, 0.6438143528824058, 0.6509573351180726, 0.6596292536942373, 0.6709430047425079, 0.6783918855030131, 0.6975209708320734, 0.7004317991565039, 0.7150387188506838, 0.7171205684721935, 0.7190774473538556, 0.7285012458181321, 0.7336158300423125, 0.7409812502745785, 0.7464158830036308, 0.7577687821754331, 0.7586763901110049, 0.7608574545654768, 0.76821640971065, 0.7732726176700367, 0.7827691135469892, 0.7914097505069756, 0.7993489825962388, 0.8015089253946509, 0.809183171139031, 0.823767395799123, 0.83506594545502, 0.8366633519109428, 0.8471944390335817, 0.8634657303414633, 0.8726550721760554, 0.877138441511404, 0.879341020176528, 0.8860433652856828, 0.9157882394541271, 0.9253615689205712, 0.9292573980072293, 0.9368909669208498, 0.9482141112671831, 0.9556122278291456, 0.9663308217861273, 0.9724808148595847, 0.977031676545176, 0.9780618179735285, 0.9816533238524479, 0.9929707961863808, 0.9937425289735298, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0\u001b[0m\n",
      "\u001b[34m.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03868471181509259, 0.0587624957676135, 0.16912280865829454, 0.258688330697908, 0.34265348812091534, 0.4119416219099208, 0.551222426168597, 0.7218876279269351, 0.8258066634217464, 0.9563383422926388, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_type_collision\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.8188215685450246,\n",
      "      \"sum\" : 6721.706256186108,\n",
      "      \"std_dev\" : 0.3457976749968297,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 914.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 132.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 143.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 164.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 145.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 150.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 133.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 123.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 150.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 6155.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 0.9318909752764775, 0.7818256704067268, 1.0, 1.0, 0.5546134740221278, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47833548167055584, 0.021021106726217154, 1.0, 1.0, 1.0, 1.0, 0.16276278177818193, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.755838391283847, 1.0, 0.6148973971769703, 0.8548057787992615, 1.0, 0.8835647283701904, 0.27061999469359665, 1.0, 1.0, 0.007334150836180275, 0.9741906071368183, 0.44670936037699993, 0.520449404165286, 1.0, 0.7981581646362419, 1.0, 1.0, 0.0, 0.7778112444584507, 1.0, 1.0, 1.0, 0.5488068085492763, 0.6696085263343835, 0.4107853856521445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2432419097530717, 0.31944183822089856, 1.0, 0.059105820875654524, 0.3092736848867369, 1.0, 1.0, 1.0, 0.09114063944467754, 0.7140994662287976, 0.32761018720129553, 1.0, 1.0, 0.3311464891641498, 0.7659715748551791, 1.0, 1.0, 0.42038090277186335, 1.0, 1.0, 0.9585719111806122, 0.03219726235151499, 1.0, 0.03684097293493349, 0.11475359941383545, 0.5095914808144868, 1.0, 1.0, 0.6175291150623116, 1.0, 1.0, 1.0, 1.0, 0.21836744194675284, 1.0, 1.0, 1.0, 1.0, 0.6750772055933587, 1.0, 1.0, 0.730243334357868, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.810468217215466, 0.2726506473124847, 0.26843788043886607, 1.0, 0.47811567184205683, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05917707186354182, 1.0, 0.7689200445711684, 1.0, 0.9889214474056903, 0.2698265466893234, 1.0, 1.0, 0.8724298254286291, 0.5909148513651238, 0.3543771829861353, 1.0, 0.2691203766777923, 1.0, 1.0, 1.0, 0.6501456158191455, 1.0, 1.0, 1.0, 0.3150105071834246, 1.0, 1.0, 1.0, 1.0, 1.0, 0.956684726745688, 0.6993394662526431, 1.0, 0.0, 0.4124030604678661, 0.8042443935943754, 0.4868249177179641, 1.0, 1.0, 0.31730547742048654, 0.9119595841996332, 0.06092872172071995, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7574217339261748, 0.09130880254467022, 0.3186896039905236, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3616470948410445, 1.0, 0.0, 1.0, 1.0, 0.5054788748795921, 0.12169530672667228, 1.0, 0.31607768384326407, 1.0, 0.1916051176959771, 1.0, 0.7042524374049793, 1.0, 0.672579041266552, 0.16462051323650484, 0.18117185085002008, 1.0, 1.0, 0.43599518057058584, 0.5940494655668112, 1.0, 0.9326231284780743, 1.0, 0.8226734467760606, 0.27692836395033116, 0.0, 1.0, 1.0, 0.01460899710888286, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29353479245866043, 1.0, 0.3327808689607955, 1.0, 0.0, 1.0, 0.8077178199814796, 1.0, 1.0, 0.9810545966256454, 1.0, 0.7916004263816684, 1.0, 0.3615112152008645, 0.0, 0.9428828366295567, 0.0, 1.0, 0.0, 0.9753820161587614, 0.7905442304904889, 0.5837372193120927, 1.0, 1.0, 1.0, 1.0, 0.31952053747562603, 1.0, 1.0, 0.8037552360117627, 1.0, 1.0, 1.0, 1.0, 0.15137117126327493, 1.0, 0.6714418501142015, 1.0, 0.81754195934751, 0.03479036145426484, 0.5718160601328272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6867335234193896, 1.0, 1.0, 0.006814697900128119, 1.0, 0.07848660809258212, 0.812077611008679, 0.8252113712596311, 1.0, 1.0, 0.0, 0.143161357811193, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18760927581384912, 0.9175940281380518, 1.0, 0.5143531346657229, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9118186286860916, 1.0, 1.0, 1.0, 1.0, 0.3306430157592517, 0.7687200716840445, 1.0, 1.0, 1.0, 0.822872855801746, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9435741440351771, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6928543518957885, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36395265766087337, 0.4017931351094245, 1.0, 0.3078741252743674, 1.0, 1.0, 1.0, 0.06751107641019816, 0.0, 0.4022237348471124, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8607531554058905, 0.6120085299594553, 1.0, 0.32610785251257346, 0.9290840405120208, 1.0, 0.13750349259841466, 0.23307281189083495, 0.30481253378993434, 0.37037165506140735, 1.0, 1.0, 0.9775899603450432, 0.41737135395963443, 0.004525847653185644, 1.0, 1.0, 0.9438379900966869, 1.0, 1.0, 1.0, 0.8325402554820115, 1.0, 0.03326797116935842, 1.0, 0.5841386605920524, 1.0, 0.6032449435444707, 0.5259937340515549, 1.0, 0.8691748574030873, 0.46993754494826756, 1.0, 1.0, 0.8176233783044862, 0.8950566039998331, 1.0, 0.6735465781313908, 0.13736174596867423, 1.0, 0.046063063681977434, 0.9308240749901141, 1.0, 1.0, 0.31157173958222895, 1.0, 1.0, 0.9983562428875503, 1.0, 1.0, 0.5212951420344775, 1.0, 1.0, 1.0, 0.4870206501790926, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2944372883503089, 1.0, 1.0, 0.9269964071003727, 1.0, 1.0, 0.7655005223259063, 0.25062098327584403, 0.08215911690644695, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5477975208964613, 1.0, 0.6865139430432525, 0.0, 0.12254787339683115, 1.0, 0.328412257061074, 1.0, 0.46503332659055596, 0.9623022750851472, 0.8080678171160226, 0.3207245244599576, 1.0, 0.7205546926810974, 1.0, 0.8865025266419025, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12187950178138363, 0.018275069723506232, 1.0, 0.9313513338521278, 0.008110804052508302, 0.9513968619791061, 1.0, 1.0, 1.0, 0.42815517303011985, 0.9385748707401673, 0.22392458779658952, 1.0, 0.4386475002460548, 1.0, 0.19213435431601877, 1.0, 1.0, 0.0, 1.0, 0.2911008872266839, 1.0, 0.3146289089351988, 0.6740175348839673, 0.0, 1.0, 0.2820673090598982, 0.28360792341713625, 0.0, 1.0, 1.0, 0.9572603939380486, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21228564166859132, 0.11555837668063174, 0.16357907701436047, 0.49753435023723447, 1.0, 1.0, 1.0, 0.3940738045857527, 1.0, 0.8784158630449617, 1.0, 0.24546308409753947, 1.0, 1.0, 1.0, 1.0, 1.0, 0.829821264717285, 1.0, 1.0, 1.0, 0.8817775879275401, 0.4014976105648763, 0.20687146203694362, 0.220508787136648, 1.0, 1.0, 1.0, 1.0, 0.03038406109566205, 1.0, 0.3004034669764718, 1.0, 0.8841769177632057, 1.0, 0.4963113906717611, 0.8291506402841399, 0.5081417186651943, 0.37975864573108786, 1.0, 1.0, 0.0, 0.0, 0.3667367983905896, 0.4502824838315258, 1.0, 1.0, 0.17405908088808175, 0.30343859785595384, 0.9240729888456831, 0.17967591185279908, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5740024805315719, 1.0, 0.34223461672739997, 0.5643953803389896, 1.0, 1.0, 0.526082518417403, 1.0, 0.28733438101345554, 0.0, 0.47130827457412117, 1.0, 0.37822451524334477, 1.0, 1.0, 0.19934548947118313, 1.0, 1.0, 0.42421413722558843, 1.0, 1.0, 0.36039404005411124, 0.9129287944226918, 0.0, 1.0, 0.0, 0.5439731112849675, 1.0, 1.0, 0.3972714728404597, 0.7544493740555089, 1.0, 1.0, 0.11148768783878193, 1.0, 1.0, 1.0, 0.24021943320838557, 0.4437713390922451, 0.28236791904265623, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1097633782042291, 0.8850936566380897, 0.9961628544921991, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5008010531586682, 1.0, 0.12737411451410363, 1.0, 1.0, 0.691416057513152, 1.0, 1.0, 0.0, 1.0, 0.08277940817513718, 0.553558532662358, 1.0, 0.43085827538227073, 1.0, 0.7251111599333161, 1.0, 0.832937392318661, 0.014231750414258837, 0.0, 0.6013840706885634, 0.3392202983917838, 0.5445954487107494, 0.04106817279040542, 0.0, 1.0, 1.0, 0.9374930584895892, 0.38746646382175665, 1.0, 1.0, 1.0, 0.4802942587913558, 0.33829615451865325, 0.7808739353291991, 1.0, 0.40356604537434004, 0.5153104830636925, 0.026867654044935296, 0.38048188549303585, 1.0, 0.5313568317526952, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.31932762677426296, 1.0, 0.48902925695493793, 1.0, 1.0, 0.02208584530117974, 1.0, 0.0, 0.38769515483900674, 0.13836820088819002, 1.0, 1.0, 1.0, 0.49236230351962584, 1.0, 0.8555511234358725, 1.0, 1.0, 0.9367245558534901, 0.5156765510770731, 0.497253886590878, 0.17841609656349577, 0.8918449854266433, 1.0, 0.38586682381248194, 0.6741754159805513, 1.0, 1.0, 1.0, 1.0, 0.14859425210852606, 0.9157356338441489, 1.0, 0.3196155862374779, 1.0, 1.0, 1.0, 0.7890228445481342, 1.0, 1.0, 1.0, 0.0, 0.0, 0.16346910923909652, 1.0, 1.0, 1.0, 0.6937321129953853, 0.2650812843385726, 1.0, 0.8071294313103857, 0.9072851891897301, 1.0, 1.0, 0.10137984246986353, 1.0, 1.0, 0.0, 0.0, 1.0, 0.29257372483806765, 0.7117779449909495, 0.10164472483233467, 0.5826861465545828, 0.8758926322862226, 1.0, 0.2788676426431763, 1.0, 1.0, 1.0, 1.0, 0.24881902701993186, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7425210238562752, 1.0, 1.0, 1.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002103843175883413, 0.0037377134751231944, 0.005315834803512831, 0.007964404745451126, 0.008736773266366793, 0.00979110641237857, 0.011164468610835532, 0.012907227980991975, 0.01340262643216561, 0.01803080955385472, 0.022026921223816998, 0.024684157224584613, 0.030392273151904625, 0.031778484357324444, 0.03798156328985347, 0.03983221527125458, 0.04404037938846439, 0.04533996996669254, 0.046500586440065494, 0.047103204002172494, 0.050018576821112215, 0.05439074852231118, 0.055525032809150554, 0.05846708971555892, 0.05947156886728078, 0.06290897154120523, 0.06367884603084317, 0.06642891654235195, 0.0683409355322604, 0.06902954088784963, 0.07071159773794056, 0.07267087161001629, 0.07436266997466423, 0.07571292920533879, 0.07680744106928128, 0.07737694191221034, 0.08022224645571407, 0.08132220300649573, 0.08474281508217696, 0.08534133648432485, 0.08893129723261639, 0.0927510556435942, 0.09608666973962532, 0.0969062721234617, 0.09954651280877513, 0.10274825245242336, 0.10536753395280596, 0.10601479495303923, 0.10761418475985884, 0.11034796698243365, 0.11188061654912385, 0.1141399693096321, 0.11602268134816929, 0.11706604142416865, 0.11843654505924306, 0.11887439117707199, 0.12123075020708551, 0.12201550301516517, 0.12389480740195746, 0.12573752938976224, 0.12786429997752347, 0.1279882085335864, 0.1299299245357013, 0.1316535887932584, 0.13345201825091313, 0.13533960785958232, 0.13603841926498983, 0.14225523977681542, 0.14350659723742643, 0.14741504506165726, 0.14931973939515375, 0.1528326386274258, 0.15380702464160778, 0.15607538738827598, 0.15928744524280514, 0.160183837854469, 0.16184781644807555, 0.1645921691578741, 0.16540904740472795, 0.16668292852698752, 0.17351190980423759, 0.1748693323338848, 0.18020219501527246, 0.18059459817530088, 0.18691444060846163, 0.18913910002298462, 0.19067560171473763, 0.19111870949600263, 0.19121001543646154, 0.1917245604440624, 0.193410657673723, 0.1944476444316886, 0.19714879100445404, 0.20028208638128042, 0.20140672761724876, 0.2039925975727167, 0.20424675891216748, 0.20551436635150933, 0.2064293454611984, 0.20660598569465227, 0.20947948972832653, 0.21189433044010908, 0.21462807325880284, 0.2152044797331928, 0.2160513650116872, 0.2162505281865289, 0.21790870825201347, 0.21849435225781788, 0.21911747946993843, 0.21965213725984145, 0.22001167308945568, 0.2204836934733041, 0.22408846719269404, 0.22569731705540486, 0.2262791082142318, 0.22691095830253383, 0.23140019521149158, 0.232645538562681, 0.23483967118323368, 0.23528085852372083, 0.23769096797806133, 0.240655672077134, 0.24628601881053158, 0.24977216244651979, 0.2537927425181614, 0.25426123144486457, 0.25530907650393164, 0.25691846036861987, 0.2603286992732363, 0.26290344956794875, 0.26616801251553746, 0.2682752634357871, 0.2690196467983105, 0.27438460520258745, 0.2756123386789454, 0.27644169058339607, 0.2778451632065655, 0.2803461833894696, 0.2856995940447645, 0.28732671650890196, 0.289970118943609, 0.291144247785179, 0.2918781650993746, 0.2933657365324036, 0.29672764110409, 0.2984349123618767, 0.2999657272278956, 0.3022437239265705, 0.30449253274895083, 0.30690451319457, 0.3083819444306807, 0.3100002626910566, 0.31168982851504146, 0.31234910188551357, 0.3140887289501363, 0.31491958861296765, 0.31654966526787, 0.31784683843836503, 0.3186089627636072, 0.31965205529206253, 0.32005983252098347, 0.3211022749221595, 0.3227265727266384, 0.3238917685855889, 0.3258231175644498, 0.3275521651801324, 0.3303973838660381, 0.33303487180539837, 0.3347078980219448, 0.33720372579027835, 0.3373354869406445, 0.33751605305839183, 0.3414252696042983, 0.34460408444755963, 0.34522995366997244, 0.34592044750169426, 0.3470503418621578, 0.3499449395296398, 0.3522257670496579, 0.3547101624742831, 0.35504105645195827, 0.3571810851998257, 0.35936440719741347, 0.3598016884403762, 0.36290916291909503, 0.3646706762343366, 0.36776184913213905, 0.36882935404329364, 0.3707011939892638, 0.3715659525810011, 0.37448039996801696, 0.37557455352827196, 0.37691416473637196, 0.3786555027464704, 0.3800314351258358, 0.38068968116086577, 0.38423962013738133, 0.3853758830473618, 0.3870787603356308, 0.39072836561361324, 0.3927937758093434, 0.39570796357379256, 0.39693569382948346, 0.39785435594751895, 0.39910018807372305, 0.40087941495967483, 0.40244663743366893, 0.4035145250145784, 0.4047984290851998, 0.4065567838081042, 0.4085932405775119, 0.41106692505443587, 0.41149506484101117, 0.41293829229884904, 0.4144697155393433, 0.4148151193889472, 0.4149712154000782, 0.41594390458185504, 0.41798993387048433, 0.42265603378895833, 0.4233859928702822, 0.42615874589548663, 0.4296228638968441, 0.43431182785899425, 0.4353709490027369, 0.4355589093211175, 0.4443653492415144, 0.44566252565965514, 0.4474681413224578, 0.44812286357881437, 0.44908474501094675, 0.45039373146924333, 0.45058576156954666, 0.45069022851989604, 0.45440315447995283, 0.4548944717393003, 0.4561942721337626, 0.4580099251102341, 0.45859794351384, 0.46311471383751146, 0.4646320588183488, 0.4658257532231247, 0.4667820772311879, 0.46751880744057384, 0.47289196563318214, 0.4756878180109587, 0.47669547504115917, 0.4780469965214361, 0.4792600899145375, 0.47980947674844554, 0.4813333765356649, 0.4822643612521922, 0.48439118560084926, 0.48531638287856105, 0.4861492654234021, 0.4877152427565149, 0.49193110010572905, 0.4933273510172542, 0.49604783867988655, 0.5006661650213817, 0.5015756999179484, 0.502490876826932, 0.5063303093542678, 0.5070824240602667, 0.5085818224714432, 0.5116253710170613, 0.5146410168401129, 0.5217659769519277, 0.5227601415618698, 0.5235387287606005, 0.5258125988733238, 0.5262784603382027, 0.5298812610885262, 0.5302562370093162, 0.5304744579561373, 0.5315773967749932, 0.5316698140661865, 0.532675886761555, 0.5349447516993556, 0.5353868311910291, 0.5368272832486582, 0.5381565187248897, 0.5403491803404276, 0.5410028989276625, 0.5415335754307422, 0.5417653496071662, 0.5431413551196314, 0.5447722269827888, 0.5450811104924129, 0.5467005205567683, 0.5483031807683173, 0.5491303362771727, 0.5546573480350956, 0.5560961676800884, 0.5578132255110699, 0.5587762863446735, 0.5632889309538147, 0.5643552095434902, 0.5649843576752536, 0.5662294339819824, 0.5703914078676366, 0.5719122038506007, 0.576055187086698, 0.5773108866038105, 0.5814193783760647, 0.5829844261646024, 0.5843578133140943, 0.5847590276659596, 0.5873246739166034, 0.5904310898226933, 0.5914067594224881, 0.5927709408701848, 0.5938024808096155, 0.5948032146777896, 0.5970957701867198, 0.5986939757802878, 0.5996275684599214, 0.600899811926277, 0.6032031529136835, 0.6061465649334797, 0.60687734157693, 0.6096310116569019, 0.6101002537089194, 0.6127627288219041, 0.6159573616088996, 0.617931559846298, 0.6193434541369114, 0.6197345714330892, 0.6227322822928333, 0.6263223516561951, 0.6267401855372411, 0.6320154860204185, 0.6321594991864574, 0.6325441099658279, 0.6350891059097188, 0.635645761571768, 0.6360707637298251, 0.6363546410805504, 0.6368992633659896, 0.6392274808894002, 0.6426746576724236, 0.6457322351589534, 0.6473973940711418, 0.6477131710629215, 0.648235897382097, 0.6507685475587474, 0.6540757953719981, 0.6563858593847672, 0.6580825847491903, 0.6581962945078175, 0.6590355342036808, 0.6596199073333251, 0.6627728672445796, 0.6662678614790385, 0.6668666605509217, 0.6695919961242262, 0.6741768824355502, 0.6754202075470892, 0.6761082314144111, 0.6769002983336627, 0.6783918855030131, 0.6816959053076527, 0.6820174486596651, 0.6862934879479348, 0.6906797711480066, 0.6913012566268047, 0.6933351537347067, 0.6959697275520004, 0.6975209708320734, 0.6983111572275728, 0.7004317991565039, 0.7043053259583958, 0.7060190076640246, 0.7101354317980658, 0.7117484228326315, 0.7150919784690392, 0.7171205684721935, 0.7218708445133876, 0.7242545274991332, 0.727529230225095, 0.7304924774822994, 0.7308180287118088, 0.7341488633456865, 0.7362398101338331, 0.7390265577879587, 0.7431161523542852, 0.7456780188216833, 0.7498507644364663, 0.7514529444593436, 0.753480094362017, 0.7537340704280046, 0.7574644454507177, 0.7577687821754331, 0.7596114286997965, 0.7596176113005162, 0.7608574545654768, 0.7618836118624439, 0.7628555340222888, 0.764\u001b[0m\n",
      "\u001b[34m1424008563129, 0.7665885239716433, 0.7680054353132096, 0.7707806182638798, 0.7723010151653429, 0.7726426999039012, 0.7764893026510181, 0.7789366285462715, 0.7820153349329673, 0.7863018584296716, 0.787901988292265, 0.7891608465887314, 0.7894922984240523, 0.7914097505069756, 0.7920936337605432, 0.7944808178535061, 0.7965635248639088, 0.8001587287180605, 0.8013479918738086, 0.8023607794088699, 0.807189318791188, 0.8092740124091053, 0.8139769999943344, 0.818026749138693, 0.8183695664813373, 0.823767395799123, 0.8267146599310183, 0.8279107707047406, 0.8306885105200769, 0.83136770622197, 0.8316630440808698, 0.8324171834102527, 0.8339781763571392, 0.8385492149028282, 0.841375855473622, 0.842015661506744, 0.8442487024058184, 0.8476704105354645, 0.8493125129991662, 0.8494785083365864, 0.8518412368739476, 0.8529819953305915, 0.8561324990137434, 0.8566046299891075, 0.8589566854206295, 0.8610452995033119, 0.8629723989869625, 0.8651933473978111, 0.8669334683518837, 0.8675953865035454, 0.868900625540571, 0.8694987358828158, 0.8701735510482824, 0.8708255547568896, 0.8726305265521189, 0.8729037597815608, 0.8733366617238478, 0.8737462172073865, 0.8747794404831686, 0.877566101641059, 0.8819921697216359, 0.8824594404560998, 0.8842986818196978, 0.8852030727487199, 0.8880390643601178, 0.8888874240036297, 0.8929428214458139, 0.8936562737442254, 0.8947408148029876, 0.8951919350024279, 0.8978504703424619, 0.9012627931173341, 0.9015830052870676, 0.9037575717751422, 0.9053598742778703, 0.9058480898743021, 0.9063275792940898, 0.9077354331775127, 0.9079047467670976, 0.9095183047129493, 0.9108026709698133, 0.9112326058922315, 0.9169420482009158, 0.9233641935247512, 0.9278889070705648, 0.928317532848577, 0.9306716696122352, 0.9325445893524509, 0.9381142983195248, 0.9389964220859776, 0.9425313075201167, 0.943174822961285, 0.9439823053632096, 0.9473952495864468, 0.948744395149711, 0.949440812040461, 0.949899668246076, 0.9548469930384681, 0.9556122278291456, 0.9562643741200305, 0.9569930481330605, 0.9576577212276162, 0.9580359265563657, 0.9644291329644517, 0.9707499576706702, 0.9721560924225866, 0.9745918113353297, 0.9751799759755083, 0.977031676545176, 0.9794791852706748, 0.9801089924137669, 0.9828502180848019, 0.9853038322872855, 0.9882752710001314, 0.9903131172590323, 0.9916960733724518, 0.9919408966578802, 0.9956378335948083, 0.9968321514192983, 0.9976228222513854, 0.9995439187190943, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036642241932757225, 0.029394445756507293, 0.05792046055879829, 0.1037786973149617, 0.16912280865829454, 0.21616744658113807, 0.25422457989749325, 0.34265348812091534, 0.39920155355780196, 0.4336553339563889, 0.49118634086862656, 0.5463063653947173, 0.5816002113323473, 0.6009540538628889, 0.6281664707612754, 0.7016255690100074, 0.7474912503116178, 0.7962987507237258, 0.8395998946699279, 0.8770291914703733, 0.8966910428759843, 0.9791388607084619, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"policy_deductable\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 750.7243269582166,\n",
      "      \"sum\" : 6162696.0,\n",
      "      \"std_dev\" : 9.688290550857555,\n",
      "      \"min\" : 750.0,\n",
      "      \"max\" : 1100.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 750.0,\n",
      "            \"upper_bound\" : 785.0,\n",
      "            \"count\" : 8147.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 785.0,\n",
      "            \"upper_bound\" : 820.0,\n",
      "            \"count\" : 26.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 820.0,\n",
      "            \"upper_bound\" : 855.0,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 855.0,\n",
      "            \"upper_bound\" : 890.0,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 890.0,\n",
      "            \"upper_bound\" : 925.0,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 925.0,\n",
      "            \"upper_bound\" : 960.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 960.0,\n",
      "            \"upper_bound\" : 995.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 995.0,\n",
      "            \"upper_bound\" : 1030.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1030.0,\n",
      "            \"upper_bound\" : 1065.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1065.0,\n",
      "            \"upper_bound\" : 1100.0,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0 ], [ 1100.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 757.0, 778.0, 803.0, 809.0, 814.0, 823.0, 828.0, 844.0, 877.0, 900.0 ], [ 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0\u001b[0m\n",
      "\u001b[34m, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 750.0, 787.0, 800.0, 800.0, 800.0, 800.0, 835.0, 850.0, 850.0, 850.0, 900.0, 900.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_dow\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.557802411986844,\n",
      "      \"sum\" : 20997.0,\n",
      "      \"std_dev\" : 1.71174038731125,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 6.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 1170.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 1331.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 2.4,\n",
      "            \"count\" : 1613.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.4,\n",
      "            \"upper_bound\" : 3.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.0,\n",
      "            \"upper_bound\" : 3.6,\n",
      "            \"count\" : 1525.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6,\n",
      "            \"upper_bound\" : 4.2,\n",
      "            \"count\" : 1422.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.2,\n",
      "            \"upper_bound\" : 4.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.8,\n",
      "            \"upper_bound\" : 5.4,\n",
      "            \"count\" : 715.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.4,\n",
      "            \"upper_bound\" : 6.0,\n",
      "            \"count\" : 433.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 2.0, 4.0, 5.0, 4.0, 2.0, 0.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 4.0, 2.0, 1.0, 0.0, 2.0, 4.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 4.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 0.0, 3.0, 4.0, 2.0, 0.0, 2.0, 5.0, 0.0, 4.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 0.0, 4.0, 4.0, 0.0, 5.0, 5.0, 2.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 2.0, 5.0, 4.0, 2.0, 2.0, 3.0, 0.0, 0.0, 5.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 0.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 4.0, 4.0, 5.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 3.0, 0.0, 2.0, 4.0, 3.0, 3.0, 4.0, 1.0, 0.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 5.0, 1.0, 0.0, 5.0, 2.0, 4.0, 0.0, 4.0, 4.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 4.0, 3.0, 4.0, 2.0, 2.0, 0.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 1.0, 0.0, 5.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 5.0, 2.0, 3.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 0.0, 3.0, 2.0, 5.0, 3.0, 0.0, 3.0, 4.0, 0.0, 1.0, 0.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 0.0, 1.0, 4.0, 4.0, 5.0, 4.0, 5.0, 6.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 5.0, 2.0, 0.0, 4.0, 3.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 0.0, 4.0, 4.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 4.0, 3.0, 2.0, 1.0, 4.0, 5.0, 4.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 5.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 5.0, 4.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 5.0, 3.0, 6.0, 4.0, 2.0, 5.0, 0.0, 2.0, 5.0, 2.0, 0.0, 4.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 4.0, 5.0, 1.0, 3.0, 0.0, 5.0, 2.0, 1.0, 4.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0, 4.0, 2.0, 5.0, 2.0, 3.0, 5.0, 2.0, 4.0, 3.0, 1.0, 0.0, 3.0, 3.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 4.0, 3.0, 0.0, 1.0, 3.0, 2.0, 0.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 0.0, 2.0, 4.0, 4.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 4.0, 4.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 3.0, 4.0, 0.0, 5.0, 3.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 4.0, 4.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 2.0, 0.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 3.0, 4.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 4.0, 2.0, 2.0, 3.0, 5.0, 1.0, 3.0, 2.0, 4.0, 3.0, 1.0, 2.0, 4.0, 2.0, 4.0, 1.0, 0.0, 0.0, 4.0, 3.0, 3.0, 1.0, 4.0, 4.0, 3.0, 1.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 4.0, 2.0, 1.0, 3.0, 2.0, 0.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 4.0, 2.0, 3.0, 5.0, 3.0, 3.0, 5.0, 2.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 1.0, 2.0, 5.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 1.0, 3.0, 3.0, 3.0, 5.0, 2.0, 3.0, 3.0, 2.0, 4.0, 4.0, 0.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0 ], [ 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6\u001b[0m\n",
      "\u001b[34m.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"incident_day\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 15.368376172493605,\n",
      "      \"sum\" : 126159.0,\n",
      "      \"std_dev\" : 7.949790899813571,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 31.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 4.0,\n",
      "            \"count\" : 538.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.0,\n",
      "            \"upper_bound\" : 7.0,\n",
      "            \"count\" : 805.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.0,\n",
      "            \"upper_bound\" : 10.0,\n",
      "            \"count\" : 903.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 10.0,\n",
      "            \"upper_bound\" : 13.0,\n",
      "            \"count\" : 1020.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.0,\n",
      "            \"upper_bound\" : 16.0,\n",
      "            \"count\" : 990.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 16.0,\n",
      "            \"upper_bound\" : 19.0,\n",
      "            \"count\" : 911.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 19.0,\n",
      "            \"upper_bound\" : 22.0,\n",
      "            \"count\" : 928.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 22.0,\n",
      "            \"upper_bound\" : 25.0,\n",
      "            \"count\" : 780.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 25.0,\n",
      "            \"upper_bound\" : 28.0,\n",
      "            \"count\" : 738.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 28.0,\n",
      "            \"upper_bound\" : 31.0,\n",
      "            \"count\" : 596.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 22.0, 16.0, 18.0, 9.0, 22.0, 24.0, 20.0, 19.0, 4.0, 5.0, 7.0, 2.0, 15.0, 9.0, 20.0, 24.0, 5.0, 17.0, 11.0, 9.0, 9.0, 21.0, 26.0, 9.0, 21.0, 10.0, 13.0, 6.0, 7.0, 3.0, 6.0, 14.0, 24.0, 8.0, 3.0, 8.0, 7.0, 13.0, 6.0, 16.0, 12.0, 27.0, 4.0, 19.0, 20.0, 26.0, 25.0, 10.0, 6.0, 22.0, 15.0, 3.0, 22.0, 8.0, 6.0, 23.0, 9.0, 19.0, 21.0, 23.0, 12.0, 9.0, 8.0, 22.0, 11.0, 17.0, 6.0, 22.0, 12.0, 16.0, 25.0, 17.0, 14.0, 19.0, 7.0, 28.0, 13.0, 15.0, 8.0, 11.0, 16.0, 22.0, 3.0, 19.0, 11.0, 17.0, 12.0, 15.0, 13.0, 3.0, 7.0, 26.0, 20.0, 17.0, 17.0, 4.0, 7.0, 23.0, 19.0, 27.0, 20.0, 26.0, 19.0, 10.0, 25.0, 9.0, 17.0, 19.0, 24.0, 2.0, 2.0, 20.0, 11.0, 17.0, 8.0, 29.0, 20.0, 4.0, 8.0, 9.0, 26.0, 20.0, 16.0, 13.0, 11.0, 18.0, 12.0, 9.0, 8.0, 11.0, 13.0, 27.0, 15.0, 14.0, 22.0, 11.0, 4.0, 16.0, 22.0, 11.0, 9.0, 4.0, 4.0, 27.0, 11.0, 5.0, 14.0, 9.0, 7.0, 23.0, 24.0, 18.0, 5.0, 21.0, 18.0, 23.0, 18.0, 10.0, 16.0, 2.0, 13.0, 15.0, 19.0, 2.0, 13.0, 13.0, 11.0, 12.0, 4.0, 19.0, 2.0, 10.0, 17.0, 24.0, 20.0, 14.0, 22.0, 7.0, 10.0, 21.0, 10.0, 18.0, 21.0, 25.0, 12.0, 8.0, 10.0, 6.0, 16.0, 6.0, 21.0, 15.0, 27.0, 6.0, 15.0, 19.0, 20.0, 14.0, 13.0, 16.0, 13.0, 21.0, 24.0, 9.0, 8.0, 29.0, 17.0, 22.0, 19.0, 17.0, 4.0, 15.0, 7.0, 6.0, 11.0, 26.0, 7.0, 18.0, 23.0, 16.0, 6.0, 25.0, 16.0, 27.0, 6.0, 12.0, 7.0, 15.0, 3.0, 27.0, 7.0, 5.0, 20.0, 6.0, 25.0, 3.0, 12.0, 9.0, 18.0, 12.0, 12.0, 15.0, 16.0, 4.0, 15.0, 11.0, 2.0, 13.0, 17.0, 7.0, 23.0, 29.0, 28.0, 11.0, 9.0, 18.0, 19.0, 4.0, 8.0, 12.0, 5.0, 15.0, 7.0, 21.0, 9.0, 21.0, 15.0, 4.0, 18.0, 7.0, 15.0, 23.0, 16.0, 9.0, 13.0, 17.0, 10.0, 7.0, 2.0, 9.0, 26.0, 20.0, 17.0, 14.0, 20.0, 10.0, 12.0, 8.0, 12.0, 8.0, 17.0, 6.0, 5.0, 26.0, 18.0, 18.0, 7.0, 5.0, 3.0, 9.0, 7.0, 16.0, 5.0, 16.0, 15.0, 17.0, 23.0, 11.0, 17.0, 6.0, 4.0, 19.0, 11.0, 17.0, 21.0, 15.0, 16.0, 11.0, 27.0, 9.0, 22.0, 17.0, 11.0, 15.0, 19.0, 14.0, 25.0, 16.0, 20.0, 12.0, 15.0, 20.0, 22.0, 14.0, 12.0, 20.0, 12.0, 25.0, 28.0, 15.0, 10.0, 9.0, 22.0, 9.0, 27.0, 17.0, 19.0, 23.0, 12.0, 14.0, 19.0, 25.0, 11.0, 20.0, 26.0, 9.0, 12.0, 18.0, 12.0, 17.0, 14.0, 8.0, 29.0, 4.0, 5.0, 6.0, 25.0, 22.0, 10.0, 26.0, 17.0, 19.0, 9.0, 22.0, 6.0, 11.0, 27.0, 7.0, 11.0, 4.0, 21.0, 9.0, 13.0, 13.0, 21.0, 22.0, 25.0, 21.0, 16.0, 4.0, 24.0, 6.0, 10.0, 16.0, 8.0, 26.0, 25.0, 10.0, 21.0, 22.0, 8.0, 26.0, 22.0, 24.0, 15.0, 29.0, 19.0, 18.0, 11.0, 6.0, 25.0, 25.0, 12.0, 22.0, 11.0, 16.0, 7.0, 18.0, 13.0, 6.0, 10.0, 2.0, 22.0, 23.0, 27.0, 13.0, 20.0, 15.0, 5.0, 23.0, 11.0, 3.0, 23.0, 8.0, 14.0, 14.0, 17.0, 13.0, 22.0, 9.0, 17.0, 13.0, 22.0, 8.0, 2.0, 10.0, 20.0, 11.0, 3.0, 29.0, 29.0, 11.0, 24.0, 10.0, 9.0, 20.0, 8.0, 13.0, 5.0, 6.0, 19.0, 6.0, 18.0, 22.0, 3.0, 15.0, 20.0, 13.0, 19.0, 18.0, 16.0, 3.0, 6.0, 10.0, 11.0, 6.0, 8.0, 9.0, 11.0, 16.0, 17.0, 7.0, 9.0, 15.0, 9.0, 21.0, 8.0, 8.0, 5.0, 14.0, 14.0, 15.0, 25.0, 12.0, 18.0, 18.0, 9.0, 12.0, 26.0, 25.0, 21.0, 6.0, 14.0, 6.0, 15.0, 7.0, 22.0, 15.0, 13.0, 6.0, 11.0, 11.0, 18.0, 19.0, 15.0, 20.0, 10.0, 13.0, 12.0, 9.0, 12.0, 12.0, 24.0, 17.0, 25.0, 12.0, 10.0, 13.0, 16.0, 12.0, 4.0, 10.0, 14.0, 16.0, 23.0, 11.0, 8.0, 21.0, 12.0, 18.0, 10.0, 17.0, 8.0, 21.0, 14.0, 11.0, 17.0, 7.0, 23.0, 17.0, 15.0, 18.0, 20.0, 18.0, 7.0, 17.0, 26.0, 26.0, 3.0, 11.0, 7.0, 16.0, 18.0, 10.0, 17.0, 20.0, 10.0, 25.0, 18.0, 10.0, 11.0, 11.0, 19.0, 19.0, 11.0, 3.0, 9.0, 18.0, 6.0, 10.0, 8.0, 14.0, 15.0, 14.0, 8.0, 22.0, 13.0, 25.0, 12.0, 16.0, 26.0, 17.0, 12.0, 10.0, 11.0, 13.0, 11.0, 9.0, 11.0, 5.0, 17.0, 10.0, 9.0, 17.0, 18.0, 8.0, 24.0, 19.0, 13.0, 6.0, 29.0, 10.0, 29.0, 9.0, 9.0, 24.0, 11.0, 23.0, 17.0, 11.0, 26.0, 16.0, 9.0, 10.0, 28.0, 18.0, 25.0, 10.0, 20.0, 13.0, 28.0, 16.0, 21.0, 6.0, 18.0, 21.0, 7.0, 14.0, 13.0, 25.0, 13.0, 14.0, 16.0, 14.0, 8.0, 6.0, 21.0, 3.0, 19.0, 9.0, 8.0, 11.0, 26.0, 15.0, 13.0, 4.0, 24.0, 3.0, 8.0, 18.0, 23.0, 12.0, 12.0, 12.0, 17.0, 17.0, 13.0, 10.0, 26.0, 6.0, 22.0, 10.0, 9.0, 21.0, 24.0, 6.0, 15.0, 12.0, 20.0, 18.0, 6.0, 6.0, 24.0, 21.0, 26.0, 20.0, 13.0, 20.0, 4.0, 8.0, 11.0, 4.0, 22.0, 26.0, 11.0, 8.0, 20.0, 23.0, 15.0, 21.0, 8.0, 17.0, 23.0, 7.0, 22.0, 8.0, 18.0, 6.0, 13.0, 4.0, 26.0 ], [ 31.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0 ], [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 1\u001b[0m\n",
      "\u001b[34m7.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"num_witnesses\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.5821659154586429,\n",
      "      \"sum\" : 4779.0,\n",
      "      \"std_dev\" : 0.9309730480417711,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 5.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 5320.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.5,\n",
      "            \"count\" : 1536.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.5,\n",
      "            \"upper_bound\" : 2.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.0,\n",
      "            \"upper_bound\" : 2.5,\n",
      "            \"count\" : 932.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.5,\n",
      "            \"upper_bound\" : 3.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.0,\n",
      "            \"upper_bound\" : 3.5,\n",
      "            \"count\" : 327.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.5,\n",
      "            \"upper_bound\" : 4.0,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.0,\n",
      "            \"upper_bound\" : 4.5,\n",
      "            \"count\" : 76.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.5,\n",
      "            \"upper_bound\" : 5.0,\n",
      "            \"count\" : 18.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3\u001b[0m\n",
      "\u001b[34m.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"authorities_contacted_ambulance\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 8209,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.024681715083646256,\n",
      "      \"sum\" : 202.6121991216521,\n",
      "      \"std_dev\" : 0.13942084973254734,\n",
      "      \"min\" : 0.0,\n",
      "      \"max\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.0,\n",
      "            \"upper_bound\" : 0.1,\n",
      "            \"count\" : 7916.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.1,\n",
      "            \"upper_bound\" : 0.2,\n",
      "            \"count\" : 23.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.2,\n",
      "            \"upper_bound\" : 0.3,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.3,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 27.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.5,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.5,\n",
      "            \"upper_bound\" : 0.6,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.6,\n",
      "            \"upper_bound\" : 0.7,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.7,\n",
      "            \"upper_bound\" : 0.8,\n",
      "            \"count\" : 35.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8,\n",
      "            \"upper_bound\" : 0.9,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.9,\n",
      "            \"upper_bound\" : 1.0,\n",
      "            \"count\" : 106.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.520449404165286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9530270089018602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9490251229775576, 0.0, 0.0, 0.41230298171245405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31270443741748244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6501456158191455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2545405429216612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10467597053553335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37303156547128347, 0.0, 0.3883535806100076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15137117126327493, 0.0, 0.0, 0.0, 0.81754195934751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5234071850674719, 0.0, 0.812077611008679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06368476750251673, 0.0, 0.0, 0.0, 0.0, 0.317347394955801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40216001315431504, 0.0, 0.0, 0.3750202516239648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08815215813664445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9221919280512842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34979606180759193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41737135395963443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06312990920796646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15434647772265764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7578253496525295, 0.9269964071003727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2497392059126845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6865139430432525, 0.0, 0.0, 0.22681649874124177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7374099443119462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08419241664932775, 0.0, 0.0, 0.0, 0.9792419678760358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1390022051990777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9525167896845986, 0.0, 0.0, 0.0, 0.7009353650179992, 0.19427357100180143, 0.0, 0.0, 0.654725348498443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7901023704137693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7059562365800072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6191680442430584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5643953803389896, 0.0, 0.4134882189625513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0722769475731766, 0.0, 0.8536545489411119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4437713390922451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5831278234528693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19033697509504754, 0.0, 0.0, 0.0, 0.43085827538227073, 0.0, 0.0, 0.7963006634151322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6192043172921549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38769515483900674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5156765510770731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7387435096159303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4677771251438061, 0.0, 0.0, 0.0, 0.8115720043515481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18378466510790115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ], [ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005351358440002119, 0.011164468610835532, 0.022893824976120247, 0.033452483447917625, 0.04865766366171331, 0.05977919442871504, 0.06980065461462892, 0.0875912974059464, 0.10851998437649324, 0.12200741357688905, 0.12459437487816571, 0.1412780492755058, 0.1543215652830794, 0.16529411097017455, 0.16984901700208188, 0.17325323197375297, 0.2007709747566786, 0.2176116705399127, 0.22254453281761444, 0.22673038292351066, 0.24188888355414595, 0.25305843280078455, 0.26290344956794875, 0.2660946229981306, 0.30458435167194675, 0.32301119838621384, 0.3373028364674864, 0.36154139875403857, 0.3735096830383876, 0.38068968116086577, 0.38480361722110323, 0.39570796357379256, 0.4148151193889472, 0.42593770846693946, 0.4411505522306324, 0.44760294032021697, 0.4592654328668958, 0.4741642962719864, 0.48836141748098594, 0.5006661650213817, 0.5235166162217073, 0.5467005205567683, 0.5488386567200587, 0.5493426449027576, 0.5625180733917903, 0.5895042059394454, 0.6063709444333756, 0.6136510901516845, 0.6172490208487257, 0.6363546410805504, 0.656055021975704, 0.6801319311034514, 0.6933351537347067, 0.7037923109905077, 0.7117484228326315, 0.7243444063295397, 0.7355056064875376, 0.7406115992568038, 0.7528684453386081, 0.7596114286997965, 0.7685199040870118, 0.7739062217706651, 0.7839095468146925, 0.7888875288338638, 0.7901580051435906, 0.8004946850703916, 0.8139769999943344, 0.8228290747281345, 0.8279139675473736, 0.8324171834102527, 0.8398203522034884, 0.8479278837633485, 0.863009046067227, 0.8839773186518307, 0.8935945864501316, 0.9086258951395908, 0.9124513359722194, 0.9323227582288776, 0.9439282834764579, 0.948099056412691, 0.9671903758713916, 0.9703317769352602, 0.9844916693734078, 0.9976228222513854 ], [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \u001b[0m\n",
      "\u001b[34m0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32209470221933534, 0.7834227259416147, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  } ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:48 INFO  FileUtil:29 - Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  YarnClientSchedulerBackend:54 - Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  YarnClientSchedulerBackend:54 - Shutting down all executors\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  YarnClientSchedulerBackend:54 - Stopped\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  MemoryStore:54 - MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  BlockManager:54 - BlockManager stopped\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  SparkContext:54 - Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  Main:65 - Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  Main:141 - Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  ShutdownHookManager:54 - Shutdown hook called\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-1e72e140-aac7-4ab9-ad3a-3c323b4de1ce\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-579ebd00-52d2-42e6-a922-42e68ede6f99\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49,426 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2022-05-19 18:48:49,426 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f34c541df10>"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Files:\n",
      "att-demo/monitoring/baselining/results/constraints.json\n",
      " att-demo/monitoring/baselining/results/statistics.json\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=baseline_results_prefix)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraud</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333293</td>\n",
       "      <td>2.736000e+03</td>\n",
       "      <td>0.471390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>driver_relationship_spouse</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>8.004006e+02</td>\n",
       "      <td>0.272649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>policy_state_ca</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591132</td>\n",
       "      <td>4.852602e+03</td>\n",
       "      <td>0.446117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 0.9318909752764775, 1.0, 0.935378161307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incident_type_breakin</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128647</td>\n",
       "      <td>1.056066e+03</td>\n",
       "      <td>0.298105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.06810902472352254, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_vehicles_involved</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>1.834206</td>\n",
       "      <td>1.505700e+04</td>\n",
       "      <td>0.803161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 1.6, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>incident_month</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>6.739432</td>\n",
       "      <td>5.532400e+04</td>\n",
       "      <td>3.331625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 2.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[4.0, 10.0, 9.0, 9.0, 6.0, 6.0, 3.0, 3.0, 2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incident_type_theft</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052531</td>\n",
       "      <td>4.312282e+02</td>\n",
       "      <td>0.202187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.2181743295932732, 0.0, 0.0, 0.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>authorities_contacted_none</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.279597</td>\n",
       "      <td>2.295215e+03</td>\n",
       "      <td>0.411311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.5035469815118861, 0.9318909752764775, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_injuries</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392740</td>\n",
       "      <td>3.224000e+03</td>\n",
       "      <td>0.821638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.4, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vehicle_claim</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8209</td>\n",
       "      <td>0</td>\n",
       "      <td>16518.060665</td>\n",
       "      <td>1.355968e+08</td>\n",
       "      <td>9252.604103</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>[{'lower_bound': 1000.0, 'upper_bound': 6000.0...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[4248.0, 16000.0, 17890.0, 11000.0, 15826.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name inferred_type  \\\n",
       "0                       fraud      Integral   \n",
       "1  driver_relationship_spouse    Fractional   \n",
       "2             policy_state_ca    Fractional   \n",
       "3       incident_type_breakin    Fractional   \n",
       "4       num_vehicles_involved      Integral   \n",
       "5              incident_month      Integral   \n",
       "6         incident_type_theft    Fractional   \n",
       "7  authorities_contacted_none    Fractional   \n",
       "8                num_injuries      Integral   \n",
       "9               vehicle_claim      Integral   \n",
       "\n",
       "   numerical_statistics.common.num_present  \\\n",
       "0                                     8209   \n",
       "1                                     8209   \n",
       "2                                     8209   \n",
       "3                                     8209   \n",
       "4                                     8209   \n",
       "5                                     8209   \n",
       "6                                     8209   \n",
       "7                                     8209   \n",
       "8                                     8209   \n",
       "9                                     8209   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   0.333293   \n",
       "1                                        0                   0.097503   \n",
       "2                                        0                   0.591132   \n",
       "3                                        0                   0.128647   \n",
       "4                                        0                   1.834206   \n",
       "5                                        0                   6.739432   \n",
       "6                                        0                   0.052531   \n",
       "7                                        0                   0.279597   \n",
       "8                                        0                   0.392740   \n",
       "9                                        0               16518.060665   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0              2.736000e+03                      0.471390   \n",
       "1              8.004006e+02                      0.272649   \n",
       "2              4.852602e+03                      0.446117   \n",
       "3              1.056066e+03                      0.298105   \n",
       "4              1.505700e+04                      0.803161   \n",
       "5              5.532400e+04                      3.331625   \n",
       "6              4.312282e+02                      0.202187   \n",
       "7              2.295215e+03                      0.411311   \n",
       "8              3.224000e+03                      0.821638   \n",
       "9              1.355968e+08                   9252.604103   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                       0.0                       1.0   \n",
       "1                       0.0                       1.0   \n",
       "2                       0.0                       1.0   \n",
       "3                       0.0                       1.0   \n",
       "4                       1.0                       7.0   \n",
       "5                       1.0                      12.0   \n",
       "6                       0.0                       1.0   \n",
       "7                       0.0                       1.0   \n",
       "8                       0.0                       4.0   \n",
       "9                    1000.0                   51000.0   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "2  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "3  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "4  [{'lower_bound': 1.0, 'upper_bound': 1.6, 'cou...   \n",
       "5  [{'lower_bound': 1.0, 'upper_bound': 2.1, 'cou...   \n",
       "6  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "7  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "8  [{'lower_bound': 0.0, 'upper_bound': 0.4, 'cou...   \n",
       "9  [{'lower_bound': 1000.0, 'upper_bound': 6000.0...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                               0.64           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                             2048.0           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "1  [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.13...  \n",
       "2  [[1.0, 0.9318909752764775, 1.0, 0.935378161307...  \n",
       "3  [[0.0, 0.06810902472352254, 0.0, 0.0, 0.0, 0.0...  \n",
       "4  [[2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0,...  \n",
       "5  [[4.0, 10.0, 9.0, 9.0, 6.0, 6.0, 3.0, 3.0, 2.0...  \n",
       "6  [[0.0, 0.0, 0.2181743295932732, 0.0, 0.0, 0.44...  \n",
       "7  [[0.5035469815118861, 0.9318909752764775, 0.0,...  \n",
       "8  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "9  [[4248.0, 16000.0, 17890.0, 11000.0, 15826.0, ...  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraud</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>driver_relationship_spouse</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>policy_state_ca</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incident_type_breakin</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_vehicles_involved</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>incident_month</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incident_type_theft</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>authorities_contacted_none</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_injuries</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vehicle_claim</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name inferred_type  completeness  \\\n",
       "0                       fraud      Integral           1.0   \n",
       "1  driver_relationship_spouse    Fractional           1.0   \n",
       "2             policy_state_ca    Fractional           1.0   \n",
       "3       incident_type_breakin    Fractional           1.0   \n",
       "4       num_vehicles_involved      Integral           1.0   \n",
       "5              incident_month      Integral           1.0   \n",
       "6         incident_type_theft    Fractional           1.0   \n",
       "7  authorities_contacted_none    Fractional           1.0   \n",
       "8                num_injuries      Integral           1.0   \n",
       "9               vehicle_claim      Integral           1.0   \n",
       "\n",
       "   num_constraints.is_non_negative  \n",
       "0                             True  \n",
       "1                             True  \n",
       "2                             True  \n",
       "3                             True  \n",
       "4                             True  \n",
       "5                             True  \n",
       "6                             True  \n",
       "7                             True  \n",
       "8                             True  \n",
       "9                             True  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.io.json.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a schedule to analyze collected data for data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_default_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: att-demo-monitoring-job-2022-05-19-18-49-55\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "mon_schedule_name = f\"{prefix}-monitoring-job-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "s3_report_path = f\"s3://{bucket}/{prefix}/montoring/report\"\n",
    "\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Scheduled\n"
     ]
    }
   ],
   "source": [
    "desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "print(\"Schedule status: {}\".format(desc_schedule_result[\"MonitoringScheduleStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some artificial traffic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 artificial traffic predicted...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "count = 0\n",
    "for i in range(1020, 1060):\n",
    "\n",
    "    combined_response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=combined_fg_name, RecordIdentifierValueAsString=str(i)\n",
    "    )\n",
    "\n",
    "    combined_record = combined_response[\"Record\"]\n",
    "    combined_df = pd.DataFrame(combined_record).set_index(\"FeatureName\")\n",
    "\n",
    "    blended_df = combined_df.loc[col_order].drop([\"fraud\"])\n",
    "    \n",
    "#     input_list = []\n",
    "#     for x in blended_df[\"ValueAsString\"]:\n",
    "#         if bool(random.getrandbits(1)):\n",
    "#             input_list.append(str(x))\n",
    "#         else:\n",
    "#             input_list.append(f\"{str(random.randint(0, 100))}\")\n",
    "#     data_input = \",\".join(input_list)\n",
    "\n",
    "    data_input = \",\".join([str(x) for x in blended_df[\"ValueAsString\"]])\n",
    "\n",
    "    results = predictor.predict(data_input, initial_args={\"ContentType\": \"text/csv\"})\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "print(f\"{count} artificial traffic predicted...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sagemaker.model_monitor.model_monitoring.MonitoringExecution at 0x7f34c6118c90>]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon_executions = my_default_monitor.list_executions()\n",
    "mon_executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1e2226af-d8dc-4f44-a794-d71a43391ca8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1e2226af-d8dc-4f44-a794-d71a43391ca8',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 12 May 2022 19:16:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_feature_group(\n",
    "    FeatureGroupName='fraud-detect-demo-customers-api'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
